{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import transformers \n",
    "import transformers as ppb # pytorch transformers\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from tqdm import notebook\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import requests\n",
    "import io\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from urllib.parse import urlencode \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка констант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Знакомство с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159292, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except:\n",
    "    df = pd.read_csv(r'C:\\Users\\maxpe\\Downloads\\Practicum\\Projects\\datasets\\toxic_comments.csv')\n",
    "display(df.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "0                0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1                1  D'aww! He matches this background colour I'm s...      0\n",
       "2                2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3                3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4                4  You, sir, are my hero. Any chance you remember...      0\n",
       "...            ...                                                ...    ...\n",
       "159287      159446  \":::::And for the second time of asking, when ...      0\n",
       "159288      159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159289      159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159290      159449  And it looks like it was actually you who put ...      0\n",
       "159291      159450  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет не содержит пустых строк, состоит из 3 столбцов, один из которых будет преобразован в признаки (`text`), а `toxic` - целевой признак. Столбец `Unnamed` можем удалить. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159287  \":::::And for the second time of asking, when ...      0\n",
       "159288  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159289  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159290  And it looks like it was actually you who put ...      0\n",
       "159291  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159292 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка предобученных модели и токенизатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим любой рандомный текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 2017,\n",
       " 1010,\n",
       " 2909,\n",
       " 1010,\n",
       " 2024,\n",
       " 2026,\n",
       " 5394,\n",
       " 1012,\n",
       " 2151,\n",
       " 3382,\n",
       " 2017,\n",
       " 3342,\n",
       " 1012,\n",
       " 1012,\n",
       " 102]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('You, sir, are my hero. Any chance you remember..', add_special_tokens=True) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизатор отрабатывает корректно. Применим его предварительно к датасету."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразуем текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "pre_tokenized = df['text'].apply(\n",
    "  lambda x: tokenizer.encode(x, add_special_tokens=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [101, 7526, 2339, 1996, 10086, 2015, 2081, 210...\n",
       "1         [101, 1040, 1005, 22091, 2860, 999, 2002, 3503...\n",
       "2         [101, 4931, 2158, 1010, 1045, 1005, 1049, 2428...\n",
       "3         [101, 1000, 2062, 1045, 2064, 1005, 1056, 2191...\n",
       "4         [101, 2017, 1010, 2909, 1010, 2024, 2026, 5394...\n",
       "                                ...                        \n",
       "159287    [101, 1000, 1024, 1024, 1024, 1024, 1024, 1998...\n",
       "159288    [101, 2017, 2323, 2022, 14984, 1997, 4426, 200...\n",
       "159289    [101, 13183, 6290, 26114, 1010, 2045, 2015, 20...\n",
       "159290    [101, 1998, 2009, 3504, 2066, 2009, 2001, 2941...\n",
       "159291    [101, 1000, 1998, 1012, 1012, 1012, 1045, 2428...\n",
       "Name: text, Length: 159292, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_tokenized"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим из сообщения к `pre_tokenized`, имеем ограничение в 512 токенов в строке. Создадим такое ограничение."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Фильтруем данные"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем датасет из токенизированных данных - столбец `text`, целевого признака и длин списков токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 7526, 2339, 1996, 10086, 2015, 2081, 210...</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 1040, 1005, 22091, 2860, 999, 2002, 3503...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 4931, 2158, 1010, 1045, 1005, 1049, 2428...</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[101, 1000, 2062, 1045, 2064, 1005, 1056, 2191...</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[101, 2017, 1010, 2909, 1010, 2024, 2026, 5394...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>[101, 1000, 1024, 1024, 1024, 1024, 1024, 1998...</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>[101, 2017, 2323, 2022, 14984, 1997, 4426, 200...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>[101, 13183, 6290, 26114, 1010, 2045, 2015, 20...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>[101, 1998, 2009, 3504, 2066, 2009, 2001, 2941...</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>[101, 1000, 1998, 1012, 1012, 1012, 1045, 2428...</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  len\n",
       "0       [101, 7526, 2339, 1996, 10086, 2015, 2081, 210...      0   68\n",
       "1       [101, 1040, 1005, 22091, 2860, 999, 2002, 3503...      0   35\n",
       "2       [101, 4931, 2158, 1010, 1045, 1005, 1049, 2428...      0   54\n",
       "3       [101, 1000, 2062, 1045, 2064, 1005, 1056, 2191...      0  144\n",
       "4       [101, 2017, 1010, 2909, 1010, 2024, 2026, 5394...      0   21\n",
       "...                                                   ...    ...  ...\n",
       "159287  [101, 1000, 1024, 1024, 1024, 1024, 1024, 1998...      0   68\n",
       "159288  [101, 2017, 2323, 2022, 14984, 1997, 4426, 200...      0   27\n",
       "159289  [101, 13183, 6290, 26114, 1010, 2045, 2015, 20...      0   19\n",
       "159290  [101, 1998, 2009, 3504, 2066, 2009, 2001, 2941...      0   28\n",
       "159291  [101, 1000, 1998, 1012, 1012, 1012, 1045, 2428...      0   51\n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = pd.DataFrame(pre_tokenized)\n",
    "df_temp['toxic'] = df['toxic']\n",
    "len_list = []\n",
    "for i in df_temp['text']:\n",
    "    len_list.append(len(i))\n",
    "df_temp['len'] = len_list\n",
    "df_temp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляем строки с превышающими лимит токенами. таких строк порядка 1.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 7526, 2339, 1996, 10086, 2015, 2081, 210...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 1040, 1005, 22091, 2860, 999, 2002, 3503...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 4931, 2158, 1010, 1045, 1005, 1049, 2428...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[101, 1000, 2062, 1045, 2064, 1005, 1056, 2191...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[101, 2017, 1010, 2909, 1010, 2024, 2026, 5394...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>[101, 1000, 1024, 1024, 1024, 1024, 1024, 1998...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>[101, 2017, 2323, 2022, 14984, 1997, 4426, 200...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>[101, 13183, 6290, 26114, 1010, 2045, 2015, 20...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>[101, 1998, 2009, 3504, 2066, 2009, 2001, 2941...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>[101, 1000, 1998, 1012, 1012, 1012, 1045, 2428...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155789 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       [101, 7526, 2339, 1996, 10086, 2015, 2081, 210...      0\n",
       "1       [101, 1040, 1005, 22091, 2860, 999, 2002, 3503...      0\n",
       "2       [101, 4931, 2158, 1010, 1045, 1005, 1049, 2428...      0\n",
       "3       [101, 1000, 2062, 1045, 2064, 1005, 1056, 2191...      0\n",
       "4       [101, 2017, 1010, 2909, 1010, 2024, 2026, 5394...      0\n",
       "...                                                   ...    ...\n",
       "159287  [101, 1000, 1024, 1024, 1024, 1024, 1024, 1998...      0\n",
       "159288  [101, 2017, 2323, 2022, 14984, 1997, 4426, 200...      0\n",
       "159289  [101, 13183, 6290, 26114, 1010, 2045, 2015, 20...      0\n",
       "159290  [101, 1998, 2009, 3504, 2066, 2009, 2001, 2941...      0\n",
       "159291  [101, 1000, 1998, 1012, 1012, 1012, 1045, 2428...      0\n",
       "\n",
       "[155789 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = df_temp.loc[df_temp['len'] < 513].drop(['len'], axis=1)\n",
    "df_temp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем данные по индексу: слева - тексты из исходного датасета, справа - целевой признак из нового, отфильтрованного датасета. Так как `join` имеет значение `inner`, то остаются только те строки, в которых совпадает индекс, то есть прошедшие фильтрацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155789 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159287  \":::::And for the second time of asking, when ...      0\n",
       "159288  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159289  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159290  And it looks like it was actually you who put ...      0\n",
       "159291  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[155789 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_left = df['text']\n",
    "df_right = df_temp['toxic']\n",
    "result = pd.concat([df_left, df_right], axis=1, join=\"inner\")\n",
    "result\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ограничиваем размер выборки"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для экономии ресурсов, ограничим исходную выборку. Количество строк поместим в переменную `q_sample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>, I replied in the Talk page. First I sent the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now I have already emigrated from Germany, and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No, the game is too linear to be OW.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RESPONSE TO DEKISUGI: :The fact that you persi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. Active serive and ASU are commonly used ter...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>WTMM and WEEV\\nThanks of taking care of this f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>Peel Police Censorship and Vandalism \\n\\nAmazi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>Merge with Media Theory  revisit \\nJust to giv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>I hate you \\nMy name is Sean Noyes and I hate ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>Thank you for experimenting with Wikipedia. Yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  toxic\n",
       "0      , I replied in the Talk page. First I sent the...      0\n",
       "1      Now I have already emigrated from Germany, and...      0\n",
       "2                   No, the game is too linear to be OW.      0\n",
       "3      RESPONSE TO DEKISUGI: :The fact that you persi...      0\n",
       "4      1. Active serive and ASU are commonly used ter...      0\n",
       "...                                                  ...    ...\n",
       "19995  WTMM and WEEV\\nThanks of taking care of this f...      0\n",
       "19996  Peel Police Censorship and Vandalism \\n\\nAmazi...      0\n",
       "19997  Merge with Media Theory  revisit \\nJust to giv...      0\n",
       "19998  I hate you \\nMy name is Sean Noyes and I hate ...      1\n",
       "19999  Thank you for experimenting with Wikipedia. Yo...      0\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_sample = 20000\n",
    "df_cut = result.sample(q_sample).reset_index(drop=True)\n",
    "df_cut"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразуем текст предобработанных данных"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизируем отфильтрованную и урезанную выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = df_cut['text'].apply(\n",
    "  lambda x: tokenizer.encode(x, add_special_tokens=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [101, 1010, 1045, 3880, 1999, 1996, 2831, 3931...\n",
       "1        [101, 2085, 1045, 2031, 2525, 11367, 2013, 276...\n",
       "2        [101, 2053, 1010, 1996, 2208, 2003, 2205, 7399...\n",
       "3        [101, 3433, 2000, 2139, 14270, 15916, 2072, 10...\n",
       "4        [101, 1015, 1012, 3161, 14262, 3512, 1998, 200...\n",
       "                               ...                        \n",
       "19995    [101, 1059, 21246, 2213, 1998, 16776, 2615, 42...\n",
       "19996    [101, 14113, 2610, 15657, 1998, 3158, 9305, 29...\n",
       "19997    [101, 13590, 2007, 2865, 3399, 7065, 17417, 21...\n",
       "19998    [101, 1045, 5223, 2017, 2026, 2171, 2003, 5977...\n",
       "19999    [101, 4067, 2017, 2005, 23781, 2007, 16948, 10...\n",
       "Name: text, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ищем размер вектора"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предупреждения больше нет. Дополнительно проверяем самое большое значение длины токенов в тексте (хоть ограничение равно 512, не факт, что такие векторы могут попасть в выборку), и создаем переменную `max_len`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "max_len"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразование векторов"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Паддингом добавляем к каждому вектору нули в конец, так, чтобы длина каждого вектора была равна длине `max_len`.\n",
    "\n",
    "Маска тоже применяется к каждому вектору - значению, отличному от нуля, присваивается 1, нули остаются нулями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"first\">[q_sample](#1)</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Расчет ячейки ниже занимает очень много времени.** \n",
    "\n",
    "Можно уменьшить количество строк переменной `q_sample` для проверки работоспособности кода. Но для удобства проверки, увеличения скорости работы, все заранее рассчитано на более крупной выборке, выгружено на Гитхаб/Яндекс.Диск, и загружено обратно в код.\n",
    "\n",
    "Если делать по прямому пути (преобразование в эмбенддинги внутри ноутбука), то ячейки выполняются последовательно, кроме пункта \"Загрузка датасета\". Выгрузка датасета закомментирована, она не должна исполняться.\n",
    "\n",
    "Если выполнять с заранее преобразованными эмбеддингами по второму пути, то пункт \"**Преобразование в эмбеддинги**\" не исполнять, и перехоить к пункту \"**Загрузка датасета**\". В датасете Гитхаба лежит выборка на 2000 строк, в Яндекс.Диске - на 20000.\n",
    "\n",
    "Сейчас пункт \"**Преобразование в эмбеддинги**\" закомментирован во избежание неразберихи, в случае запуска всего файла целиком, а не по ячейкам. То есть, фактически, код исполняется по второму сценарию, через Яндекс.Диск. \n",
    "\n",
    "*Для раскомментирования/комментирования всей ячейки использовать сочетание `Ctrl + /`.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразование в эмбеддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011997222900390625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 40,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0401b2da14484b2384b17f41efcec379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.210253</td>\n",
       "      <td>-0.088105</td>\n",
       "      <td>0.373194</td>\n",
       "      <td>0.045138</td>\n",
       "      <td>-0.412036</td>\n",
       "      <td>0.115870</td>\n",
       "      <td>0.592757</td>\n",
       "      <td>0.490689</td>\n",
       "      <td>0.245250</td>\n",
       "      <td>-0.675427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206053</td>\n",
       "      <td>0.073777</td>\n",
       "      <td>-0.020319</td>\n",
       "      <td>-0.036723</td>\n",
       "      <td>0.048516</td>\n",
       "      <td>-0.063282</td>\n",
       "      <td>-0.291686</td>\n",
       "      <td>0.131764</td>\n",
       "      <td>0.505391</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.086958</td>\n",
       "      <td>0.619067</td>\n",
       "      <td>0.029847</td>\n",
       "      <td>-0.391548</td>\n",
       "      <td>-0.167374</td>\n",
       "      <td>-0.407611</td>\n",
       "      <td>0.808926</td>\n",
       "      <td>0.458772</td>\n",
       "      <td>-0.011550</td>\n",
       "      <td>-0.476740</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.212916</td>\n",
       "      <td>-0.214355</td>\n",
       "      <td>-0.239323</td>\n",
       "      <td>0.307829</td>\n",
       "      <td>0.141115</td>\n",
       "      <td>0.046230</td>\n",
       "      <td>-0.242870</td>\n",
       "      <td>0.519338</td>\n",
       "      <td>0.629348</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010980</td>\n",
       "      <td>-0.178602</td>\n",
       "      <td>0.077921</td>\n",
       "      <td>0.065314</td>\n",
       "      <td>-0.412028</td>\n",
       "      <td>-0.527476</td>\n",
       "      <td>0.038064</td>\n",
       "      <td>0.252827</td>\n",
       "      <td>0.327264</td>\n",
       "      <td>-0.307346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057288</td>\n",
       "      <td>0.267838</td>\n",
       "      <td>-0.116387</td>\n",
       "      <td>-0.286996</td>\n",
       "      <td>-0.009243</td>\n",
       "      <td>0.093149</td>\n",
       "      <td>-0.120039</td>\n",
       "      <td>0.309154</td>\n",
       "      <td>0.658118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.088517</td>\n",
       "      <td>-0.471235</td>\n",
       "      <td>-0.667682</td>\n",
       "      <td>-0.059110</td>\n",
       "      <td>-0.605237</td>\n",
       "      <td>-0.350114</td>\n",
       "      <td>0.480405</td>\n",
       "      <td>0.203409</td>\n",
       "      <td>0.070762</td>\n",
       "      <td>-0.420400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.670664</td>\n",
       "      <td>-0.147321</td>\n",
       "      <td>-0.092641</td>\n",
       "      <td>0.043940</td>\n",
       "      <td>-0.066983</td>\n",
       "      <td>-0.083624</td>\n",
       "      <td>-0.187160</td>\n",
       "      <td>-0.075435</td>\n",
       "      <td>0.534236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.146267</td>\n",
       "      <td>0.062430</td>\n",
       "      <td>-0.461665</td>\n",
       "      <td>-0.140508</td>\n",
       "      <td>-0.031926</td>\n",
       "      <td>-0.329088</td>\n",
       "      <td>0.564474</td>\n",
       "      <td>0.623633</td>\n",
       "      <td>0.113733</td>\n",
       "      <td>-0.299472</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186488</td>\n",
       "      <td>0.117171</td>\n",
       "      <td>-0.234970</td>\n",
       "      <td>-0.034679</td>\n",
       "      <td>0.198808</td>\n",
       "      <td>0.094138</td>\n",
       "      <td>-0.288756</td>\n",
       "      <td>0.299675</td>\n",
       "      <td>0.468383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>-0.538163</td>\n",
       "      <td>-0.293847</td>\n",
       "      <td>0.561924</td>\n",
       "      <td>-0.284176</td>\n",
       "      <td>-0.207451</td>\n",
       "      <td>-0.663484</td>\n",
       "      <td>0.672475</td>\n",
       "      <td>0.591221</td>\n",
       "      <td>0.425575</td>\n",
       "      <td>-0.468169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.174168</td>\n",
       "      <td>-0.147563</td>\n",
       "      <td>-0.639911</td>\n",
       "      <td>0.613554</td>\n",
       "      <td>0.122093</td>\n",
       "      <td>-0.009356</td>\n",
       "      <td>-0.035191</td>\n",
       "      <td>0.724588</td>\n",
       "      <td>0.733067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>-0.572489</td>\n",
       "      <td>0.238362</td>\n",
       "      <td>0.015432</td>\n",
       "      <td>0.161005</td>\n",
       "      <td>-0.124715</td>\n",
       "      <td>-0.135626</td>\n",
       "      <td>0.207103</td>\n",
       "      <td>0.489043</td>\n",
       "      <td>-0.259537</td>\n",
       "      <td>-0.259918</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199020</td>\n",
       "      <td>-0.188011</td>\n",
       "      <td>-0.414878</td>\n",
       "      <td>0.677697</td>\n",
       "      <td>0.208532</td>\n",
       "      <td>-0.430124</td>\n",
       "      <td>-0.331739</td>\n",
       "      <td>0.082620</td>\n",
       "      <td>0.545732</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0.067305</td>\n",
       "      <td>-0.394596</td>\n",
       "      <td>-0.363171</td>\n",
       "      <td>0.017226</td>\n",
       "      <td>-0.605997</td>\n",
       "      <td>-0.646271</td>\n",
       "      <td>0.133162</td>\n",
       "      <td>0.700449</td>\n",
       "      <td>0.066573</td>\n",
       "      <td>-0.308690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062487</td>\n",
       "      <td>-0.124399</td>\n",
       "      <td>-0.611043</td>\n",
       "      <td>0.026428</td>\n",
       "      <td>0.270664</td>\n",
       "      <td>-0.310393</td>\n",
       "      <td>-0.391263</td>\n",
       "      <td>0.631866</td>\n",
       "      <td>0.689399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>-0.006548</td>\n",
       "      <td>0.250921</td>\n",
       "      <td>-0.315235</td>\n",
       "      <td>-0.377749</td>\n",
       "      <td>-0.533632</td>\n",
       "      <td>-0.221953</td>\n",
       "      <td>0.650980</td>\n",
       "      <td>0.918593</td>\n",
       "      <td>0.315673</td>\n",
       "      <td>-0.316328</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070844</td>\n",
       "      <td>-0.102762</td>\n",
       "      <td>-0.321104</td>\n",
       "      <td>0.476053</td>\n",
       "      <td>-0.009053</td>\n",
       "      <td>-0.083950</td>\n",
       "      <td>-0.336701</td>\n",
       "      <td>0.266582</td>\n",
       "      <td>0.735228</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>-0.002855</td>\n",
       "      <td>-0.073349</td>\n",
       "      <td>-0.005081</td>\n",
       "      <td>-0.168381</td>\n",
       "      <td>-0.036934</td>\n",
       "      <td>-0.749657</td>\n",
       "      <td>0.594881</td>\n",
       "      <td>0.669694</td>\n",
       "      <td>0.125158</td>\n",
       "      <td>-0.411319</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083819</td>\n",
       "      <td>-0.009881</td>\n",
       "      <td>-0.207218</td>\n",
       "      <td>0.481938</td>\n",
       "      <td>0.173691</td>\n",
       "      <td>-0.332396</td>\n",
       "      <td>-0.236408</td>\n",
       "      <td>0.336156</td>\n",
       "      <td>0.636091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -0.210253 -0.088105  0.373194  0.045138 -0.412036  0.115870  0.592757   \n",
       "1      0.086958  0.619067  0.029847 -0.391548 -0.167374 -0.407611  0.808926   \n",
       "2      0.010980 -0.178602  0.077921  0.065314 -0.412028 -0.527476  0.038064   \n",
       "3     -0.088517 -0.471235 -0.667682 -0.059110 -0.605237 -0.350114  0.480405   \n",
       "4      0.146267  0.062430 -0.461665 -0.140508 -0.031926 -0.329088  0.564474   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "19995 -0.538163 -0.293847  0.561924 -0.284176 -0.207451 -0.663484  0.672475   \n",
       "19996 -0.572489  0.238362  0.015432  0.161005 -0.124715 -0.135626  0.207103   \n",
       "19997  0.067305 -0.394596 -0.363171  0.017226 -0.605997 -0.646271  0.133162   \n",
       "19998 -0.006548  0.250921 -0.315235 -0.377749 -0.533632 -0.221953  0.650980   \n",
       "19999 -0.002855 -0.073349 -0.005081 -0.168381 -0.036934 -0.749657  0.594881   \n",
       "\n",
       "              7         8         9  ...       759       760       761  \\\n",
       "0      0.490689  0.245250 -0.675427  ... -0.206053  0.073777 -0.020319   \n",
       "1      0.458772 -0.011550 -0.476740  ... -0.212916 -0.214355 -0.239323   \n",
       "2      0.252827  0.327264 -0.307346  ... -0.057288  0.267838 -0.116387   \n",
       "3      0.203409  0.070762 -0.420400  ... -0.670664 -0.147321 -0.092641   \n",
       "4      0.623633  0.113733 -0.299472  ... -0.186488  0.117171 -0.234970   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "19995  0.591221  0.425575 -0.468169  ... -0.174168 -0.147563 -0.639911   \n",
       "19996  0.489043 -0.259537 -0.259918  ... -0.199020 -0.188011 -0.414878   \n",
       "19997  0.700449  0.066573 -0.308690  ...  0.062487 -0.124399 -0.611043   \n",
       "19998  0.918593  0.315673 -0.316328  ... -0.070844 -0.102762 -0.321104   \n",
       "19999  0.669694  0.125158 -0.411319  ... -0.083819 -0.009881 -0.207218   \n",
       "\n",
       "            762       763       764       765       766       767  toxic  \n",
       "0     -0.036723  0.048516 -0.063282 -0.291686  0.131764  0.505391      0  \n",
       "1      0.307829  0.141115  0.046230 -0.242870  0.519338  0.629348      0  \n",
       "2     -0.286996 -0.009243  0.093149 -0.120039  0.309154  0.658118      0  \n",
       "3      0.043940 -0.066983 -0.083624 -0.187160 -0.075435  0.534236      0  \n",
       "4     -0.034679  0.198808  0.094138 -0.288756  0.299675  0.468383      0  \n",
       "...         ...       ...       ...       ...       ...       ...    ...  \n",
       "19995  0.613554  0.122093 -0.009356 -0.035191  0.724588  0.733067      0  \n",
       "19996  0.677697  0.208532 -0.430124 -0.331739  0.082620  0.545732      0  \n",
       "19997  0.026428  0.270664 -0.310393 -0.391263  0.631866  0.689399      0  \n",
       "19998  0.476053 -0.009053 -0.083950 -0.336701  0.266582  0.735228      1  \n",
       "19999  0.481938  0.173691 -0.332396 -0.236408  0.336156  0.636091      0  \n",
       "\n",
       "[20000 rows x 769 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size = 500 # задаем размер батча (кратен q_sample, если уменьшаем q_sample - уменьшаем и батч)\n",
    "# embeddings = [] # список эмбеддингов\n",
    "# for i in notebook.tqdm(range(padded.shape[0] // batch_size)): # цикл по батчам, отображать прогресс будет функция notebook()\n",
    "#         batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) # преобразуем данные в формат тензоров\n",
    "#         attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]) # преобразуем маску\n",
    "        \n",
    "#         with torch.no_grad(): # для ускорения вычисления функцией no_grad() в библиотеке torch укажем, что градиенты не нужны\n",
    "#             batch_embeddings = model(batch, attention_mask=attention_mask_batch) # чтобы получить эмбеддинги для батча, передадим модели данные и маску\n",
    "        \n",
    "#         embeddings.append(batch_embeddings[0][:,0,:].numpy()) # преобразуем элементы методом numpy() к типу numpy.array\n",
    "\n",
    "# df_ed = pd.DataFrame(np.concatenate(embeddings)) # соберём все эмбеддинги в матрицу признаков вызовом функции concatenate()\n",
    "# df_ed['toxic'] = df_cut['toxic'] # добавляем целевой признак\n",
    "# df_ed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выгрузка датасета"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выгружаем датасет после этапа преобразования в эмбеддинги, для того, чтобы не пересчитывать их в следующий сеанс или на другом устройстве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ed.to_csv('df_ed.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка датасета"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка из GitHub"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитанные эмбендинги я поместил на нескольких ресурсах: Гитхаб и Яндекс.Диск. В Гитхабе имеется ограничение на размер файла, поэтому код ниже использовался/используется для быстрых загрузок небольшой выборки (порядка 2000-3000 строк), для оценки метрики `F1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Если преобразование в эмбенддинги делается внутри тетради, эту ячейку закомментировать/не исполнять.\n",
    "\n",
    "# # загрузка csv файла из GitHub\n",
    "# #url = \"https://raw.githubusercontent.com/rustyt0aster/samples/main/df_ed.csv\" # обязательно в формате raw. 20 000 не вписались в ограничение 25 мегабайт. итоговый вышел на 170 МБ.\n",
    "# download = requests.get(url).content\n",
    "\n",
    "# df_ed = pd.read_csv(io.StringIO(download.decode('utf-8'))) # чтение csv таблицы и удаление образованного столбца\n",
    "# df_ed = df_ed.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "# df_ed # вывод датафрейма"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка из Яндекс.Диска"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данный момент используется выборка на 20000 строк, с размером файла более чем в 170 МБ. Поэтому, можем использовать Яндекс.Диск для чтения `csv-файла`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.210253</td>\n",
       "      <td>-0.088105</td>\n",
       "      <td>0.373194</td>\n",
       "      <td>0.045138</td>\n",
       "      <td>-0.412036</td>\n",
       "      <td>0.115870</td>\n",
       "      <td>0.592757</td>\n",
       "      <td>0.490689</td>\n",
       "      <td>0.245250</td>\n",
       "      <td>-0.675427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206053</td>\n",
       "      <td>0.073777</td>\n",
       "      <td>-0.020319</td>\n",
       "      <td>-0.036723</td>\n",
       "      <td>0.048516</td>\n",
       "      <td>-0.063282</td>\n",
       "      <td>-0.291686</td>\n",
       "      <td>0.131764</td>\n",
       "      <td>0.505391</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.086958</td>\n",
       "      <td>0.619067</td>\n",
       "      <td>0.029847</td>\n",
       "      <td>-0.391548</td>\n",
       "      <td>-0.167374</td>\n",
       "      <td>-0.407611</td>\n",
       "      <td>0.808926</td>\n",
       "      <td>0.458772</td>\n",
       "      <td>-0.011550</td>\n",
       "      <td>-0.476740</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.212916</td>\n",
       "      <td>-0.214355</td>\n",
       "      <td>-0.239323</td>\n",
       "      <td>0.307829</td>\n",
       "      <td>0.141115</td>\n",
       "      <td>0.046230</td>\n",
       "      <td>-0.242870</td>\n",
       "      <td>0.519338</td>\n",
       "      <td>0.629348</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010980</td>\n",
       "      <td>-0.178602</td>\n",
       "      <td>0.077921</td>\n",
       "      <td>0.065314</td>\n",
       "      <td>-0.412028</td>\n",
       "      <td>-0.527477</td>\n",
       "      <td>0.038064</td>\n",
       "      <td>0.252827</td>\n",
       "      <td>0.327264</td>\n",
       "      <td>-0.307346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057288</td>\n",
       "      <td>0.267838</td>\n",
       "      <td>-0.116387</td>\n",
       "      <td>-0.286996</td>\n",
       "      <td>-0.009243</td>\n",
       "      <td>0.093149</td>\n",
       "      <td>-0.120039</td>\n",
       "      <td>0.309154</td>\n",
       "      <td>0.658118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.088517</td>\n",
       "      <td>-0.471235</td>\n",
       "      <td>-0.667682</td>\n",
       "      <td>-0.059110</td>\n",
       "      <td>-0.605237</td>\n",
       "      <td>-0.350114</td>\n",
       "      <td>0.480405</td>\n",
       "      <td>0.203409</td>\n",
       "      <td>0.070762</td>\n",
       "      <td>-0.420400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.670664</td>\n",
       "      <td>-0.147321</td>\n",
       "      <td>-0.092641</td>\n",
       "      <td>0.043940</td>\n",
       "      <td>-0.066983</td>\n",
       "      <td>-0.083624</td>\n",
       "      <td>-0.187160</td>\n",
       "      <td>-0.075435</td>\n",
       "      <td>0.534236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.146267</td>\n",
       "      <td>0.062430</td>\n",
       "      <td>-0.461665</td>\n",
       "      <td>-0.140508</td>\n",
       "      <td>-0.031926</td>\n",
       "      <td>-0.329088</td>\n",
       "      <td>0.564474</td>\n",
       "      <td>0.623633</td>\n",
       "      <td>0.113733</td>\n",
       "      <td>-0.299472</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186488</td>\n",
       "      <td>0.117171</td>\n",
       "      <td>-0.234970</td>\n",
       "      <td>-0.034679</td>\n",
       "      <td>0.198808</td>\n",
       "      <td>0.094138</td>\n",
       "      <td>-0.288756</td>\n",
       "      <td>0.299675</td>\n",
       "      <td>0.468383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>-0.538163</td>\n",
       "      <td>-0.293847</td>\n",
       "      <td>0.561924</td>\n",
       "      <td>-0.284176</td>\n",
       "      <td>-0.207451</td>\n",
       "      <td>-0.663484</td>\n",
       "      <td>0.672475</td>\n",
       "      <td>0.591221</td>\n",
       "      <td>0.425575</td>\n",
       "      <td>-0.468169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.174168</td>\n",
       "      <td>-0.147563</td>\n",
       "      <td>-0.639911</td>\n",
       "      <td>0.613554</td>\n",
       "      <td>0.122093</td>\n",
       "      <td>-0.009356</td>\n",
       "      <td>-0.035191</td>\n",
       "      <td>0.724588</td>\n",
       "      <td>0.733067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>-0.572489</td>\n",
       "      <td>0.238362</td>\n",
       "      <td>0.015432</td>\n",
       "      <td>0.161005</td>\n",
       "      <td>-0.124715</td>\n",
       "      <td>-0.135626</td>\n",
       "      <td>0.207103</td>\n",
       "      <td>0.489043</td>\n",
       "      <td>-0.259537</td>\n",
       "      <td>-0.259918</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199020</td>\n",
       "      <td>-0.188011</td>\n",
       "      <td>-0.414878</td>\n",
       "      <td>0.677697</td>\n",
       "      <td>0.208532</td>\n",
       "      <td>-0.430124</td>\n",
       "      <td>-0.331739</td>\n",
       "      <td>0.082619</td>\n",
       "      <td>0.545732</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0.067305</td>\n",
       "      <td>-0.394596</td>\n",
       "      <td>-0.363171</td>\n",
       "      <td>0.017226</td>\n",
       "      <td>-0.605997</td>\n",
       "      <td>-0.646271</td>\n",
       "      <td>0.133162</td>\n",
       "      <td>0.700449</td>\n",
       "      <td>0.066573</td>\n",
       "      <td>-0.308690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062487</td>\n",
       "      <td>-0.124399</td>\n",
       "      <td>-0.611043</td>\n",
       "      <td>0.026428</td>\n",
       "      <td>0.270664</td>\n",
       "      <td>-0.310393</td>\n",
       "      <td>-0.391263</td>\n",
       "      <td>0.631866</td>\n",
       "      <td>0.689399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>-0.006548</td>\n",
       "      <td>0.250921</td>\n",
       "      <td>-0.315235</td>\n",
       "      <td>-0.377749</td>\n",
       "      <td>-0.533632</td>\n",
       "      <td>-0.221953</td>\n",
       "      <td>0.650980</td>\n",
       "      <td>0.918593</td>\n",
       "      <td>0.315673</td>\n",
       "      <td>-0.316328</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070844</td>\n",
       "      <td>-0.102762</td>\n",
       "      <td>-0.321104</td>\n",
       "      <td>0.476053</td>\n",
       "      <td>-0.009053</td>\n",
       "      <td>-0.083950</td>\n",
       "      <td>-0.336701</td>\n",
       "      <td>0.266582</td>\n",
       "      <td>0.735228</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>-0.002855</td>\n",
       "      <td>-0.073349</td>\n",
       "      <td>-0.005081</td>\n",
       "      <td>-0.168381</td>\n",
       "      <td>-0.036934</td>\n",
       "      <td>-0.749657</td>\n",
       "      <td>0.594881</td>\n",
       "      <td>0.669694</td>\n",
       "      <td>0.125158</td>\n",
       "      <td>-0.411319</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083819</td>\n",
       "      <td>-0.009881</td>\n",
       "      <td>-0.207218</td>\n",
       "      <td>0.481938</td>\n",
       "      <td>0.173691</td>\n",
       "      <td>-0.332396</td>\n",
       "      <td>-0.236408</td>\n",
       "      <td>0.336156</td>\n",
       "      <td>0.636091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -0.210253 -0.088105  0.373194  0.045138 -0.412036  0.115870  0.592757   \n",
       "1      0.086958  0.619067  0.029847 -0.391548 -0.167374 -0.407611  0.808926   \n",
       "2      0.010980 -0.178602  0.077921  0.065314 -0.412028 -0.527477  0.038064   \n",
       "3     -0.088517 -0.471235 -0.667682 -0.059110 -0.605237 -0.350114  0.480405   \n",
       "4      0.146267  0.062430 -0.461665 -0.140508 -0.031926 -0.329088  0.564474   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "19995 -0.538163 -0.293847  0.561924 -0.284176 -0.207451 -0.663484  0.672475   \n",
       "19996 -0.572489  0.238362  0.015432  0.161005 -0.124715 -0.135626  0.207103   \n",
       "19997  0.067305 -0.394596 -0.363171  0.017226 -0.605997 -0.646271  0.133162   \n",
       "19998 -0.006548  0.250921 -0.315235 -0.377749 -0.533632 -0.221953  0.650980   \n",
       "19999 -0.002855 -0.073349 -0.005081 -0.168381 -0.036934 -0.749657  0.594881   \n",
       "\n",
       "              7         8         9  ...       759       760       761  \\\n",
       "0      0.490689  0.245250 -0.675427  ... -0.206053  0.073777 -0.020319   \n",
       "1      0.458772 -0.011550 -0.476740  ... -0.212916 -0.214355 -0.239323   \n",
       "2      0.252827  0.327264 -0.307346  ... -0.057288  0.267838 -0.116387   \n",
       "3      0.203409  0.070762 -0.420400  ... -0.670664 -0.147321 -0.092641   \n",
       "4      0.623633  0.113733 -0.299472  ... -0.186488  0.117171 -0.234970   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "19995  0.591221  0.425575 -0.468169  ... -0.174168 -0.147563 -0.639911   \n",
       "19996  0.489043 -0.259537 -0.259918  ... -0.199020 -0.188011 -0.414878   \n",
       "19997  0.700449  0.066573 -0.308690  ...  0.062487 -0.124399 -0.611043   \n",
       "19998  0.918593  0.315673 -0.316328  ... -0.070844 -0.102762 -0.321104   \n",
       "19999  0.669694  0.125158 -0.411319  ... -0.083819 -0.009881 -0.207218   \n",
       "\n",
       "            762       763       764       765       766       767  toxic  \n",
       "0     -0.036723  0.048516 -0.063282 -0.291686  0.131764  0.505391      0  \n",
       "1      0.307829  0.141115  0.046230 -0.242870  0.519338  0.629348      0  \n",
       "2     -0.286996 -0.009243  0.093149 -0.120039  0.309154  0.658118      0  \n",
       "3      0.043940 -0.066983 -0.083624 -0.187160 -0.075435  0.534236      0  \n",
       "4     -0.034679  0.198808  0.094138 -0.288756  0.299675  0.468383      0  \n",
       "...         ...       ...       ...       ...       ...       ...    ...  \n",
       "19995  0.613554  0.122093 -0.009356 -0.035191  0.724588  0.733067      0  \n",
       "19996  0.677697  0.208532 -0.430124 -0.331739  0.082619  0.545732      0  \n",
       "19997  0.026428  0.270664 -0.310393 -0.391263  0.631866  0.689399      0  \n",
       "19998  0.476053 -0.009053 -0.083950 -0.336701  0.266582  0.735228      1  \n",
       "19999  0.481938  0.173691 -0.332396 -0.236408  0.336156  0.636091      0  \n",
       "\n",
       "[20000 rows x 769 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# используем api \n",
    "base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?' \n",
    "public_key = 'https://disk.yandex.ru/d/8emThoENQmlsTA' \n",
    " \n",
    "# получаем url \n",
    "final_url = base_url + urlencode(dict(public_key=public_key)) \n",
    "response = requests.get(final_url) \n",
    "download_url = response.json()['href'] \n",
    " \n",
    "# загружаем файл в df \n",
    "download_response = requests.get(download_url)\n",
    "df_ed = pd.read_csv(download_url, sep=',')\n",
    "df_ed = df_ed.drop(['Unnamed: 0'], axis=1)\n",
    "df_ed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split( #создаем 4 датасета, два признаков (тест+валидация) и два целевых, \n",
    "    df_ed.drop(columns='toxic'), #для датасетов признаков удаляем целевой\n",
    "    df_ed['toxic'], #для целевого оставляем только целевой\n",
    "    test_size=0.2, #с соотношением 75/25\n",
    "    random_state=RANDOM_STATE, #с заданной опорой для рандома \n",
    "    stratify= df_ed['toxic']) #с заданной стратификацией по целевому признаку"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxpe\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение метрики F1 для модели логистической регрессии с использованием кросс-валидации: 0.6322827525389966\n",
      "CPU times: total: 39.7 s\n",
      "Wall time: 54.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "log_reg = LogisticRegression(solver='lbfgs', max_iter=1000, class_weight= 'balanced') #максимальное количество итераций 1000, \n",
    "log_reg_scores = cross_val_score(log_reg, features_train, target_train.values, scoring='f1', cv=10)\n",
    "log_reg_f1 = log_reg_scores.mean()\n",
    "\n",
    "print(\"Среднее значение метрики F1 для модели логистической регрессии \"\\\n",
    "    \"с использованием кросс-валидации:\", log_reg_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_reg.fit(features_train, target_train) #обучение модели на тренировочных данных\n",
    "# predictions_log_reg = log_reg.predict(features_test) #предсказание целевого признака на основе тренировочных признаков\n",
    "# result_log_reg = f1_score(target_test, predictions_log_reg) #качество методом score на основе предсказанных данных и \n",
    "\n",
    "# result_log_reg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель опорных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение метрики F1 для модели логистической регрессии с использованием кросс-валидации: 0.6834586100172242\n",
      "CPU times: total: 2min 18s\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "svclassifier = SVC(kernel='linear') #максимальное количество итераций 1000, \n",
    "svclassifier_scores = cross_val_score(svclassifier, features_train, target_train.values, scoring='f1', cv=10)\n",
    "svclassifier_f1 = svclassifier_scores.mean()\n",
    "\n",
    "print(\"Среднее значение метрики F1 для модели SVC \"\\\n",
    "    \"с использованием кросс-валидации:\", svclassifier_f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = make_scorer(f1_score, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для модели случайного леса с использованием кросс-валидации: {'n_estimators': 101, 'max_depth': 58}\n",
      "Наибольшее значение метрики F1 для модели случайного леса при лучших гиперпараметрах с использованием кросс-валидации: 0.41778114470409805\n",
      "CPU times: total: 41.2 s\n",
      "Wall time: 12min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "forest = RandomForestClassifier(random_state=RANDOM_STATE) #модель случайного леса\n",
    "parameters = {'n_estimators': range (1, 500), 'max_depth': range (1, 100)} #перебор гиперпараметров\n",
    "#применение метода гридсёрч со встроенной кросс-валидацией к модели леса с перебором указанных параметров\n",
    "\n",
    "randomized_forest = RandomizedSearchCV(forest, n_iter=20, param_distributions= parameters, scoring='f1', n_jobs= -1, cv=5)\n",
    "#обучение модели\n",
    "randomized_forest.fit(features_train, target_train.values)\n",
    "\n",
    "#лучшее значение после перебора параметров \n",
    "best_forest = abs(randomized_forest.best_score_)\n",
    "\n",
    "print(\"Лучшие параметры для модели случайного леса с \"\\\n",
    "    \"использованием кросс-валидации:\", randomized_forest.best_params_)\n",
    "print(\"Наибольшее значение метрики F1 для модели случайного леса \"\\\n",
    "    \"при лучших гиперпараметрах с использованием кросс-валидации:\", best_forest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для модели случайного леса с использованием кросс-валидации: {'n_estimators': 844, 'max_depth': 45, 'learning_rate': 0.5}\n",
      "Наибольшее значение метрики F1 для модели LGBMClassifier при лучших гиперпараметрах с использованием кросс-валидации: 0.6724757980296925\n",
      "CPU times: total: 1min 31s\n",
      "Wall time: 17min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgbm = lgb.LGBMClassifier() #\n",
    "parameters = {'n_estimators': range (1, 1000), 'max_depth': range (1, 100), 'learning_rate': (0.05, 0.5, 0.05)}\n",
    "#применение метода гридсёрч со встроенной кросс-валидацией\n",
    "\n",
    "rand_lgbm = RandomizedSearchCV(lgbm, n_iter=20, param_distributions= parameters, scoring='f1', n_jobs= -1, cv=5)\n",
    "#обучение модели\n",
    "rand_lgbm.fit(features_train, target_train.values)\n",
    "\n",
    "#лучшее значение после перебора параметров \n",
    "best_lgbm = rand_lgbm.best_score_\n",
    "\n",
    "print(\"Лучшие параметры для модели случайного леса с \"\\\n",
    "    \"использованием кросс-валидации:\", rand_lgbm.best_params_)\n",
    "print(\"Наибольшее значение метрики F1 для модели LGBMClassifier \"\\\n",
    "    \"при лучших гиперпараметрах с использованием кросс-валидации:\", best_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_practicum_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "af7472ffbb6f11e94eca2dc243fc9b09d1dc0fb11170c3918ea151f7aad82d25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
