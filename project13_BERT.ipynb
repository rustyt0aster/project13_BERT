{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Привет Максим! Меня зовут Марат, и я буду твоим ревьюером. Спешу сообщить что все ключевые этапы в работе выполнены,  с задачей тебе удалось справиться. По поводу обращения - в IT сфере принято общаться на «ты» :) Но, если привычней на «вы», дай знать. Как ревьюера моя задача помочь тебе в развитии, дав хорошие советы. Я внимательно посмотрю твой код, ознакомлюсь с твоими выводами и оставлю комментарии. Где то могу предложить небольшие исправление в коде, но ненавязчиво. Где потребуются уточнения, я оставлю много наводящих вопросов. Они помогут тебя с поиском верного решения.\n",
    "\n",
    "Все мои комментарии размечены по цветам, для лучшего восприятия. \n",
    "    \n",
    "<div class=\"alert alert-success\">Зеленым цветом и словом «Успех» отмечены особо удачные и элегантные решения, которыми ты можешь гордиться. </div>\n",
    "        \n",
    "<div class=\"alert alert-warning\">Желтым и значком словом «Совет», помечены решения у которых есть альтернативные решения, более оптимальные. Ты можешь найти их сразу и доработать проект, или отложить это на потом, для будущих проектах. Проект будет принят и без их доработки. </div>\n",
    "        \n",
    "<div class=\"alert alert-danger\"> Красным цветом и значком словом «Ошибка» помечу твои решения, на которые стоит обратить внимание прежде всего. После их доработки проект будет принят. </div>\n",
    "        \n",
    "Залог успеха - работа сообща, взаимное уважение и работа в диалоге. Поэтому, помечай свои ответные комментарии на мои реплики заметным цветом или курсивом, так мне будет легче их отслеживать. Пожалуйста, не изменяй и не удаляй мои комментарии. Все это поможет выполнить повторную проверку быстрей.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Установка-библиотек\" data-toc-modified-id=\"Установка-библиотек-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Установка библиотек</a></span></li><li><span><a href=\"#Импорт-библиотек\" data-toc-modified-id=\"Импорт-библиотек-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Импорт библиотек</a></span></li><li><span><a href=\"#Подготовка-констант\" data-toc-modified-id=\"Подготовка-констант-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Подготовка констант</a></span></li><li><span><a href=\"#Знакомство-с-данными\" data-toc-modified-id=\"Знакомство-с-данными-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Знакомство с данными</a></span></li></ul></li><li><span><a href=\"#BERT\" data-toc-modified-id=\"BERT-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>BERT</a></span><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-данных-для-BERT\" data-toc-modified-id=\"Подготовка-данных-для-BERT-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Подготовка данных для BERT</a></span><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-предобученных-модели-и-токенизатора.\" data-toc-modified-id=\"Загрузка-предобученных-модели-и-токенизатора.-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Загрузка предобученных модели и токенизатора.</a></span></li><li><span><a href=\"#Преобразуем-текст\" data-toc-modified-id=\"Преобразуем-текст-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Преобразуем текст</a></span></li><li><span><a href=\"#Фильтруем-данные\" data-toc-modified-id=\"Фильтруем-данные-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Фильтруем данные</a></span></li><li><span><a href=\"#Преобразуем-текст-предобработанных-данных\" data-toc-modified-id=\"Преобразуем-текст-предобработанных-данных-2.1.4\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>Преобразуем текст предобработанных данных</a></span></li><li><span><a href=\"#Преобразование-векторов\" data-toc-modified-id=\"Преобразование-векторов-2.1.5\"><span class=\"toc-item-num\">2.1.5&nbsp;&nbsp;</span>Преобразование векторов</a></span></li><li><span><a href=\"#Преобразование-в-эмбеддинги\" data-toc-modified-id=\"Преобразование-в-эмбеддинги-2.1.6\"><span class=\"toc-item-num\">2.1.6&nbsp;&nbsp;</span>Преобразование в эмбеддинги</a></span></li><li><span><a href=\"#Выгрузка-датасета\" data-toc-modified-id=\"Выгрузка-датасета-2.1.7\"><span class=\"toc-item-num\">2.1.7&nbsp;&nbsp;</span>Выгрузка датасета</a></span></li><li><span><a href=\"#Загрузка-датасета\" data-toc-modified-id=\"Загрузка-датасета-2.1.8\"><span class=\"toc-item-num\">2.1.8&nbsp;&nbsp;</span>Загрузка датасета</a></span></li></ul></li><li><span><a href=\"#Обучение-для-BERT\" data-toc-modified-id=\"Обучение-для-BERT-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Обучение для BERT</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ограничение-датасета\" data-toc-modified-id=\"Ограничение-датасета-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Ограничение датасета</a></span></li><li><span><a href=\"#Разбиение-данных\" data-toc-modified-id=\"Разбиение-данных-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Разбиение данных</a></span></li><li><span><a href=\"#Модель-логистической-регрессии\" data-toc-modified-id=\"Модель-логистической-регрессии-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>Модель логистической регрессии</a></span></li><li><span><a href=\"#Модель-опорных-векторов\" data-toc-modified-id=\"Модель-опорных-векторов-2.2.4\"><span class=\"toc-item-num\">2.2.4&nbsp;&nbsp;</span>Модель опорных векторов</a></span></li><li><span><a href=\"#Модель-случайного-леса\" data-toc-modified-id=\"Модель-случайного-леса-2.2.5\"><span class=\"toc-item-num\">2.2.5&nbsp;&nbsp;</span>Модель случайного леса</a></span></li><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-2.2.6\"><span class=\"toc-item-num\">2.2.6&nbsp;&nbsp;</span>LightGBM</a></span></li></ul></li><li><span><a href=\"#Выводы-по-методу-BERT\" data-toc-modified-id=\"Выводы-по-методу-BERT-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Выводы по методу BERT</a></span></li></ul></li><li><span><a href=\"#TF-IDF\" data-toc-modified-id=\"TF-IDF-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>TF-IDF</a></span><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Подгрузка-необходимых-данных\" data-toc-modified-id=\"Подгрузка-необходимых-данных-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Подгрузка необходимых данных</a></span></li><li><span><a href=\"#Функция-очистки-текста\" data-toc-modified-id=\"Функция-очистки-текста-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Функция очистки текста</a></span></li><li><span><a href=\"#Лемматизатор\" data-toc-modified-id=\"Лемматизатор-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Лемматизатор</a></span></li><li><span><a href=\"#Выгрузка-датасета\" data-toc-modified-id=\"Выгрузка-датасета-3.1.4\"><span class=\"toc-item-num\">3.1.4&nbsp;&nbsp;</span>Выгрузка датасета</a></span></li><li><span><a href=\"#Загрузка-лемматизированного-датасета\" data-toc-modified-id=\"Загрузка-лемматизированного-датасета-3.1.5\"><span class=\"toc-item-num\">3.1.5&nbsp;&nbsp;</span>Загрузка лемматизированного датасета</a></span></li><li><span><a href=\"#Облако-слов\" data-toc-modified-id=\"Облако-слов-3.1.6\"><span class=\"toc-item-num\">3.1.6&nbsp;&nbsp;</span>Облако слов</a></span></li></ul></li><li><span><a href=\"#Обучение-для-TF-IDF\" data-toc-modified-id=\"Обучение-для-TF-IDF-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Обучение для TF-IDF</a></span><ul class=\"toc-item\"><li><span><a href=\"#Разбиение-данных\" data-toc-modified-id=\"Разбиение-данных-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Разбиение данных</a></span></li><li><span><a href=\"#Вводим-стоп-слова\" data-toc-modified-id=\"Вводим-стоп-слова-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Вводим стоп слова</a></span></li><li><span><a href=\"#Мешки-слов\" data-toc-modified-id=\"Мешки-слов-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Мешки слов</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Модель-логистической-регрессии\" data-toc-modified-id=\"Модель-логистической-регрессии-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Модель логистической регрессии</a></span></li><li><span><a href=\"#Модель-опорных-векторов\" data-toc-modified-id=\"Модель-опорных-векторов-3.3.2\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>Модель опорных векторов</a></span></li><li><span><a href=\"#Модель-случайного-леса\" data-toc-modified-id=\"Модель-случайного-леса-3.3.3\"><span class=\"toc-item-num\">3.3.3&nbsp;&nbsp;</span>Модель случайного леса</a></span></li><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-3.3.4\"><span class=\"toc-item-num\">3.3.4&nbsp;&nbsp;</span>LightGBM</a></span></li></ul></li><li><span><a href=\"#Выводы-по-методу-TF-IDF\" data-toc-modified-id=\"Выводы-по-методу-TF-IDF-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Выводы по методу TF-IDF</a></span></li><li><span><a href=\"#Проверяем-лучшую-модель\" data-toc-modified-id=\"Проверяем-лучшую-модель-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Проверяем лучшую модель</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "Вступление в работу очень важно, так человек, который смотрит твой проект (и на работе в том числе) будет сразу введен в курс дела. \n",
    "     \n",
    "    \n",
    " \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет: \n",
    "   \n",
    "Вопросик, при желании можешь ответить )\n",
    "    \n",
    "    \n",
    "- а почему по твоему была выбрана метрика f1? \n",
    "    \n",
    "    \n",
    "- а что если бы нам было нужно найти как можно больше токсичных комментариев, в этом случаи на какую метрику мы бы ориентировались?\n",
    "    \n",
    "    \n",
    "- каким образом мы можем изменить функцию ошибки в модели, чтобы она максимизировала интересующую нас метрику (accuracy, f1, precision, roc-auc итп)?    \n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарий студента:</b> Марат, привет, ниже попытался ответить на вопросы, но понял, что не знаю точный ответ на второй и совсем не знаю на третий. Попрошу тебя самого ответить на них, было бы полезно понять это.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Для оценки токсичности комментариев используется метрика `F1`, так как имеется сильный дисбаланс классов. `Accuracy` является метрикой, которая будет работать только при сбалансированнных классах.\n",
    "\n",
    "`F1` метрика включает в себя сразу две метрики: `precision` (доля истинноположительных из набора всех положительных, в т.ч. отрицательноположительных) и `recall` (доля истинноположительных из всего набора положительного класса, т.е. включая ложноотрицательные предсказания). Таким образом, увеличение метрики `F1` влечет за собой:\n",
    "\n",
    "- либо уменьшение доли ложноположительных предсказаний (по метрике `precision`),\n",
    "- либо уменьшение доли ложноотрицательных предсказаний (по метрике `recall`),\n",
    "- либо оба варианта сразу.\n",
    "\n",
    "2. Тут имеется в виду `precision`? Не столько важно, какая будет метрика, важно, чтобы было, грубо говоря, отобрано как можно больше комментариев класса положительный, даже если это будет ложноположительный?\n",
    "\n",
    "\n",
    "3. Не знаю ответ, либо не понял вопрос."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Установка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nltk # доустанавливаем необходимые библиотеки\n",
    "# pip install pywsd\n",
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers as ppb # pytorch transformers\n",
    "import requests #получить финальный url я.диска\n",
    "import lightgbm as lgb\n",
    "import nltk\n",
    "import re\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from pandas.core.common import flatten\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "from tqdm import notebook\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import urlencode # для задания адреса таблицы в я.диске\n",
    "from pywsd.utils import lemmatize_sentence #лемматизатор\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Совет:\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "- есть рекомендации PEP-8 при написании кода, в том числе и для импортов. Если интересно можешь почитать [тут](https://pythonworld.ru/osnovy/pep-8-rukovodstvo-po-napisaniyu-koda-na-python.html). Есть что поправить \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарий студента:</b> Сделано.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка констант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 100\n",
    "max_len = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Знакомство с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159292, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv', index_col=0)\n",
    "except:\n",
    "    df = pd.read_csv(r'C:\\Users\\maxpe\\Downloads\\Practicum\\Projects\\datasets\\toxic_comments.csv', index_col=0)\n",
    "display(df.shape);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Ошибка:\n",
    "    \n",
    "Мне пришлось подправить твой код чтобы запустилось. Для некоторых особо строгих ревьюеров это основание завернуть работу без проверки, так что будь внимательней в следующий раз \n",
    "    \n",
    "  \n",
    "\tdf = pd.read_csv('/datasets/toxic_comments.csv')    \n",
    "\n",
    "    \n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "Если не знаешь - чтобы не было столбца  `Unnamed: 0` при чтении файла можно так:\n",
    "\n",
    "\n",
    "    pd.read_csv(..., index_col=0)\n",
    "\n",
    "    \n",
    "(`Unnamed: 0` появляется при не совсем корректном сохранении файла)    \n",
    "\n",
    "<div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарий студента:</b> Прошу прощения, исправил</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5673</th>\n",
       "      <td>Phuu. That's warm. How do you cope?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26677</th>\n",
       "      <td>When using the  tag on an article, you need to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51032</th>\n",
       "      <td>\"\\n\\n RE: I Think This Should Be Deleted \\nTo ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60335</th>\n",
       "      <td>\"\\n\\n Citation quality \\n\\nFirst thing, I kiss...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129851</th>\n",
       "      <td>Jim1138, there was no edit warring. You kept a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89330</th>\n",
       "      <td>Thank you for your response. I have since bloc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9004</th>\n",
       "      <td>You jumped the gun here, you should not really...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "5673                  Phuu. That's warm. How do you cope?      0\n",
       "26677   When using the  tag on an article, you need to...      0\n",
       "51032   \"\\n\\n RE: I Think This Should Be Deleted \\nTo ...      0\n",
       "60335   \"\\n\\n Citation quality \\n\\nFirst thing, I kiss...      0\n",
       "129851  Jim1138, there was no edit warring. You kept a...      0\n",
       "89330   Thank you for your response. I have since bloc...      0\n",
       "9004    You jumped the gun here, you should not really...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет не содержит пустых строк, состоит из 2 столбцов, один из которых будет преобразован в признаки (`text`), а `toxic` - целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1kAAAHjCAYAAADRz9UJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAA9hAAAPYQGoP6dpAABRxUlEQVR4nO3dfXyP9f////tmdmJsw2yzLKacRlaEISfZ2yp5t968c/bO0kLaipCQNkoppVBOkjJ94p10IlHLQlasYbNCSDlPc5K2F/M2Ozl+f/i9ju9eds6xptyul8vrctmO5+N4Hs/jdXJs99dx5mQYhiEAAAAAgCWcq3oAAAAAAPB3QsgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGygEry9ddfy8nJqdhHjRo11LBhQ0VERGjZsmXKy8ur6uECAADAIk6GYRhVPQjg7+jrr79Wjx49ylV72223adWqVQoICKjkUQEAAKCysScL+BOMHDlSO3bsMB/Jycl6/fXX1ahRI0nS1q1bde+994rvPAAAAP76XKp6AMC1wM/PT61atXKY1rFjRw0ePFjt27fXzz//rC1btmj16tXq06dPFY0SAAAAVmBPFlCFateurYkTJ5q/JyQkVOFoAAAAYAVCFlDF2rdvb/586NAhh7aCggKtX79e48aNU+fOneXr66vq1avLx8dHISEhGjdunA4fPlyu5RQUFOi///2v+vbtq+uvv14eHh7y8PBQ06ZNNXjwYH344YfKzc11mGfKlCklXryjpMeDDz5YZNnx8fFm+8GDB5WTk6NXXnlFt956q7y9veXl5aUOHTpo3rx5ys/PL3Nd8vPztWTJEt1zzz0KDAyUm5ub6tatqy5duujVV1/V//73v3I9J927dy/XOk2ZMqXMvjZs2KDIyEg1btxYNWrUkJeXl1q3bq0nn3xSx44dK9d4GjVqVK7xxMfHl9jH+fPn9cYbb6hnz54KCAiQq6ur/Pz8FBYWprfffrvUi6zYl1/ca1hY4Yu6fP3110Xa7c9r9+7dS+zjq6++clin4vqxs+r1LklZ633u3Dl16dJFTk5OcnNz09q1a0vsq7yfmZKem507d2ratGkKDw9XgwYN5Obmppo1a6pJkyaKjIzUd999V+712rRpkx5++GE1a9ZMXl5ecnV1VYMGDXTPPfdo7ty5yszMLHHegwcP6qmnnlLbtm1Vt25dVa9eXb6+vrr99ts1ZcoU7d+/v8R5d+zYoeHDh6tJkyaqUaOGatWqpZtuuklPPPGEDh48WOoyS7tYUNOmTRUVFaX09PRyPwdlKe92raT355Vsoy9n+2p/XOq7777T5MmT1b17d/Nz7+XlpZYtW2rkyJH68ccfy/2cfP755/rPf/6jxo0by9PTU+7u7goODlbfvn0VHx+vc+fOlThvWlqaHnnkETVr1kw1a9aUp6enmjVrppEjR+qnn34qUl/aa17R7eBvv/2mefPmqV+/fmrSpIk8PT3l5uam6667Tvfee6+WL1+ugoKCcj8PwBUzAFSKDRs2GJIMSUZcXFyJdXv27DHr7rzzToe2uLg4s62kR40aNYyPP/641LEcOHDACAkJKbOvDRs2VHj5lz4iIyOLLH/x4sVme1pamtG2bdsS5+/atatx5syZEtfl0KFDRps2bUodw4033mjs3bu31OfEMAyjW7du5Vqn0l6///3vf8aAAQNKnd/T09NYtWpVmeNp2LBhucazePHiYudPT08vs4/bbrvNyMjIKHX5xb2GhRV+b1/6njGM//e8duvWrdj58/LyjFatWpX63rOz8vUuSWnrnZOTY/Tq1cuQZFSrVs348MMPS+2rvJ+Z4p6bws9raY8JEyaUOoZz584ZAwcOvOz39csvv2xUr169wuM3DMN44YUXDGdn5xLnc3NzM5YsWVLsvAcOHCjX+lerVq3EPiqqvNu1kt6fV7KNvpztq/1RWOHta2nP2dy5c0t9Lk6dOmX07NnzsrY/+fn5xhNPPGE4OTmVOJ+Li4vx5ptvOsxX3te8rHHk5eWV+r6zP/7xj3+U+vcFsBLnZAFVbMeOHebPgYGBDm15eXmqX7++7rvvPoWGhqpx48Zyd3fXkSNHtHnzZs2bN09nz57VoEGDlJaWphYtWhTp//jx4+rcubO5N+WOO+5QZGSkmjdvLicnJx04cEDr16/XihUryj3O4oSHh5drj82IESOUmpqq/v37KzIyUn5+fvrpp5/02muvaevWrUpKStIDDzygTz75pMi8v//+u7p06aIjR47Izc1Nw4YNU7du3dSoUSOdPXtWa9eu1ezZs/Xzzz/rrrvuUlpamry9vcscU7t27bR48eIi01u3bl3qfIZhqF+/flqzZo0kqU+fPrr//vvVuHFjOTs7a8uWLZo5c6YOHz6sfv36adOmTWrXrl2Z47n33ns1bdo0h2nHjh1TeHh4ifP8/PPP6tatm7KysuTl5aXo6Gi1b99eQUFB+v3337Vq1Sq9+eab5kVWvvnmG1WvXr3MsVSGRYsWaefOnWXWVdbrXV75+fkaNGiQ1q5dKycnJ7311lvq27dvuecv7jMzdOhQbdu2rdj6vLw8eXp6qnfv3rrjjjvUvHlzeXl56cSJE9q1a5fmzJmjQ4cO6cUXX1TTpk01dOjQIn0UFBTo3nvvVWJioiSpSZMmevTRR9WuXTvVqFFDv/32mzZv3qwPPvig2DE899xzio2NlST5+Pjo0UcfVY8ePVS3bl1lZmYqLS1NH3/8cbF7U+bNm6dJkyZJkurVq6ennnpKnTt3Vn5+vr766iu9/PLLys7O1oMPPihfX1/dfffdJT5306ZN07333ivp4ufs+PHjWrNmjd544w3l5eVp5MiRuueee1SnTp0S+6iIkSNH6tFHH3WYtnXrVj300EOlzncl2+hHH31U/fr1K9LnvHnzNH/+fEllb3ftY6hdu7buvfdede3a1dyLc+zYMaWlpWnOnDk6deqUYmJi1Lx5c91xxx1F+jh37px69OhhLq9t27YaPny4WrVqJTc3Nx05ckRJSUlavnx5sWN47LHHNG/ePElS165d9eCDD5p79b///nvNmjVLu3bt0ogRIxQQEKB//vOfkqTrrruu2HUsvL0r/F4orEGDBubPxv9/0ag77rhDd911l1q3bq169erpzJkz2r9/v9566y0lJycrMTFR0dHRWrJkSZnPK3DFqjjkAX9b5dmTlZuba3Ts2NGse/fddx3aDxw4YFy4cKHEZRw5csS47rrrDEnGf/7zn2Jr7rvvPrP/l156qcS+zpw5Y5w+fdphWuFvWstS2t6AS79pfeGFF4rU5ObmGuHh4WbNmjVritQMGjTIkGQ0bNjQ2L9/f7HjSEtLMzw9PQ1JxqRJk0odc5cuXUr9Vr6s12/hwoWGJKN69erGF198UWzN6dOnjZtuusmQZHTu3LnU8dhfywcffLBIW+FvfIv7JrlTp06GJOOWW24xTp48WWz/X3zxhflt78KFC4u0/xl7srKysgw/Pz9DksMezeL6sfr1Lklx611QUGA89NBD5vhee+21cvX19NNPl/qZKe25OXnypPHHH3+U2HdOTo7xj3/8w3xO8vLyitTMnj3bXP59991nnD9/vti+8vPzjaNHjzpMS0tLM98fTZs2NY4cOVLiWA4fPuzw+4kTJ4waNWoYkozAwMAi7fb+7a/VddddV2TbVtZ73DAMY9asWWbNp59+WuL4yiMvL6/Uz3hZ73P7mK90G32pimx3DcMwjh49amRnZ5fYnpmZadx8882GJKNLly7F1jzxxBPmMqOjo42CgoJi63JycorsCV+7dq0576JFi4qd73//+59xxx13mO/d3NzcUtepPO+FwgoKCox9+/aVWhMbG2tIMpycnIyffvqpzD6BK8U5WUAVyM7O1saNG/WPf/zDPMeiYcOGuv/++x3qGjVqVOrehgYNGujJJ5+UJK1atarIJeD37t2rlStXSpIiIiI0fvz4EvuqWbOmateufTmrUyE333yzJkyYUGS6i4uLFi1aZK6v/VtRu4MHD5rfor7xxhsKDg4utv9bbrlF0dHRklTquUvSxfOX7MuuKMMw9NJLL0mSHn/8cd15553F1tWuXVsvv/yypIvnyOzbt6/EPu3nxFV0D9M333yjzZs3S5KWLFkiX1/fYuvuvPNO85vzsp6byvL888/rxIkTqlu3riZPnlxiXWW83hUxduxYvfPOO5KkuLg4jR49ulzzXe5rKEm+vr7y8fEpsd3V1dV8Lx06dKjIuUkFBQVme4MGDfTuu+/Kzc2t2L6cnZ113XXXOUx7+eWXVVBQICcnJ73//vsOewouFRQU5PD74sWLzXN1Xn311SLt0sXXyn6hn19//dXcNlVE4XPZrvQm7vbPv3R52wDpyrfRVrjuuutUo0aNEtu9vb317LPPSpK+/fZb/f777w7tmZmZevPNNyVd3IM1e/bsYvdUShffg/7+/g7TXnzxRUlS3759FRUVVex87u7ueuONNyRdfO9u2LChHGtWfk5OTrrxxhtLrYmNjZWvr68Mw9CqVassXT5QHEIW8CeYOnWqwwm7NWvWVPfu3c2Tqf38/LRy5coS/yGys9lsOnDggHbt2qWdO3dq586d5h9Xe1tha9asMf+oP/HEE9av2GWIjIws8Q94gwYN1KtXL0kXL65Q+CIYa9asUX5+vmrUqKG77rqr1GV07dpV0sVDTkq7MEhOTo4klfoPSkl+/PFH/fLLL5JU7CE/xY1HkpKTk0usu3DhgqSL/8hUhP0fhmbNmpV5iKN9LFu3br3if1Irav/+/Zo9e7aki5+J0gJFZbze5fXss8/qtddekySNGjWqXBc+sbvc17A4OTk5Onz4sH788Ufz8174n/Tvv//eoT49PV1Hjx6VJA0bNkw1a9Ys97IKCgr0xRdfSLoYZG655ZYKjfWrr76SdPEQw3/9618l1j388MNF5qmIL7/80vz5pptuqvD8hdk//9LlbQOKU9FtdGXIzs7WwYMHHcZQOAhe+r5Zv369GZAff/xxVatWrdzLstls5t+xsraDLVq0ML8AKm07aIWCggIdO3ZMe/fuNZ+D3bt3m18cXPocAJWBc7KAKhQcHKx+/fpp3Lhx8vPzK7bm0KFDeuWVV/TZZ58VufrgpU6dOqXGjRubv2/fvl3SxW/VO3bsaN3Ar8Btt91Wanv79u21Zs0aZWdna//+/WrSpIkkmeexnDt3rkLfOmdkZOj6668vtu3UqVOSJA8Pj3L3Z1f4vJrQ0NAKjac4hmHIZrNJuvit7+WMZe/evSUG2Evl5ubq9OnTxb7vMjMzSz1n6nL/URw/frxycnLUokULjRgxQt9++22JtZXxepfH66+/rri4OEkX9/YMHz68QvPbr9hX0dfQLjs7W3PmzNH777+vXbt2lXq1Tfv7187+eZek22+/vULLPXDggDn2is4ryXy/3HrrraXu2fH391ejRo108ODBUt9jv/76q9luGIYyMjL06aefasGCBZIuflnTrFmzCo+zsMLP3+VsA+yuZBttlVOnTunVV1/VRx99pH379pW6x8zK98327dvNK/YNHDhQAwcOLNd8JW0Hr4RhGFq6dKnefvttpaSklHrV0UufA6AyELKAP0Hhk6qdnJzk7u4uX1/fMk/S/+KLL9SvX79SL5lb2KV/VOx/SOrUqWPJN+tWKClM2hU+FOX06dPmzydOnLis5ZX03OXn55t9Xnr4S3lYPZ7MzEzzn5V69epV6Vg+/fRTffrpp5fVZ0m++eYbffTRR5KkmTNnlhmcrF6n8tiwYYPeffddSRc/pwUFBXrooYe0adOmcn+7b3/PVvQ1lC4eInnHHXeUO8SW9HmXpPr161do2Vcyr/T/1rusz7ckBQQE6ODBgw6f70tNnjy52MNJ/fz8NG3aNIc9Yper8IV6LmcbIF35NtoKqampCg8PL3IYYHnHcCWvfVV8Totz/vx5/etf/zL3xpalMl4H4FKELOBP4Ofnp1atWlVonlOnTmnQoEE6d+6catasqXHjxik8PFw33HCDvL29zdC0fv169ezZU5Iq5Xh/q5V3T8ul7N/o+/r6Vuh4/pLO5Tly5IjZZ6NGjS57PJL02WeflbuPkv4JLfzNbkX/4bOPpU2bNnrvvffKPd+l5+RUFsMwzMNVw8PDyzz8T7L+9S4P+6GGYWFheuihhzRo0CClpKRo5syZpZ7PWJj9dbycf9ofeOABHThwQE5OTho6dKgGDBigFi1aqF69enJ1dTWDnz3wXY2f98v9fJfXiRMnNGHCBLm6uioyMvKK+ip8z67L2QZcDdvoCxcu6P7779fvv/+u6tWr67HHHtO9996rpk2bqnbt2uYh6Pv379cNN9xg+RgKbwfffPNNderUqVzzWX3+7/PPP28GrG7duik6Olq33nqrAgIC5OHhIWfni2fHdO3aVd98881V+dnB3w8hC7hKffjhh+bhO5988onCwsKKrSvt22D78e+nT5/WhQsXroq9WcePH1fTpk1LbbcrfHnmunXrSpLOnDmjFi1aVOi8geKkpaWZPzdv3rzC89vHI108D6WiIfpShS+IYf9nqKJjOXv27BWPQ7p4KFZpF5H4+uuv1aNHj3L39+677yo1NVXVqlXTq6++Wq55rH69yys0NFQrV66Up6enPv30Uy1fvlyxsbHq06dPsbdIuJT9dazoa7hnzx7z8MlJkyYVuYS/XXk+79LFG7NW5H196bwVVadOHf32228On9+S2INoaZdfX7x4scPNoTMzM7Vnzx5Nnz5dq1at0oMPPqhatWqVev5XWezbAGdnZ/Ow5IqwYht9pdavX2/eGHrevHkl7uGryPumIl9UFN4O1qhRw5LtT0UZhqFFixZJuni44/r1681QdanKfC2AS3HhC+AqtWvXLkkX/xEp6Y+3pBLvuSNdPD9Cunj+TWWfaFxeW7duLVd7jRo1HM5dsJ+In5OTU+o6l5f9+XB2di73t6+FFb4wwKZNm654PIXPi7j55psvayz79++vlHMdrkR2drZ576QRI0aoZcuW5ZrP6te7PJo3b641a9bI09NT0sWrGvr5+SknJ0dDhw4t9fwo6eK5OX/88Yeki3sVK8L+eZek/v37l1hXns+7JCUlJVVo+cHBweaFSCo6ryTzn+u0tLRSL6hy4sQJ87ylivxD7uPjo44dO+qjjz4yv6SZPn16hcdZmH0b0KZNG9WqVavC81uxjb5SVf2+CQkJMfdeWrEdvBynT582t3v//ve/SwxYZ8+e1d69e//MoeEaR8gCrlL2f1TOnz9vnqtzqXPnzun//u//Suyjd+/e5h/AWbNmWT7Gy/F///d/JR6q8euvv2rt2rWSLl7hrPDeiz59+li6Lh9++KEkqUOHDqVe5a4kt956q3mlqoULFzpcDvpy2A91CQkJqfANde039jQMw7x639XipZde0rFjx+Tt7a2pU6eWez6rX+/y6NChg8NhTL6+vuatBOyHDZam8Pkg3bp1q9CyCweT7OzsEuvsF34oTps2bcxLpy9atEhnz54t9/KdnZ3Vu3dvSdLGjRsdQn952ENGZmamPv744xLr3n77bfPzX1owKYmLi4t5VcHdu3dXeH67AwcOmMGjpNsvlMWKbfSVKs/7pqCgQG+99VaJffTo0cP8YuH1118v88uEwurVq2deVGnZsmU6efJkuee1Snk/O4sWLfrTr6iKaxshC7hK2Q9fOXfunD744IMi7fn5+Xr44YcdTt6+VNOmTXXfffdJklauXGneQ6c42dnZ5rfwlSk9Pb3YceTl5WnYsGHmJbBHjhzp0N6sWTP9+9//liS9//77ZR52duDAAf33v/8ttu3dd981z8cYNmxYRVdB0sV/Su17aPbv368hQ4Y4XBL6UjabzbxPzKUWLVqklJQUSSr31bkK69Wrl9q3by/p4r2Oinu/FLZjxw599tlnFV5ORR07dkyvvPKKJOmZZ54p8f5dxbHy9b4Sffv2Ne9fFxsbW+I/9ocPH9Zzzz0n6eKlqiu6J6vw4WolHao5f/78Ui9I4uzsbN6T6ejRoxoyZIj5ebqU/RLXhY0bN07Ozs4yDEMDBgwwLwdfnEvbhg4dal6qfOzYsfr111+LzPP999/rhRdekHTxfMCIiIgS+y9JZmameW/By9n7ZGd/rZycnEq8t1NZrNhGX6nyvG8mTpzocHj0pXx8fDRixAhJFy+iMXr06BK/CMvNzS1ysQv7BUpsNpv69etnHkJZnJycHM2dO/eKv5QqrF69euYXZf/973+L3Q5v3bpVzzzzjGXLBMrlz7zzMXAt2bBhg3nH+ri4uArPf+TIEcPNzc2QZLi7uxtPPfWU8dVXXxlbt2414uPjjbZt2xqSjM6dO5vL2bBhQ5F+MjIyjMDAQLPmjjvuMN59911jy5YtxtatW40VK1YYjz76qFGnTp0i88fFxZnzlaVhw4aGJCMyMrJI2+LFi81+2rVrZ0gyBg4caHzxxRdGamqq8f777xvt27c3a/r06VPsMn7//XejcePGZl3Xrl2NRYsWGcnJyUZaWpqRmJhovPLKK0ZYWJjh7Oxs9O3b12H+/fv3G2+++abh6elpSDJq1aplbN261dixY0exD/tyRo4caezYscM4fvy4Q38FBQXGfffdZ9bdcMMNxowZM4yvv/7a2L59u7Fx40bjzTffNAYOHGh4enoadevWdZh/1apVxoABAwwnJydDktG4cWPj3Llzxa77gQMHzOUsXry4SPvPP/9s1KlTx+E5fO+994yUlBRj27Ztxueff248//zzRseOHQ1JxtixYyv0GhZW+L1d3HuuW7duZrv9ecnJyalwP1f6epdXWet98uRJw8/Pz5BkdOjQwcjLyzPbdu/ebUydOtWoW7euOc6EhIQSl2V/brp16+YwvaCgwGjVqpXZx/3332989tlnxrZt24yVK1ca/fr1K/J5L267kp+fb/zjH/8wa5o2bWrMmjXL+Pbbb420tDTj888/N2JjY40mTZoUO/9zzz1nzuvj42M8/fTTxldffWVs377d2LBhg/Haa68Zt99+u9G9e/ci886dO9ec19/f33jttdeMlJQUY9OmTcbUqVONmjVrGpIMJycnY82aNUXmL/wenzZtmsNn8dtvvzUWLlxotGzZ0qyJiYkp8XkuyY4dO4xRo0aZfYSGhpb4+X/nnXfMunfeecfYsWOHcfbsWbMvq7bRl6rIdvfs2bPme7NatWrGiBEjjISEBGPbtm3G+++/b/Ts2bPIGIrbfmRnZxutW7c2a9q2bWssXLjQSE5ONlJTU41PP/3UGDdunHHdddcVO3/h5zQgIMCYMmWK+b759ttvjfj4eCMqKsqoXbu2Ick4c+ZMqetV1vbuUtHR0Q5/Y5YtW2Zs3brV+Oqrr4wxY8YY7u7uhq+vr9G0adNiP39AZSBkAZXkSkOWYRjGO++8Yzg7Ozv8w1r40b9/f+Orr74q8w/4L7/84vAPXEmPPyNkpaWlGbfcckuJY+jcubNhs9lKXM5vv/1m3H777WWuiyRj6NChDvNe+s9/RR/FvY4XLlwwRo4caQal0h7BwcEO8xZua9GihfHLL7+UuN7l+adj79695XqdJRlTp04tMn9lhayPP/74svoxjCt7vcurPOu9YsUKczkvvviiOT0yMtKc7urqasTHx5e6rJJClmEYxvbt281/Qot7tG7d2jh27FiZ25Xs7GwzlFX0/WwYhvH8888bLi4upc5b0j+pzz//fKnbLDc3N2PJkiXFzlv4PV7Wo1OnTkZWVlapz3VxruTzX9z71KptdGEV2e4ahmEkJCQY7u7uJY6he/fuxs6dO8vcfpw8edLo2rVrmc9BcfMXFBQYU6dOLfN9I8nw9PQs8csku4qGrMzMTCMkJKTEZdapU8fYuHFjqZ8/wGocLghcxYYOHapvvvlGERERqlevnqpXr6769evrzjvv1PLly/X++++X66prjRs3Vnp6uuLj49W7d2/Vr19f1atXl4eHh5o2baohQ4bo008/vaybkFZU7dq1tXnzZk2fPl0hISGqVauWatasqdtuu02vv/66Nm7cWOphQAEBAUpKStLq1as1ePBgNW7cWDVq1FD16tVVr149derUSWPHjtXGjRv1zjvvVPr6VK9eXfPmzdP333+vxx57TK1bt5a3t7eqVasmb29vhYSEKCoqSh9++GGRQ80CAgJ09913a8mSJUpPT7/im5Q2bdpU6enpWrZsmfr27avrr79eHh4ecnV1Vf369dW9e3dNnjxZqampio2NvaJllVe3bt3MQ1Yvx9Xyevfr1888bDAuLs58LWvUqKH27dtr4sSJ+uWXX67osuIhISFKT0/XI488ooYNG6p69eqqU6eO2rdvr1deeUVbtmwp132MatSooRUrVmj9+vV64IEHFBwcbL4PgoKC1KdPH7355psaO3ZssfNPmjRJP/74o0aPHq1WrVrJy8tLLi4uqlevnrp166Zp06aVeJ7RpEmTtH37dg0bNkw33HCDPDw85OnpqRYtWmjUqFHas2ePhgwZUuHnxv4evuuuu7R48WIlJSXJy8urwv1Yzapt9JUIDw/Xtm3b9J///EeBgYHmZ6Nbt25auHCh1q1bZ55zVRpfX19t3LhRH3/8sfr166cGDRrIzc1N7u7uaty4sf79739r6dKlxR7S7OTkpNjYWP30008aP3682rVrpzp16qhatWqqVauWWrZsqcGDB2vJkiX67bffrujmz8Xx9vbWpk2b9Nxzz6l169Zyd3dXzZo11aJFC40bN07ff/+9unbtaukygbI4GQY3CwBQueLj4zV06FBJF8+duZx70lihe/fu2rhxozZs2KDu3buXe74pU6Zo6tSpiouL05QpUyptfAAql/1iKhX91+dytx0Arl3syQIAAAAACxGyAAAAAMBCLlU9AAD4swQHB+vUqVPlOj+hMD8/P910003y8/OrpJEB+DPY77FVUZe77QBw7eKcLACV7mo5JwsAAODPwOGCAAAAAGAh9mQBAAAAgIU4J6sUBQUFOnbsmGrVqmVe9hUAAADAtccwDJ05c0aBgYFydi79gEBCVimOHTumoKCgqh4GAAAAgKvEkSNH1KBBg1JrCFmlqFWrlqSLT+TVcGd5AAAAAFXDZrMpKCjIzAilIWSVwn6IoJeXFyELAAAAQLlOI+LqggAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFnKp6gEAZZk6dWpVDwGocnFxcVU9BAAAUE7syQIAAAAACxGyAAAAAMBChCwAAAAAsFCFQ1ZSUpL69OmjwMBAOTk5aeXKlSXWPvLII3JyctKsWbMcpp8+fVqDBw+Wl5eXfHx8FBUVpbNnzzrU/PDDD7r99tvl7u6uoKAgzZgxo0j/K1asUPPmzeXu7q7WrVvr888/d2g3DEOxsbGqX7++PDw8FBYWpn379lV0lQEAAACg3CocsrKzs9WmTRvNnTu31LpPPvlE3333nQIDA4u0DR48WLt27VJiYqJWr16tpKQkDR8+3Gy32Wzq1auXGjZsqNTUVL388suaMmWKFi5caNZs3rxZAwcOVFRUlLZv366IiAhFRERo586dZs2MGTM0Z84cLViwQCkpKfL09FR4eLjOnz9f0dUGAAAAgHJxMgzDuOyZnZz0ySefKCIiwmH6r7/+qg4dOujLL79U7969NXr0aI0ePVqStHv3brVs2VJbt25Vu3btJEkJCQm6++67dfToUQUGBmr+/Pl6+umnlZGRIVdXV0nShAkTtHLlSu3Zs0eS1L9/f2VnZ2v16tXmcjt27KiQkBAtWLBAhmEoMDBQY8eO1bhx4yRJWVlZ8vf3V3x8vAYMGFDm+tlsNnl7eysrK0teXl6X+zThCnF1QYCrCwIAUNUqkg0sPyeroKBADzzwgJ588knddNNNRdqTk5Pl4+NjBixJCgsLk7Ozs1JSUsyarl27mgFLksLDw7V371798ccfZk1YWJhD3+Hh4UpOTpYkHThwQBkZGQ413t7e6tChg1lzqZycHNlsNocHAAAAAFSE5SHrpZdekouLix5//PFi2zMyMuTn5+cwzcXFRXXq1FFGRoZZ4+/v71Bj/72smsLthecrruZS06dPl7e3t/kICgoqc30BAAAAoDBLQ1Zqaqpmz56t+Ph4OTk5Wdn1n2LixInKysoyH0eOHKnqIQEAAAD4i7E0ZH3zzTc6ceKErr/+erm4uMjFxUWHDh3S2LFj1ahRI0lSQECATpw44TBfXl6eTp8+rYCAALPm+PHjDjX238uqKdxeeL7iai7l5uYmLy8vhwcAAAAAVISlIeuBBx7QDz/8oPT0dPMRGBioJ598Ul9++aUkKTQ0VJmZmUpNTTXnW79+vQoKCtShQwezJikpSbm5uWZNYmKimjVrptq1a5s169atc1h+YmKiQkNDJUnBwcEKCAhwqLHZbEpJSTFrAAAAAMBqLhWd4ezZs/r555/N3w8cOKD09HTVqVNH119/verWretQX716dQUEBKhZs2aSpBYtWujOO+/UsGHDtGDBAuXm5iomJkYDBgwwL/c+aNAgTZ06VVFRUXrqqae0c+dOzZ49W6+99prZ76hRo9StWzfNnDlTvXv31vvvv69t27aZl3l3cnLS6NGjNW3aNDVp0kTBwcF65plnFBgYWORqiAAAAABglQqHrG3btqlHjx7m72PGjJEkRUZGKj4+vlx9LF26VDExMerZs6ecnZ3Vt29fzZkzx2z39vbW2rVrFR0drbZt28rX11exsbEO99Lq1KmTli1bpsmTJ2vSpElq0qSJVq5cqVatWpk148ePV3Z2toYPH67MzEx16dJFCQkJcnd3r+hqAwAAAEC5XNF9sv7uuE/W1YH7ZAHcJwsAgKpWpffJAgAAAIBrGSELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBCFQ5ZSUlJ6tOnjwIDA+Xk5KSVK1eabbm5uXrqqafUunVreXp6KjAwUEOGDNGxY8cc+jh9+rQGDx4sLy8v+fj4KCoqSmfPnnWo+eGHH3T77bfL3d1dQUFBmjFjRpGxrFixQs2bN5e7u7tat26tzz//3KHdMAzFxsaqfv368vDwUFhYmPbt21fRVQYAAACAcqtwyMrOzlabNm00d+7cIm3nzp1TWlqannnmGaWlpenjjz/W3r179c9//tOhbvDgwdq1a5cSExO1evVqJSUlafjw4Wa7zWZTr1691LBhQ6Wmpurll1/WlClTtHDhQrNm8+bNGjhwoKKiorR9+3ZFREQoIiJCO3fuNGtmzJihOXPmaMGCBUpJSZGnp6fCw8N1/vz5iq42AAAAAJSLk2EYxmXP7OSkTz75RBERESXWbN26Ve3bt9ehQ4d0/fXXa/fu3WrZsqW2bt2qdu3aSZISEhJ099136+jRowoMDNT8+fP19NNPKyMjQ66urpKkCRMmaOXKldqzZ48kqX///srOztbq1avNZXXs2FEhISFasGCBDMNQYGCgxo4dq3HjxkmSsrKy5O/vr/j4eA0YMKDM9bPZbPL29lZWVpa8vLwu92nCFZo6dWpVDwGocnFxcVU9BAAArmkVyQaVfk5WVlaWnJyc5OPjI0lKTk6Wj4+PGbAkKSwsTM7OzkpJSTFrunbtagYsSQoPD9fevXv1xx9/mDVhYWEOywoPD1dycrIk6cCBA8rIyHCo8fb2VocOHcyaS+Xk5Mhmszk8AAAAAKAiKjVknT9/Xk899ZQGDhxopr2MjAz5+fk51Lm4uKhOnTrKyMgwa/z9/R1q7L+XVVO4vfB8xdVcavr06fL29jYfQUFBFV5nAAAAANe2SgtZubm5uv/++2UYhubPn19Zi7HUxIkTlZWVZT6OHDlS1UMCAAAA8BfjUhmd2gPWoUOHtH79eodjFgMCAnTixAmH+ry8PJ0+fVoBAQFmzfHjxx1q7L+XVVO43T6tfv36DjUhISHFjtvNzU1ubm4VXV0AAAAAMFm+J8sesPbt26evvvpKdevWdWgPDQ1VZmamUlNTzWnr169XQUGBOnToYNYkJSUpNzfXrElMTFSzZs1Uu3Zts2bdunUOfScmJio0NFSSFBwcrICAAIcam82mlJQUswYAAAAArFbhkHX27Fmlp6crPT1d0sULTKSnp+vw4cPKzc1Vv379tG3bNi1dulT5+fnKyMhQRkaGLly4IElq0aKF7rzzTg0bNkxbtmzRpk2bFBMTowEDBigwMFCSNGjQILm6uioqKkq7du3S8uXLNXv2bI0ZM8Ycx6hRo5SQkKCZM2dqz549mjJlirZt26aYmBhJF698OHr0aE2bNk2rVq3Sjh07NGTIEAUGBpZ6NUQAAAAAuBIVPlxw27Zt6tGjh/m7PfhERkZqypQpWrVqlSQVOSRvw4YN6t69uyRp6dKliomJUc+ePeXs7Ky+fftqzpw5Zq23t7fWrl2r6OhotW3bVr6+voqNjXW4l1anTp20bNkyTZ48WZMmTVKTJk20cuVKtWrVyqwZP368srOzNXz4cGVmZqpLly5KSEiQu7t7RVcbAAAAAMrliu6T9XfHfbKuDtwnC+A+WQAAVLWr6j5ZAAAAAHAtIWQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFqpwyEpKSlKfPn0UGBgoJycnrVy50qHdMAzFxsaqfv368vDwUFhYmPbt2+dQc/r0aQ0ePFheXl7y8fFRVFSUzp4961Dzww8/6Pbbb5e7u7uCgoI0Y8aMImNZsWKFmjdvLnd3d7Vu3Vqff/55hccCAAAAAFaqcMjKzs5WmzZtNHfu3GLbZ8yYoTlz5mjBggVKSUmRp6enwsPDdf78ebNm8ODB2rVrlxITE7V69WolJSVp+PDhZrvNZlOvXr3UsGFDpaam6uWXX9aUKVO0cOFCs2bz5s0aOHCgoqKitH37dkVERCgiIkI7d+6s0FgAAAAAwEpOhmEYlz2zk5M++eQTRURESLq45ygwMFBjx47VuHHjJElZWVny9/dXfHy8BgwYoN27d6tly5baunWr2rVrJ0lKSEjQ3XffraNHjyowMFDz58/X008/rYyMDLm6ukqSJkyYoJUrV2rPnj2SpP79+ys7O1urV682x9OxY0eFhIRowYIF5RpLWWw2m7y9vZWVlSUvL6/LfZpwhaZOnVrVQwCqXFxcXFUPAQCAa1pFsoGl52QdOHBAGRkZCgsLM6d5e3urQ4cOSk5OliQlJyfLx8fHDFiSFBYWJmdnZ6WkpJg1Xbt2NQOWJIWHh2vv3r36448/zJrCy7HX2JdTnrFcKicnRzabzeEBAAAAABVhacjKyMiQJPn7+ztM9/f3N9syMjLk5+fn0O7i4qI6deo41BTXR+FllFRTuL2ssVxq+vTp8vb2Nh9BQUHlWGsAAAAA+H+4umAhEydOVFZWlvk4cuRIVQ8JAAAAwF+MpSErICBAknT8+HGH6cePHzfbAgICdOLECYf2vLw8nT592qGmuD4KL6OkmsLtZY3lUm5ubvLy8nJ4AAAAAEBFWBqygoODFRAQoHXr1pnTbDabUlJSFBoaKkkKDQ1VZmamUlNTzZr169eroKBAHTp0MGuSkpKUm5tr1iQmJqpZs2aqXbu2WVN4OfYa+3LKMxYAAAAAsFqFQ9bZs2eVnp6u9PR0SRcvMJGenq7Dhw/LyclJo0eP1rRp07Rq1Srt2LFDQ4YMUWBgoHkFwhYtWujOO+/UsGHDtGXLFm3atEkxMTEaMGCAAgMDJUmDBg2Sq6uroqKitGvXLi1fvlyzZ8/WmDFjzHGMGjVKCQkJmjlzpvbs2aMpU6Zo27ZtiomJkaRyjQUAAAAArOZS0Rm2bdumHj16mL/bg09kZKTi4+M1fvx4ZWdna/jw4crMzFSXLl2UkJAgd3d3c56lS5cqJiZGPXv2lLOzs/r27as5c+aY7d7e3lq7dq2io6PVtm1b+fr6KjY21uFeWp06ddKyZcs0efJkTZo0SU2aNNHKlSvVqlUrs6Y8YwEAAAAAK13RfbL+7rhP1tWB+2QB3CcLAICqVmX3yQIAAACAax0hCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQpaHrPz8fD3zzDMKDg6Wh4eHbrjhBj333HMyDMOsMQxDsbGxql+/vjw8PBQWFqZ9+/Y59HP69GkNHjxYXl5e8vHxUVRUlM6ePetQ88MPP+j222+Xu7u7goKCNGPGjCLjWbFihZo3by53d3e1bt1an3/+udWrDAAAAAAmy0PWSy+9pPnz5+uNN97Q7t279dJLL2nGjBl6/fXXzZoZM2Zozpw5WrBggVJSUuTp6anw8HCdP3/erBk8eLB27dqlxMRErV69WklJSRo+fLjZbrPZ1KtXLzVs2FCpqal6+eWXNWXKFC1cuNCs2bx5swYOHKioqCht375dERERioiI0M6dO61ebQAAAACQJDkZhXcxWeCee+6Rv7+/3n77bXNa37595eHhoffee0+GYSgwMFBjx47VuHHjJElZWVny9/dXfHy8BgwYoN27d6tly5baunWr2rVrJ0lKSEjQ3XffraNHjyowMFDz58/X008/rYyMDLm6ukqSJkyYoJUrV2rPnj2SpP79+ys7O1urV682x9KxY0eFhIRowYIFZa6LzWaTt7e3srKy5OXlZdlzhIqZOnVqVQ8BqHJxcXFVPQQAAK5pFckGlu/J6tSpk9atW6effvpJkvT999/r22+/1V133SVJOnDggDIyMhQWFmbO4+3trQ4dOig5OVmSlJycLB8fHzNgSVJYWJicnZ2VkpJi1nTt2tUMWJIUHh6uvXv36o8//jBrCi/HXmNfzqVycnJks9kcHgAAAABQES5WdzhhwgTZbDY1b95c1apVU35+vp5//nkNHjxYkpSRkSFJ8vf3d5jP39/fbMvIyJCfn5/jQF1cVKdOHYea4ODgIn3Y22rXrq2MjIxSl3Op6dOns9cEAAAAwBWxfE/WBx98oKVLl2rZsmVKS0vTkiVL9Morr2jJkiVWL8pyEydOVFZWlvk4cuRIVQ8JAAAAwF+M5XuynnzySU2YMEEDBgyQJLVu3VqHDh3S9OnTFRkZqYCAAEnS8ePHVb9+fXO+48ePKyQkRJIUEBCgEydOOPSbl5en06dPm/MHBATo+PHjDjX238uqsbdfys3NTW5ubpez2gAAAAAgqRL2ZJ07d07Ozo7dVqtWTQUFBZKk4OBgBQQEaN26dWa7zWZTSkqKQkNDJUmhoaHKzMxUamqqWbN+/XoVFBSoQ4cOZk1SUpJyc3PNmsTERDVr1ky1a9c2awovx15jXw4AAAAAWM3ykNWnTx89//zzWrNmjQ4ePKhPPvlEr776qu677z5JkpOTk0aPHq1p06Zp1apV2rFjh4YMGaLAwEBFRERIklq0aKE777xTw4YN05YtW7Rp0ybFxMRowIABCgwMlCQNGjRIrq6uioqK0q5du7R8+XLNnj1bY8aMMccyatQoJSQkaObMmdqzZ4+mTJmibdu2KSYmxurVBgAAAABJlXC44Ouvv65nnnlGjz76qE6cOKHAwECNGDFCsbGxZs348eOVnZ2t4cOHKzMzU126dFFCQoLc3d3NmqVLlyomJkY9e/aUs7Oz+vbtqzlz5pjt3t7eWrt2raKjo9W2bVv5+voqNjbW4V5anTp10rJlyzR58mRNmjRJTZo00cqVK9WqVSurVxsAAAAAJFXCfbL+TrhP1tWBKz4C3CcLAICqVqX3yQIAAACAaxkhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQpUSsn799Vf95z//Ud26deXh4aHWrVtr27ZtZrthGIqNjVX9+vXl4eGhsLAw7du3z6GP06dPa/DgwfLy8pKPj4+ioqJ09uxZh5offvhBt99+u9zd3RUUFKQZM2YUGcuKFSvUvHlzubu7q3Xr1vr8888rY5UBAAAAQFIlhKw//vhDnTt3VvXq1fXFF1/oxx9/1MyZM1W7dm2zZsaMGZozZ44WLFiglJQUeXp6Kjw8XOfPnzdrBg8erF27dikxMVGrV69WUlKShg8fbrbbbDb16tVLDRs2VGpqql5++WVNmTJFCxcuNGs2b96sgQMHKioqStu3b1dERIQiIiK0c+dOq1cbAAAAACRJToZhGFZ2OGHCBG3atEnffPNNse2GYSgwMFBjx47VuHHjJElZWVny9/dXfHy8BgwYoN27d6tly5baunWr2rVrJ0lKSEjQ3XffraNHjyowMFDz58/X008/rYyMDLm6uprLXrlypfbs2SNJ6t+/v7Kzs7V69Wpz+R07dlRISIgWLFhQ5rrYbDZ5e3srKytLXl5eV/S84PJNnTq1qocAVLm4uLiqHgIAANe0imQDy/dkrVq1Su3atdO///1v+fn56ZZbbtFbb71lth84cEAZGRkKCwszp3l7e6tDhw5KTk6WJCUnJ8vHx8cMWJIUFhYmZ2dnpaSkmDVdu3Y1A5YkhYeHa+/evfrjjz/MmsLLsdfYl3OpnJwc2Ww2hwcAAAAAVITlIWv//v2aP3++mjRpoi+//FIjR47U448/riVLlkiSMjIyJEn+/v4O8/n7+5ttGRkZ8vPzc2h3cXFRnTp1HGqK66PwMkqqsbdfavr06fL29jYfQUFBFV5/AAAAANc2y0NWQUGBbr31Vr3wwgu65ZZbNHz4cA0bNqxch+dVtYkTJyorK8t8HDlypKqHBAAAAOAvxvKQVb9+fbVs2dJhWosWLXT48GFJUkBAgCTp+PHjDjXHjx832wICAnTixAmH9ry8PJ0+fdqhprg+Ci+jpBp7+6Xc3Nzk5eXl8AAAAACAirA8ZHXu3Fl79+51mPbTTz+pYcOGkqTg4GAFBARo3bp1ZrvNZlNKSopCQ0MlSaGhocrMzFRqaqpZs379ehUUFKhDhw5mTVJSknJzc82axMRENWvWzLySYWhoqMNy7DX25QAAAACA1SwPWU888YS+++47vfDCC/r555+1bNkyLVy4UNHR0ZIkJycnjR49WtOmTdOqVau0Y8cODRkyRIGBgYqIiJB0cc/XnXfeqWHDhmnLli3atGmTYmJiNGDAAAUGBkqSBg0aJFdXV0VFRWnXrl1avny5Zs+erTFjxphjGTVqlBISEjRz5kzt2bNHU6ZM0bZt2xQTE2P1agMAAACAJMnF6g5vu+02ffLJJ5o4caKeffZZBQcHa9asWRo8eLBZM378eGVnZ2v48OHKzMxUly5dlJCQIHd3d7Nm6dKliomJUc+ePeXs7Ky+fftqzpw5Zru3t7fWrl2r6OhotW3bVr6+voqNjXW4l1anTp20bNkyTZ48WZMmTVKTJk20cuVKtWrVyurVBgAAAABJlXCfrL8T7pN1deA+WQD3yQIAoKpV6X2yAAAAAOBaRsgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALBQpYesF198UU5OTho9erQ57fz584qOjlbdunVVs2ZN9e3bV8ePH3eY7/Dhw+rdu7dq1KghPz8/Pfnkk8rLy3Oo+frrr3XrrbfKzc1NN954o+Lj44ssf+7cuWrUqJHc3d3VoUMHbdmypTJWEwAAAAAkVXLI2rp1q958803dfPPNDtOfeOIJffbZZ1qxYoU2btyoY8eO6V//+pfZnp+fr969e+vChQvavHmzlixZovj4eMXGxpo1Bw4cUO/evdWjRw+lp6dr9OjRevjhh/Xll1+aNcuXL9eYMWMUFxentLQ0tWnTRuHh4Tpx4kRlrjYAAACAa1ilhayzZ89q8ODBeuutt1S7dm1zelZWlt5++229+uqruuOOO9S2bVstXrxYmzdv1nfffSdJWrt2rX788Ue99957CgkJ0V133aXnnntOc+fO1YULFyRJCxYsUHBwsGbOnKkWLVooJiZG/fr102uvvWYu69VXX9WwYcM0dOhQtWzZUgsWLFCNGjX0zjvvVNZqAwAAALjGVVrIio6OVu/evRUWFuYwPTU1Vbm5uQ7Tmzdvruuvv17JycmSpOTkZLVu3Vr+/v5mTXh4uGw2m3bt2mXWXNp3eHi42ceFCxeUmprqUOPs7KywsDCz5lI5OTmy2WwODwAAAACoCJfK6PT9999XWlqatm7dWqQtIyNDrq6u8vHxcZju7++vjIwMs6ZwwLK329tKq7HZbPrf//6nP/74Q/n5+cXW7Nmzp9hxT58+XVOnTi3/igIAAADAJSzfk3XkyBGNGjVKS5culbu7u9XdV6qJEycqKyvLfBw5cqSqhwQAAADgL8bykJWamqoTJ07o1ltvlYuLi1xcXLRx40bNmTNHLi4u8vf314ULF5SZmekw3/HjxxUQECBJCggIKHK1QfvvZdV4eXnJw8NDvr6+qlatWrE19j4u5ebmJi8vL4cHAAAAAFSE5SGrZ8+e2rFjh9LT081Hu3btNHjwYPPn6tWra926deY8e/fu1eHDhxUaGipJCg0N1Y4dOxyuApiYmCgvLy+1bNnSrCnch73G3oerq6vatm3rUFNQUKB169aZNQAAAABgNcvPyapVq5ZatWrlMM3T01N169Y1p0dFRWnMmDGqU6eOvLy89Nhjjyk0NFQdO3aUJPXq1UstW7bUAw88oBkzZigjI0OTJ09WdHS03NzcJEmPPPKI3njjDY0fP14PPfSQ1q9frw8++EBr1qwxlztmzBhFRkaqXbt2at++vWbNmqXs7GwNHTrU6tUGAAAAAEmVdOGLsrz22mtydnZW3759lZOTo/DwcM2bN89sr1atmlavXq2RI0cqNDRUnp6eioyM1LPPPmvWBAcHa82aNXriiSc0e/ZsNWjQQIsWLVJ4eLhZ079/f508eVKxsbHKyMhQSEiIEhISilwMAwAAAACs4mQYhlHVg7ha2Ww2eXt7Kysri/OzqhBXfASkuLi4qh4CAADXtIpkg0q7TxYAAAAAXIsIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFLA9Z06dP12233aZatWrJz89PERER2rt3r0PN+fPnFR0drbp166pmzZrq27evjh8/7lBz+PBh9e7dWzVq1JCfn5+efPJJ5eXlOdR8/fXXuvXWW+Xm5qYbb7xR8fHxRcYzd+5cNWrUSO7u7urQoYO2bNli9SoDAAAAgMnykLVx40ZFR0fru+++U2JionJzc9WrVy9lZ2ebNU888YQ+++wzrVixQhs3btSxY8f0r3/9y2zPz89X7969deHCBW3evFlLlixRfHy8YmNjzZoDBw6od+/e6tGjh9LT0zV69Gg9/PDD+vLLL82a5cuXa8yYMYqLi1NaWpratGmj8PBwnThxwurVBgAAAABJkpNhGEZlLuDkyZPy8/PTxo0b1bVrV2VlZalevXpatmyZ+vXrJ0nas2ePWrRooeTkZHXs2FFffPGF7rnnHh07dkz+/v6SpAULFuipp57SyZMn5erqqqeeekpr1qzRzp07zWUNGDBAmZmZSkhIkCR16NBBt912m9544w1JUkFBgYKCgvTYY49pwoQJRcaak5OjnJwc83ebzaagoCBlZWXJy8ur0p4jlG7q1KlVPQSgysXFxVX1EAAAuKbZbDZ5e3uXKxtU+jlZWVlZkqQ6depIklJTU5Wbm6uwsDCzpnnz5rr++uuVnJwsSUpOTlbr1q3NgCVJ4eHhstls2rVrl1lTuA97jb2PCxcuKDU11aHG2dlZYWFhZs2lpk+fLm9vb/MRFBR0pasPAAAA4BpTqSGroKBAo0ePVufOndWqVStJUkZGhlxdXeXj4+NQ6+/vr4yMDLOmcMCyt9vbSqux2Wz63//+p1OnTik/P7/YGnsfl5o4caKysrLMx5EjRy5vxQEAAABcs1wqs/Po6Gjt3LlT3377bWUuxjJubm5yc3Or6mEAAAAA+AurtD1ZMTExWr16tTZs2KAGDRqY0wMCAnThwgVlZmY61B8/flwBAQFmzaVXG7T/XlaNl5eXPDw85Ovrq2rVqhVbY+8DAAAAAKxmecgyDEMxMTH65JNPtH79egUHBzu0t23bVtWrV9e6devMaXv37tXhw4cVGhoqSQoNDdWOHTscrgKYmJgoLy8vtWzZ0qwp3Ie9xt6Hq6ur2rZt61BTUFCgdevWmTUAAAAAYDXLDxeMjo7WsmXL9Omnn6pWrVrm+U/e3t7y8PCQt7e3oqKiNGbMGNWpU0deXl567LHHFBoaqo4dO0qSevXqpZYtW+qBBx7QjBkzlJGRocmTJys6Oto8nO+RRx7RG2+8ofHjx+uhhx7S+vXr9cEHH2jNmjXmWMaMGaPIyEi1a9dO7du316xZs5Sdna2hQ4davdoAAAAAIKkSQtb8+fMlSd27d3eYvnjxYj344IOSpNdee03Ozs7q27evcnJyFB4ernnz5pm11apV0+rVqzVy5EiFhobK09NTkZGRevbZZ82a4OBgrVmzRk888YRmz56tBg0aaNGiRQoPDzdr+vfvr5MnTyo2NlYZGRkKCQlRQkJCkYthAAAAAIBVKv0+WX9lFbkWPioP98kCuE8WAABV7aq6TxYAAAAAXEsIWQAAAABgoUq9TxYAAIBVOHwc1zoOHf/rYE8WAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFjomghZc+fOVaNGjeTu7q4OHTpoy5YtVT0kAAAAAH9Tf/uQtXz5co0ZM0ZxcXFKS0tTmzZtFB4erhMnTlT10AAAAAD8Df3tQ9arr76qYcOGaejQoWrZsqUWLFigGjVq6J133qnqoQEAAAD4G3Kp6gFUpgsXLig1NVUTJ040pzk7OyssLEzJyclF6nNycpSTk2P+npWVJUmy2WyVP1iU6Pz581U9BKDKsR0C+HsA8Legatmff8Mwyqz9W4esU6dOKT8/X/7+/g7T/f39tWfPniL106dP19SpU4tMDwoKqrQxAkB5vPjii1U9BABAFeNvwdXhzJkz8vb2LrXmbx2yKmrixIkaM2aM+XtBQYFOnz6tunXrysnJqQpHBlQdm82moKAgHTlyRF5eXlU9HABAFeHvAa51hmHozJkzCgwMLLP2bx2yfH19Va1aNR0/ftxh+vHjxxUQEFCk3s3NTW5ubg7TfHx8KnOIwF+Gl5cXf1QBAPw9wDWtrD1Ydn/rC1+4urqqbdu2WrdunTmtoKBA69atU2hoaBWODAAAAMDf1d96T5YkjRkzRpGRkWrXrp3at2+vWbNmKTs7W0OHDq3qoQEAAAD4G/rbh6z+/fvr5MmTio2NVUZGhkJCQpSQkFDkYhgAiufm5qa4uLgih9ICAK4t/D0Ays/JKM81CAEAAAAA5fK3PicLAAAAAP5shCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAUa+vWrbr77rvl4+MjT09PdezYUR988EFVDwsA8Cd67733NGLECLVr105ubm5ycnJSfHx8VQ8LuOr97S/hDqDiNmzYoPDwcLm7u2vAgAGqVauWPvroI/Xv319HjhzR2LFjq3qIAIA/weTJk3Xo0CH5+vqqfv36OnToUFUPCfhLYE8WAAd5eXkaNmyYnJ2dlZSUpIULF2rmzJn6/vvv1bRpU02aNIk/sgBwjVi0aJEOHjyokydP6pFHHqnq4QB/GYQsAA7Wr1+vX375RYMGDVJISIg53dvbW5MmTdKFCxe0ZMmSqhsgAOBPExYWpoYNG1b1MIC/HEIWAAdff/21JKlXr15F2sLDwyVJGzdu/DOHBAAA8JdCyALgYN++fZKkJk2aFGkLCAhQzZo1zRoAAAAURcgC4CArK0vSxcMDi+Pl5WXWAAAAoChCFgAAAABYiJAFwIF9D1ZJe6tsNluJe7kAAABAyAJwCfu5WMWdd5WRkaGzZ88We74WAAAALiJkAXDQrVs3SdLatWuLtH355ZcONQAAACiKkAXAQc+ePdW4cWMtW7ZM6enp5vSsrCy98MILcnV11ZAhQ6pugAAAAFc5J8MwjKoeBICry4YNGxQeHi53d3cNGDBAtWrV0kcffaRDhw7plVde0dixY6t6iACAP8GiRYv07bffSpJ27NihtLQ0de7cWTfeeKMkqUuXLnr44YercojAVYmQBaBYW7ZsUVxcnDZv3qzc3Fy1bt1aY8aMUf/+/at6aACAP8mDDz6oJUuWlNgeGRmp+Pj4P29AwF8EIQsAAAAALMQ5WQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAFegUaNGmjVrVlUPAwBwFXEyDMOo6kEAAPBn6N69u0JCQiwNRSdPnpSnp6dq1KhhWZ8AgL82l6oeAAAAf2X16tWr6iEAAK4yHC4IALgmPPjgg9q4caNmz54tJycnOTk56eDBg9q4caPat28vNzc31a9fXxMmTFBeXp4k6d1331XNmjW1b98+s59HH31UzZs317lz5yQVPVwwMzNTI0aMkL+/v9zd3dWqVSutXr36T11XAEDVYk8WAOCaMHv2bP30009q1aqVnn32WUlSfn6+7r77bj344IN69913tWfPHg0bNkzu7u6aMmWKhgwZotWrV2vw4MHavHmzvvzySy1atEjJycnFHh5YUFCgu+66S2fOnNF7772nG264QT/++KOqVav2Z68uAKAKEbIAANcEb29vubq6qkaNGgoICJAkPf300woKCtIbb7whJycnNW/eXMeOHdNTTz2l2NhYOTs7680339TNN9+sxx9/XB9//LGmTJmitm3bFruMr776Slu2bNHu3bvVtGlTSVLjxo3/tHUEAFwdOFwQAHDN2r17t0JDQ+Xk5GRO69y5s86ePaujR49KkmrXrq23335b8+fP1w033KAJEyaU2F96eroaNGhgBiwAwLWJkAUAQBmSkpJUrVo1/fbbb8rOzi6xzsPD408cFQDgakXIAgBcM1xdXZWfn2/+3qJFCyUnJ6vw3Uw2bdqkWrVqqUGDBpKkzZs366WXXtJnn32mmjVrKiYmpsT+b775Zh09elQ//fRT5a0EAOCqR8gCAFwzGjVqpJSUFB08eFCnTp3So48+qiNHjuixxx7Tnj179OmnnyouLk5jxoyRs7Ozzpw5owceeECPP/647rrrLi1dulTLly/Xhx9+WGz/3bp1U9euXdW3b18lJibqwIED+uKLL5SQkPAnrykAoCoRsgAA14xx48apWrVqatmyperVq6fc3Fx9/vnn2rJli9q0aaNHHnlEUVFRmjx5siRp1KhR8vT01AsvvCBJat26tV544QWNGDFCv/76a7HL+Oijj3Tbbbdp4MCBatmypcaPH++w9wwA8PfnZBQ+RgIAAAAAcEXYkwUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgof8PbtMuirIGOnUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar = df.groupby('toxic')['toxic'].count()\n",
    "bar.plot(kind='bar', figsize=(10, 5), color='grey') #столб.диаграмма по сводной таблице с указанным размером\n",
    "bw = 0.3 #толщина столбика\n",
    "plt.title('Распределение классов датасета', fontsize=20) #имя графика\n",
    "plt.xticks(fontsize=14, rotation=0); #показать подпись, убрать поворот"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.84 %\n"
     ]
    }
   ],
   "source": [
    "print(round((df['toxic'].count() - df['toxic'].sum()) / df['toxic'].count() * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наблюдаем сильный дисбаланс классов. Нетоксичных комментариев почти 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "Данные изучены. Небольшой EDA не помешает, так как это аналитический проект. \n",
    "\n",
    "\n",
    "Плюс за\n",
    "\n",
    "    \n",
    "\n",
    "- промужуточный вывод в конце раздела\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "\n",
    "- стоило еще проверить на сбалансированность классов в таргете это важная информация при моделировании и  корректной оценки модели. и к нему график можно, ведь красивый, хорошо оформленный график может быть украшением проекта. \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "- .sample вместо .head, ведь если данные каким то образом упорядоченны, то шансы увидеть что то разнообразное через .sample чуть выше чем через .head (или .tail)     \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарий студента:</b> Сделано</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных для BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка предобученных модели и токенизатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "\n",
    "Принято\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "Есть модели обученных на специальных в текстах и предназначенные для специальных целей, их можно поискать на  на huggingface. Там авторы указывают,на каких данных учили и для каких целей, можно поискать. В частности для нашего датосета возможно будут интересна модель  toxic-bert. Судя по названию она самое то )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарий студента:</b> Честно говоря, не нашел ни примеров синтаксиса, ни ведеоматериалов, чтобы с текущими знаниями получилось реализовать BERT иначе.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим любой рандомный текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 2017,\n",
       " 1010,\n",
       " 2909,\n",
       " 1010,\n",
       " 2024,\n",
       " 2026,\n",
       " 5394,\n",
       " 1012,\n",
       " 2151,\n",
       " 3382,\n",
       " 2017,\n",
       " 3342,\n",
       " 1012,\n",
       " 1012,\n",
       " 102]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('You, sir, are my hero. Any chance you remember..', add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизатор отрабатывает корректно. Применим его предварительно к датасету."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразуем текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "pre_tokenized = df['text'].apply(\n",
    "  lambda x: tokenizer.encode(x, add_special_tokens=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [101, 7526, 2339, 1996, 10086, 2015, 2081, 210...\n",
       "1         [101, 1040, 1005, 22091, 2860, 999, 2002, 3503...\n",
       "2         [101, 4931, 2158, 1010, 1045, 1005, 1049, 2428...\n",
       "3         [101, 1000, 2062, 1045, 2064, 1005, 1056, 2191...\n",
       "4         [101, 2017, 1010, 2909, 1010, 2024, 2026, 5394...\n",
       "                                ...                        \n",
       "159446    [101, 1000, 1024, 1024, 1024, 1024, 1024, 1998...\n",
       "159447    [101, 2017, 2323, 2022, 14984, 1997, 4426, 200...\n",
       "159448    [101, 13183, 6290, 26114, 1010, 2045, 2015, 20...\n",
       "159449    [101, 1998, 2009, 3504, 2066, 2009, 2001, 2941...\n",
       "159450    [101, 1000, 1998, 1012, 1012, 1012, 1045, 2428...\n",
       "Name: text, Length: 159292, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим из сообщения к `pre_tokenized`, имеем ограничение в 512 токенов в строке. Создадим такое ограничение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Фильтруем данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем датасет из токенизированных данных - столбец `text`, целевого признака и длин списков токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 7526, 2339, 1996, 10086, 2015, 2081, 210...</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 1040, 1005, 22091, 2860, 999, 2002, 3503...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 4931, 2158, 1010, 1045, 1005, 1049, 2428...</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[101, 1000, 2062, 1045, 2064, 1005, 1056, 2191...</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[101, 2017, 1010, 2909, 1010, 2024, 2026, 5394...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>[101, 1000, 1024, 1024, 1024, 1024, 1024, 1998...</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>[101, 2017, 2323, 2022, 14984, 1997, 4426, 200...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>[101, 13183, 6290, 26114, 1010, 2045, 2015, 20...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>[101, 1998, 2009, 3504, 2066, 2009, 2001, 2941...</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>[101, 1000, 1998, 1012, 1012, 1012, 1045, 2428...</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  len\n",
       "0       [101, 7526, 2339, 1996, 10086, 2015, 2081, 210...      0   68\n",
       "1       [101, 1040, 1005, 22091, 2860, 999, 2002, 3503...      0   35\n",
       "2       [101, 4931, 2158, 1010, 1045, 1005, 1049, 2428...      0   54\n",
       "3       [101, 1000, 2062, 1045, 2064, 1005, 1056, 2191...      0  144\n",
       "4       [101, 2017, 1010, 2909, 1010, 2024, 2026, 5394...      0   21\n",
       "...                                                   ...    ...  ...\n",
       "159446  [101, 1000, 1024, 1024, 1024, 1024, 1024, 1998...      0   68\n",
       "159447  [101, 2017, 2323, 2022, 14984, 1997, 4426, 200...      0   27\n",
       "159448  [101, 13183, 6290, 26114, 1010, 2045, 2015, 20...      0   19\n",
       "159449  [101, 1998, 2009, 3504, 2066, 2009, 2001, 2941...      0   28\n",
       "159450  [101, 1000, 1998, 1012, 1012, 1012, 1045, 2428...      0   51\n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = pd.DataFrame(pre_tokenized)\n",
    "df_temp['toxic'] = df['toxic']\n",
    "len_list = []\n",
    "for i in df_temp['text']:\n",
    "    len_list.append(len(i))\n",
    "df_temp['len'] = len_list\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляем строки с превышающими лимит токенами. таких строк порядка 1.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_temp.loc[df_temp['len'] < 513].drop(['len'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Совет 🤔:\n",
    "\n",
    "\n",
    "Можно было подать с такими аргументами    \n",
    "\n",
    "    df['text'].apply(lambda x: tokenizer.encode(x, \n",
    "                                                            max_length=512,\n",
    "                                                            padding='max_length',\n",
    "                                                            truncation=True,\n",
    "                                                            add_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарий студента:</b> Вот этого я как раз не хотел делать, чтобы не обрезать текст. Вдруг в обрезках были бы слова, которые дают категорию 1. Лучше полность исключить строки, их не так много. Я неправ?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем данные по индексу: слева - тексты из исходного датасета, справа - целевой признак из нового, отфильтрованного датасета. Так как `join` имеет значение `inner`, то остаются только те строки, в которых совпадает индекс, то есть прошедшие фильтрацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155789 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159446  \":::::And for the second time of asking, when ...      0\n",
       "159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159449  And it looks like it was actually you who put ...      0\n",
       "159450  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[155789 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_left = df['text']\n",
    "df_right = df_temp['toxic']\n",
    "result = pd.concat([df_left, df_right], axis=1, join=\"inner\")\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае преобразования в эмбенддинги внутри ноутбука, код ниже - указывает количество семплов для будущего датасета, где `q_sample = len(result)` - это полный датасет.\n",
    "\n",
    "Ниже приведен пример расчета для очень маленькой выборки - взяли 256 строк, чтобы показать работоспособность кода. \n",
    "\n",
    "Полный преобразованный датасет будет использоваться уже на этапе разделения признаков и целевого признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_sample = 256 # нужное число для датасета, вплоть до q_sample = len(result)\n",
    "result = result.sample(q_sample).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразуем текст предобработанных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизируем отфильтрованную выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = result['text'].apply(\n",
    "  lambda x: tokenizer.encode(x, add_special_tokens=True)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предупреждения больше нет. Максимальная длина токена `max_len` равна ограничению - 512. Вынесли это значения в константы.\n",
    "\n",
    "При исполнении преобразования внутри ноутбука, `max_len` расчитывается ниже. Так как мы случайным образом отберем какое-то количество строк, может случиться, что строки будут короче константной `max_len = 512`, это нужно учитывать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразование векторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Паддингом добавляем к каждому вектору нули в конец, так, чтобы длина каждого вектора была равна длине `max_len`.\n",
    "\n",
    "Маска тоже применяется к каждому вектору - значению, отличному от нуля, присваивается 1, нули остаются нулями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заранее рассчитанные данные:\n",
    "- В Яндекс.Диске лежит датасет, содержащий 78% данных (ограничение по размеру файла), при батче равном 200. Он будет прочитан позже.\n",
    "\n",
    "Преобразование эмбеддингов было произведено в Google Colab, с использованием GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразование в эмбеддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017107725143432617,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 8,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9b512b575449868a0fe24328b17d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.270376</td>\n",
       "      <td>-0.109006</td>\n",
       "      <td>-0.477660</td>\n",
       "      <td>0.270684</td>\n",
       "      <td>-0.240516</td>\n",
       "      <td>-0.604802</td>\n",
       "      <td>0.764190</td>\n",
       "      <td>0.883395</td>\n",
       "      <td>-0.162878</td>\n",
       "      <td>-0.440548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.223434</td>\n",
       "      <td>0.023012</td>\n",
       "      <td>-0.216745</td>\n",
       "      <td>0.247818</td>\n",
       "      <td>0.385476</td>\n",
       "      <td>-0.331367</td>\n",
       "      <td>-0.066175</td>\n",
       "      <td>0.339361</td>\n",
       "      <td>0.561782</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.215965</td>\n",
       "      <td>-0.064486</td>\n",
       "      <td>0.171992</td>\n",
       "      <td>0.213599</td>\n",
       "      <td>0.262521</td>\n",
       "      <td>-0.149945</td>\n",
       "      <td>0.224523</td>\n",
       "      <td>0.414178</td>\n",
       "      <td>-0.083124</td>\n",
       "      <td>-0.178243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107594</td>\n",
       "      <td>0.173650</td>\n",
       "      <td>0.084636</td>\n",
       "      <td>0.374016</td>\n",
       "      <td>0.304638</td>\n",
       "      <td>-0.209161</td>\n",
       "      <td>-0.142330</td>\n",
       "      <td>0.303607</td>\n",
       "      <td>0.599943</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.256517</td>\n",
       "      <td>-0.008255</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.333179</td>\n",
       "      <td>0.205015</td>\n",
       "      <td>-0.249076</td>\n",
       "      <td>0.230479</td>\n",
       "      <td>0.332486</td>\n",
       "      <td>-0.057936</td>\n",
       "      <td>-0.221463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087054</td>\n",
       "      <td>-0.076492</td>\n",
       "      <td>-0.126979</td>\n",
       "      <td>0.518873</td>\n",
       "      <td>0.147304</td>\n",
       "      <td>-0.481433</td>\n",
       "      <td>-0.221487</td>\n",
       "      <td>0.474675</td>\n",
       "      <td>0.298737</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.004680</td>\n",
       "      <td>-0.192381</td>\n",
       "      <td>0.131963</td>\n",
       "      <td>-0.306438</td>\n",
       "      <td>-0.280289</td>\n",
       "      <td>-0.481397</td>\n",
       "      <td>-0.003957</td>\n",
       "      <td>0.581554</td>\n",
       "      <td>0.180571</td>\n",
       "      <td>-0.448998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.488260</td>\n",
       "      <td>-0.225800</td>\n",
       "      <td>-0.547975</td>\n",
       "      <td>-0.103998</td>\n",
       "      <td>0.183307</td>\n",
       "      <td>-0.219604</td>\n",
       "      <td>-0.288737</td>\n",
       "      <td>0.227150</td>\n",
       "      <td>0.743948</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.178259</td>\n",
       "      <td>0.296173</td>\n",
       "      <td>0.129975</td>\n",
       "      <td>-0.400100</td>\n",
       "      <td>-0.241940</td>\n",
       "      <td>-0.205647</td>\n",
       "      <td>0.574739</td>\n",
       "      <td>0.493405</td>\n",
       "      <td>-0.041588</td>\n",
       "      <td>-0.155493</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.369010</td>\n",
       "      <td>-0.104315</td>\n",
       "      <td>-0.508261</td>\n",
       "      <td>0.367626</td>\n",
       "      <td>0.142204</td>\n",
       "      <td>0.098504</td>\n",
       "      <td>-0.296253</td>\n",
       "      <td>0.420840</td>\n",
       "      <td>0.457711</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>-0.251713</td>\n",
       "      <td>-0.149814</td>\n",
       "      <td>-0.435527</td>\n",
       "      <td>-0.074261</td>\n",
       "      <td>-0.562632</td>\n",
       "      <td>-0.407684</td>\n",
       "      <td>0.437929</td>\n",
       "      <td>0.345515</td>\n",
       "      <td>0.077336</td>\n",
       "      <td>-0.280696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.183804</td>\n",
       "      <td>-0.115963</td>\n",
       "      <td>-0.593659</td>\n",
       "      <td>0.618964</td>\n",
       "      <td>0.561259</td>\n",
       "      <td>-0.459574</td>\n",
       "      <td>0.147581</td>\n",
       "      <td>0.646249</td>\n",
       "      <td>0.283916</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.026077</td>\n",
       "      <td>0.181218</td>\n",
       "      <td>-0.059621</td>\n",
       "      <td>-0.283367</td>\n",
       "      <td>-0.223145</td>\n",
       "      <td>-0.195438</td>\n",
       "      <td>0.345665</td>\n",
       "      <td>0.109532</td>\n",
       "      <td>0.319496</td>\n",
       "      <td>-0.154305</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086503</td>\n",
       "      <td>-0.017991</td>\n",
       "      <td>-0.006160</td>\n",
       "      <td>0.079280</td>\n",
       "      <td>-0.164264</td>\n",
       "      <td>-0.127958</td>\n",
       "      <td>-0.419423</td>\n",
       "      <td>0.550043</td>\n",
       "      <td>0.654435</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>-0.892689</td>\n",
       "      <td>0.098495</td>\n",
       "      <td>0.402001</td>\n",
       "      <td>-0.179198</td>\n",
       "      <td>0.137741</td>\n",
       "      <td>-0.361135</td>\n",
       "      <td>-0.106007</td>\n",
       "      <td>0.093611</td>\n",
       "      <td>0.043195</td>\n",
       "      <td>-0.156481</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015632</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>-0.558394</td>\n",
       "      <td>-0.010419</td>\n",
       "      <td>-0.050655</td>\n",
       "      <td>-0.111066</td>\n",
       "      <td>-0.523665</td>\n",
       "      <td>0.556151</td>\n",
       "      <td>0.793079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>-0.077887</td>\n",
       "      <td>-0.416015</td>\n",
       "      <td>0.199894</td>\n",
       "      <td>-0.370491</td>\n",
       "      <td>-0.159890</td>\n",
       "      <td>-0.388170</td>\n",
       "      <td>0.101460</td>\n",
       "      <td>0.638184</td>\n",
       "      <td>0.218372</td>\n",
       "      <td>-0.756674</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.413653</td>\n",
       "      <td>-0.117157</td>\n",
       "      <td>-0.575325</td>\n",
       "      <td>-0.077441</td>\n",
       "      <td>-0.058787</td>\n",
       "      <td>-0.572139</td>\n",
       "      <td>-0.151710</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.684834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0.208991</td>\n",
       "      <td>-0.184688</td>\n",
       "      <td>-0.272500</td>\n",
       "      <td>0.018786</td>\n",
       "      <td>0.164206</td>\n",
       "      <td>0.053327</td>\n",
       "      <td>0.067971</td>\n",
       "      <td>0.147177</td>\n",
       "      <td>-0.405134</td>\n",
       "      <td>0.012086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262186</td>\n",
       "      <td>0.105450</td>\n",
       "      <td>-0.009845</td>\n",
       "      <td>0.297282</td>\n",
       "      <td>0.355816</td>\n",
       "      <td>-0.305125</td>\n",
       "      <td>-0.093553</td>\n",
       "      <td>0.498915</td>\n",
       "      <td>0.456015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.270376 -0.109006 -0.477660  0.270684 -0.240516 -0.604802  0.764190   \n",
       "1    0.215965 -0.064486  0.171992  0.213599  0.262521 -0.149945  0.224523   \n",
       "2    0.256517 -0.008255  0.000268  0.333179  0.205015 -0.249076  0.230479   \n",
       "3   -0.004680 -0.192381  0.131963 -0.306438 -0.280289 -0.481397 -0.003957   \n",
       "4   -0.178259  0.296173  0.129975 -0.400100 -0.241940 -0.205647  0.574739   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "251 -0.251713 -0.149814 -0.435527 -0.074261 -0.562632 -0.407684  0.437929   \n",
       "252  0.026077  0.181218 -0.059621 -0.283367 -0.223145 -0.195438  0.345665   \n",
       "253 -0.892689  0.098495  0.402001 -0.179198  0.137741 -0.361135 -0.106007   \n",
       "254 -0.077887 -0.416015  0.199894 -0.370491 -0.159890 -0.388170  0.101460   \n",
       "255  0.208991 -0.184688 -0.272500  0.018786  0.164206  0.053327  0.067971   \n",
       "\n",
       "            7         8         9  ...       759       760       761  \\\n",
       "0    0.883395 -0.162878 -0.440548  ... -0.223434  0.023012 -0.216745   \n",
       "1    0.414178 -0.083124 -0.178243  ... -0.107594  0.173650  0.084636   \n",
       "2    0.332486 -0.057936 -0.221463  ...  0.087054 -0.076492 -0.126979   \n",
       "3    0.581554  0.180571 -0.448998  ... -0.488260 -0.225800 -0.547975   \n",
       "4    0.493405 -0.041588 -0.155493  ... -0.369010 -0.104315 -0.508261   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "251  0.345515  0.077336 -0.280696  ... -0.183804 -0.115963 -0.593659   \n",
       "252  0.109532  0.319496 -0.154305  ... -0.086503 -0.017991 -0.006160   \n",
       "253  0.093611  0.043195 -0.156481  ... -0.015632  0.000749 -0.558394   \n",
       "254  0.638184  0.218372 -0.756674  ... -0.413653 -0.117157 -0.575325   \n",
       "255  0.147177 -0.405134  0.012086  ...  0.262186  0.105450 -0.009845   \n",
       "\n",
       "          762       763       764       765       766       767  toxic  \n",
       "0    0.247818  0.385476 -0.331367 -0.066175  0.339361  0.561782      0  \n",
       "1    0.374016  0.304638 -0.209161 -0.142330  0.303607  0.599943      0  \n",
       "2    0.518873  0.147304 -0.481433 -0.221487  0.474675  0.298737      0  \n",
       "3   -0.103998  0.183307 -0.219604 -0.288737  0.227150  0.743948      0  \n",
       "4    0.367626  0.142204  0.098504 -0.296253  0.420840  0.457711      0  \n",
       "..        ...       ...       ...       ...       ...       ...    ...  \n",
       "251  0.618964  0.561259 -0.459574  0.147581  0.646249  0.283916      0  \n",
       "252  0.079280 -0.164264 -0.127958 -0.419423  0.550043  0.654435      0  \n",
       "253 -0.010419 -0.050655 -0.111066 -0.523665  0.556151  0.793079      0  \n",
       "254 -0.077441 -0.058787 -0.572139 -0.151710  0.002426  0.684834      0  \n",
       "255  0.297282  0.355816 -0.305125 -0.093553  0.498915  0.456015      0  \n",
       "\n",
       "[256 rows x 769 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32 # задаем размер батча (кратен q_sample, если уменьшаем q_sample - уменьшаем и батч)\n",
    "embeddings = [] # список эмбеддингов\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)): # цикл по батчам, отображать прогресс будет функция notebook()\n",
    "        batch = torch.IntTensor(padded[batch_size*i:batch_size*(i+1)]) # преобразуем данные в формат тензоров\n",
    "        attention_mask_batch = torch.IntTensor(attention_mask[batch_size*i:batch_size*(i+1)]) # преобразуем маску\n",
    "        \n",
    "        with torch.no_grad(): # для ускорения вычисления функцией no_grad() в библиотеке torch укажем, что градиенты не нужны\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch) # чтобы получить эмбеддинги для батча, передадим модели данные и маску\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy()) # преобразуем элементы методом numpy() к типу numpy.array\n",
    "\n",
    "df_ed = pd.DataFrame(np.concatenate(embeddings)) # соберём все эмбеддинги в матрицу признаков вызовом функции concatenate()\n",
    "df_ed['toxic'] = result['toxic'] # добавляем целевой признак\n",
    "df_ed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Совет 🤔:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Обычно размер бача берут 32 или 64/128 (что-то кратное 2^N), чтобы код бежал быстрее.\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарий студента:</b> Про это не знал, в теории про это не было ни слова. Спасибо</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код выше, показывает механизм преобразования эмбеддингов на маленькой выборке. То же самое было расчитано на всем датасете. Прочитаем его."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выгрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ed.to_csv('df_ed_20k.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выгружаем датасет после этапа преобразования в эмбеддинги, для того, чтобы не пересчитывать их в следующий сеанс или на другом устройстве. Выгрузка датасета закомментирована, она не должна больше исполняться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитанные эмбендинги в Colab я сохранил в Яндекс.Диске. Здесь сохранен неполный датасет, порядка 78% от исходного. Прочитаем `csv-файл`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.214180</td>\n",
       "      <td>0.147004</td>\n",
       "      <td>-0.198792</td>\n",
       "      <td>0.039257</td>\n",
       "      <td>-0.117727</td>\n",
       "      <td>-0.340003</td>\n",
       "      <td>-0.144716</td>\n",
       "      <td>0.312527</td>\n",
       "      <td>-0.208113</td>\n",
       "      <td>-0.603441</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.209616</td>\n",
       "      <td>0.381346</td>\n",
       "      <td>0.129333</td>\n",
       "      <td>0.156410</td>\n",
       "      <td>-0.196734</td>\n",
       "      <td>-0.076245</td>\n",
       "      <td>-0.302536</td>\n",
       "      <td>0.222647</td>\n",
       "      <td>0.358534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.352702</td>\n",
       "      <td>0.166299</td>\n",
       "      <td>0.279629</td>\n",
       "      <td>-0.027249</td>\n",
       "      <td>0.170146</td>\n",
       "      <td>-0.320978</td>\n",
       "      <td>0.132645</td>\n",
       "      <td>0.255978</td>\n",
       "      <td>-0.076715</td>\n",
       "      <td>-0.255779</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071787</td>\n",
       "      <td>-0.004774</td>\n",
       "      <td>-0.050075</td>\n",
       "      <td>0.283952</td>\n",
       "      <td>0.130654</td>\n",
       "      <td>-0.132127</td>\n",
       "      <td>-0.168120</td>\n",
       "      <td>0.573513</td>\n",
       "      <td>0.351487</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.390808</td>\n",
       "      <td>0.389703</td>\n",
       "      <td>0.201352</td>\n",
       "      <td>-0.158126</td>\n",
       "      <td>-0.351628</td>\n",
       "      <td>-0.587400</td>\n",
       "      <td>0.745436</td>\n",
       "      <td>0.543038</td>\n",
       "      <td>0.301617</td>\n",
       "      <td>-0.075048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.401640</td>\n",
       "      <td>0.525003</td>\n",
       "      <td>-0.361147</td>\n",
       "      <td>0.151722</td>\n",
       "      <td>0.284467</td>\n",
       "      <td>-0.114487</td>\n",
       "      <td>-0.712322</td>\n",
       "      <td>0.500326</td>\n",
       "      <td>0.233124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.172516</td>\n",
       "      <td>-0.347529</td>\n",
       "      <td>0.091326</td>\n",
       "      <td>0.274101</td>\n",
       "      <td>-0.638771</td>\n",
       "      <td>-0.430128</td>\n",
       "      <td>0.085095</td>\n",
       "      <td>0.347237</td>\n",
       "      <td>-0.185096</td>\n",
       "      <td>-0.064509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003850</td>\n",
       "      <td>0.156936</td>\n",
       "      <td>-0.172188</td>\n",
       "      <td>-0.043264</td>\n",
       "      <td>0.498429</td>\n",
       "      <td>-0.266780</td>\n",
       "      <td>-0.493660</td>\n",
       "      <td>0.516713</td>\n",
       "      <td>0.692796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.525008</td>\n",
       "      <td>-0.264399</td>\n",
       "      <td>-0.078045</td>\n",
       "      <td>-0.365558</td>\n",
       "      <td>-0.029540</td>\n",
       "      <td>-0.140087</td>\n",
       "      <td>0.207137</td>\n",
       "      <td>0.112012</td>\n",
       "      <td>-0.148200</td>\n",
       "      <td>-0.204890</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169026</td>\n",
       "      <td>-0.345219</td>\n",
       "      <td>-0.417685</td>\n",
       "      <td>-0.296221</td>\n",
       "      <td>-0.003516</td>\n",
       "      <td>-0.313758</td>\n",
       "      <td>-0.492042</td>\n",
       "      <td>0.370257</td>\n",
       "      <td>0.604431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121363</th>\n",
       "      <td>-0.212598</td>\n",
       "      <td>0.256898</td>\n",
       "      <td>-0.447700</td>\n",
       "      <td>0.227991</td>\n",
       "      <td>0.286868</td>\n",
       "      <td>-0.134953</td>\n",
       "      <td>0.286301</td>\n",
       "      <td>0.290358</td>\n",
       "      <td>-0.119520</td>\n",
       "      <td>-0.162863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228032</td>\n",
       "      <td>0.299517</td>\n",
       "      <td>-0.117757</td>\n",
       "      <td>0.055547</td>\n",
       "      <td>0.581419</td>\n",
       "      <td>-0.358383</td>\n",
       "      <td>-0.404726</td>\n",
       "      <td>0.595774</td>\n",
       "      <td>0.296562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121364</th>\n",
       "      <td>0.159202</td>\n",
       "      <td>0.578980</td>\n",
       "      <td>0.106536</td>\n",
       "      <td>-0.247540</td>\n",
       "      <td>-0.566379</td>\n",
       "      <td>-0.770876</td>\n",
       "      <td>0.918120</td>\n",
       "      <td>0.894100</td>\n",
       "      <td>0.635024</td>\n",
       "      <td>-0.554825</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121072</td>\n",
       "      <td>0.448461</td>\n",
       "      <td>-0.421211</td>\n",
       "      <td>-0.195475</td>\n",
       "      <td>0.213188</td>\n",
       "      <td>-0.265779</td>\n",
       "      <td>-0.492184</td>\n",
       "      <td>0.749388</td>\n",
       "      <td>0.467811</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121365</th>\n",
       "      <td>-0.183408</td>\n",
       "      <td>-0.071542</td>\n",
       "      <td>-0.303102</td>\n",
       "      <td>-0.209128</td>\n",
       "      <td>-0.538787</td>\n",
       "      <td>-0.419055</td>\n",
       "      <td>0.380409</td>\n",
       "      <td>0.182944</td>\n",
       "      <td>0.382511</td>\n",
       "      <td>-0.468929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184913</td>\n",
       "      <td>-0.053646</td>\n",
       "      <td>-0.508643</td>\n",
       "      <td>-0.307283</td>\n",
       "      <td>0.272276</td>\n",
       "      <td>-0.089274</td>\n",
       "      <td>0.003302</td>\n",
       "      <td>0.500062</td>\n",
       "      <td>0.727596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121366</th>\n",
       "      <td>-0.865203</td>\n",
       "      <td>-0.198704</td>\n",
       "      <td>-0.309393</td>\n",
       "      <td>-0.249649</td>\n",
       "      <td>-0.151374</td>\n",
       "      <td>0.112604</td>\n",
       "      <td>0.326239</td>\n",
       "      <td>0.257939</td>\n",
       "      <td>-0.153978</td>\n",
       "      <td>-0.107524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156371</td>\n",
       "      <td>-0.256471</td>\n",
       "      <td>-0.130817</td>\n",
       "      <td>0.261458</td>\n",
       "      <td>-0.010640</td>\n",
       "      <td>-0.337773</td>\n",
       "      <td>-0.589161</td>\n",
       "      <td>0.084944</td>\n",
       "      <td>0.195185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121367</th>\n",
       "      <td>-0.350851</td>\n",
       "      <td>0.153475</td>\n",
       "      <td>-0.000659</td>\n",
       "      <td>-0.175750</td>\n",
       "      <td>0.097799</td>\n",
       "      <td>-0.125996</td>\n",
       "      <td>0.166500</td>\n",
       "      <td>0.109540</td>\n",
       "      <td>-0.282164</td>\n",
       "      <td>-0.295945</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013262</td>\n",
       "      <td>-0.041247</td>\n",
       "      <td>0.148737</td>\n",
       "      <td>0.262797</td>\n",
       "      <td>0.274336</td>\n",
       "      <td>-0.072843</td>\n",
       "      <td>-0.352375</td>\n",
       "      <td>0.213584</td>\n",
       "      <td>0.661390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121368 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0      -0.214180  0.147004 -0.198792  0.039257 -0.117727 -0.340003 -0.144716   \n",
       "1       0.352702  0.166299  0.279629 -0.027249  0.170146 -0.320978  0.132645   \n",
       "2      -0.390808  0.389703  0.201352 -0.158126 -0.351628 -0.587400  0.745436   \n",
       "3      -0.172516 -0.347529  0.091326  0.274101 -0.638771 -0.430128  0.085095   \n",
       "4      -0.525008 -0.264399 -0.078045 -0.365558 -0.029540 -0.140087  0.207137   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "121363 -0.212598  0.256898 -0.447700  0.227991  0.286868 -0.134953  0.286301   \n",
       "121364  0.159202  0.578980  0.106536 -0.247540 -0.566379 -0.770876  0.918120   \n",
       "121365 -0.183408 -0.071542 -0.303102 -0.209128 -0.538787 -0.419055  0.380409   \n",
       "121366 -0.865203 -0.198704 -0.309393 -0.249649 -0.151374  0.112604  0.326239   \n",
       "121367 -0.350851  0.153475 -0.000659 -0.175750  0.097799 -0.125996  0.166500   \n",
       "\n",
       "               7         8         9  ...       759       760       761  \\\n",
       "0       0.312527 -0.208113 -0.603441  ... -0.209616  0.381346  0.129333   \n",
       "1       0.255978 -0.076715 -0.255779  ... -0.071787 -0.004774 -0.050075   \n",
       "2       0.543038  0.301617 -0.075048  ... -0.401640  0.525003 -0.361147   \n",
       "3       0.347237 -0.185096 -0.064509  ...  0.003850  0.156936 -0.172188   \n",
       "4       0.112012 -0.148200 -0.204890  ... -0.169026 -0.345219 -0.417685   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "121363  0.290358 -0.119520 -0.162863  ...  0.228032  0.299517 -0.117757   \n",
       "121364  0.894100  0.635024 -0.554825  ... -0.121072  0.448461 -0.421211   \n",
       "121365  0.182944  0.382511 -0.468929  ... -0.184913 -0.053646 -0.508643   \n",
       "121366  0.257939 -0.153978 -0.107524  ...  0.156371 -0.256471 -0.130817   \n",
       "121367  0.109540 -0.282164 -0.295945  ... -0.013262 -0.041247  0.148737   \n",
       "\n",
       "             762       763       764       765       766       767  toxic  \n",
       "0       0.156410 -0.196734 -0.076245 -0.302536  0.222647  0.358534      0  \n",
       "1       0.283952  0.130654 -0.132127 -0.168120  0.573513  0.351487      1  \n",
       "2       0.151722  0.284467 -0.114487 -0.712322  0.500326  0.233124      1  \n",
       "3      -0.043264  0.498429 -0.266780 -0.493660  0.516713  0.692796      0  \n",
       "4      -0.296221 -0.003516 -0.313758 -0.492042  0.370257  0.604431      0  \n",
       "...          ...       ...       ...       ...       ...       ...    ...  \n",
       "121363  0.055547  0.581419 -0.358383 -0.404726  0.595774  0.296562      0  \n",
       "121364 -0.195475  0.213188 -0.265779 -0.492184  0.749388  0.467811      1  \n",
       "121365 -0.307283  0.272276 -0.089274  0.003302  0.500062  0.727596      0  \n",
       "121366  0.261458 -0.010640 -0.337773 -0.589161  0.084944  0.195185      0  \n",
       "121367  0.262797  0.274336 -0.072843 -0.352375  0.213584  0.661390      0  \n",
       "\n",
       "[121368 rows x 769 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# используем api \n",
    "base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?' \n",
    "public_key = 'https://disk.yandex.ru/d/KLot7E--emZcKg' \n",
    " \n",
    "# получаем url \n",
    "final_url = base_url + urlencode(dict(public_key=public_key)) \n",
    "response = requests.get(final_url) \n",
    "download_url = response.json()['href'] \n",
    " \n",
    "# загружаем файл в df \n",
    "download_response = requests.get(download_url)\n",
    "df_ed_78 = pd.read_csv(download_url, sep=',')\n",
    "df_ed_78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ed_78 = df_ed_78.astype('float32') #меняем тип - чтобы при работе с данными требовалось меньше памяти\n",
    "df_ed_78['toxic'] = df_ed_78['toxic'].astype('int16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение для BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ограничение датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как датасет получается тяжелым, чтобы была возможность на его данных провести обучение, их нужно немного разделить. Сделаем это с помощью `train_test_split`, чтобы сохранить соотношение в целевом признаке.\n",
    "\n",
    "Таблица `out` - это таблица неиспользуемых данных. Их слишком много, чтобы оборудование было способно их обработать.\n",
    "\n",
    "Соотношение 0.1 - это 10% на второй сет в сплите, то есть порядка 12 тысяч строк будет при таком соотношении во втором датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, df_ed = train_test_split(df_ed_78, test_size=0.1, random_state=RANDOM_STATE, stratify= df_ed_78['toxic']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12137 entries, 39465 to 20976\n",
      "Columns: 769 entries, 0 to toxic\n",
      "dtypes: float32(768), int16(1)\n",
      "memory usage: 35.7 MB\n"
     ]
    }
   ],
   "source": [
    "df_ed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разбиение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split( #создаем 4 датасета, два признаков (тест+валидация) и два целевых, \n",
    "    df_ed.drop(columns='toxic'), #для датасетов признаков удаляем целевой\n",
    "    df_ed['toxic'], #для целевого оставляем только целевой\n",
    "    test_size=0.2, #с соотношением \n",
    "    random_state=RANDOM_STATE, #с заданной опорой для рандома \n",
    "    stratify= df_ed['toxic']) #с заданной стратификацией по целевому признаку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для модели логистической регрессии с использованием кросс-валидации: {'max_iter': 800, 'C': 0.8}\n",
      "Наибольшее значение метрики F1 для модели логистической регрессии при лучших гиперпараметрах с использованием кросс-валидации: 0.6494990514316098\n",
      "CPU times: total: 3.25 s\n",
      "Wall time: 37.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "log_reg = LogisticRegression(solver='liblinear', random_state=RANDOM_STATE, class_weight= 'balanced') #максимальное количество итераций 1000, \n",
    "parameters = {'max_iter': range (100, 1000, 100), 'C': np.arange(0.1, 1.0, 0.1)} #перебор гиперпараметров\n",
    "rand_log_reg = RandomizedSearchCV(log_reg, n_iter=20, param_distributions= parameters, scoring='f1', n_jobs= -3, cv=3)\n",
    "rand_log_reg.fit(features_train, target_train.values)\n",
    "\n",
    "best_log_reg = rand_log_reg.best_score_\n",
    "\n",
    "print(\"Лучшие параметры для модели логистической регрессии с \"\\\n",
    "    \"использованием кросс-валидации:\", rand_log_reg.best_params_)\n",
    "print(\"Наибольшее значение метрики F1 для модели логистической регрессии \"\\\n",
    "    \"при лучших гиперпараметрах с использованием кросс-валидации:\", best_log_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Ошибка:\n",
    "\n",
    "\n",
    "Не забываем при инициализации модели о random_state, иначе после каждого запуска кода у нас может быть разный результат. Это касается очень многих моделей\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарий студента:</b> Справедливо, исправил</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель опорных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для модели SVC с использованием кросс-валидации: {'C': 0.05}\n",
      "Наибольшее значение метрики F1 для модели SVC при лучших гиперпараметрах с использованием кросс-валидации: 0.6227423902616643\n",
      "CPU times: total: 7.28 s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "svclassifier = SVC(kernel='linear', random_state=RANDOM_STATE, class_weight= 'balanced') #максимальное количество итераций 1000, \n",
    "parameters = {'C': np.arange(0.05, 1.0, 0.05)} #перебор гиперпараметров\n",
    "rand_svclassifier = RandomizedSearchCV(svclassifier, n_iter=10, param_distributions= parameters, scoring='f1', n_jobs= -3, cv=3)\n",
    "rand_svclassifier.fit(features_train, target_train.values)\n",
    "\n",
    "best_svclassifier = rand_svclassifier.best_score_\n",
    "\n",
    "print(\"Лучшие параметры для модели SVC с \"\\\n",
    "    \"использованием кросс-валидации:\", rand_svclassifier.best_params_)\n",
    "print(\"Наибольшее значение метрики F1 для модели SVC \"\\\n",
    "    \"при лучших гиперпараметрах с использованием кросс-валидации:\", best_svclassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для модели случайного леса с использованием кросс-валидации: {'n_estimators': 6, 'max_depth': 7}\n",
      "Наибольшее значение метрики F1 для модели случайного леса при лучших гиперпараметрах с использованием кросс-валидации: 0.5553040863929963\n",
      "CPU times: total: 609 ms\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "forest = RandomForestClassifier(random_state=RANDOM_STATE, class_weight= 'balanced') #модель случайного леса\n",
    "parameters = {'n_estimators': range (1, 300), 'max_depth': range (1, 50)} #перебор гиперпараметров\n",
    "#применение метода гридсёрч со встроенной кросс-валидацией к модели леса с перебором указанных параметров\n",
    "\n",
    "randomized_forest = RandomizedSearchCV(forest, n_iter=20, param_distributions= parameters, scoring='f1', n_jobs= -3, cv=5)\n",
    "#обучение модели\n",
    "randomized_forest.fit(features_train, target_train.values)\n",
    "\n",
    "#лучшее значение после перебора параметров \n",
    "best_forest = randomized_forest.best_score_\n",
    "\n",
    "print(\"Лучшие параметры для модели случайного леса с \"\\\n",
    "    \"использованием кросс-валидации:\", randomized_forest.best_params_)\n",
    "print(\"Наибольшее значение метрики F1 для модели случайного леса \"\\\n",
    "    \"при лучших гиперпараметрах с использованием кросс-валидации:\", best_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для модели LGBMClassifier с использованием кросс-валидации: {'n_estimators': 592, 'max_depth': 69, 'learning_rate': 0.35000000000000003}\n",
      "Наибольшее значение метрики F1 для модели LGBMClassifier при лучших гиперпараметрах с использованием кросс-валидации: 0.6702944547451882\n",
      "CPU times: total: 1min 9s\n",
      "Wall time: 9min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgbm = lgb.LGBMClassifier(class_weight= 'balanced') #\n",
    "parameters = {'n_estimators': range (1, 1000), 'max_depth': range (1, 100), 'learning_rate': np.arange(0.05, 0.5, 0.05)}\n",
    "#применение метода гридсёрч со встроенной кросс-валидацией\n",
    "\n",
    "rand_lgbm = RandomizedSearchCV(lgbm, n_iter=20, param_distributions= parameters, scoring='f1', n_jobs= -3, cv=5)\n",
    "#обучение модели\n",
    "rand_lgbm.fit(features_train, target_train.values)\n",
    "\n",
    "#лучшее значение после перебора параметров \n",
    "best_lgbm = rand_lgbm.best_score_\n",
    "\n",
    "print(\"Лучшие параметры для модели LGBMClassifier с \"\\\n",
    "    \"использованием кросс-валидации:\", rand_lgbm.best_params_)\n",
    "print(\"Наибольшее значение метрики F1 для модели LGBMClassifier \"\\\n",
    "    \"при лучших гиперпараметрах с использованием кросс-валидации:\", best_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по методу BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>Значение метрики F1</th>\n",
       "      <th>Время расчета (~10 000 строк)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Логистическая регрессия</td>\n",
       "      <td>0.649499</td>\n",
       "      <td>~1 минута</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Модель опорных векторов</td>\n",
       "      <td>0.622742</td>\n",
       "      <td>~1.5 минут</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Случайный лес</td>\n",
       "      <td>0.555304</td>\n",
       "      <td>~3 минуты</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.670294</td>\n",
       "      <td>~10 минут</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Модель  Значение метрики F1 Время расчета (~10 000 строк)\n",
       "0  Логистическая регрессия             0.649499                     ~1 минута\n",
       "1  Модель опорных векторов             0.622742                    ~1.5 минут\n",
       "2            Случайный лес             0.555304                     ~3 минуты\n",
       "3           LGBMClassifier             0.670294                     ~10 минут"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = ['Логистическая регрессия', 'Модель опорных векторов', 'Случайный лес', 'LGBMClassifier']\n",
    "F1 = [best_log_reg, best_svclassifier, best_forest, best_lgbm]\n",
    "total_time = ['~1 минута', '~1.5 минут', '~3 минуты', '~10 минут']\n",
    "\n",
    "bert_result_table = pd.DataFrame({ #созаем датафрейм\n",
    "    'Модель': models, #\n",
    "    'Значение метрики F1': F1,\n",
    "    'Время расчета (~10 000 строк)': total_time\n",
    "}) #\n",
    "bert_result_table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили довольно неплохие показатели метрики `F1` на модели `LGBMClassifier`, самые высокие для метода `BERT` для сильно урезанной выборки. В то же время, модель самая медленная. Модели векторов и регрессии обучаются на порядок быстрее, а значение метрики уступает совсем немного. Модель леса показывает очень плохой результат: она не быстрая и с низким зачеством метрики `F1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "\n",
    "\n",
    "Здорово Что использовал коллаб и GPU.  Если хочешь всё-таки попробовать получить метрику выше то можно сделать перебор гиперпараметров модели, или/и используй toxic-bert\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка важности слова определяется величиной `TF-IDF`. `TF` отвечает за количество упоминаний слова в отдельном тексте, а `IDF` отражает частоту его употребления во всём корпусе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подгрузка необходимых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df.copy() #исходный датасет, до преобразований BERTa\n",
    "df_check = df.sample(200) #таблица для проверки работоспособности лемматизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\maxpe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\maxpe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\maxpe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maxpe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#загружаем необходимые дополнения для библиотеки\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet') \n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None #убираем предупреждения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция очистки текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "\n",
    "    def limit(text):\n",
    "        #убираем из комментариев слова длиной от 50 до 10000 символов\n",
    "        #это ограничение необходимо, т.к. есть \"слово\", ломающее лемматизатор\n",
    "        lim = re.sub(r'\\b\\w{50,10000}\\b', ' ', text) \n",
    "        lim1 = \" \".join(lim.split()) #применяем фильтр\n",
    "        return lim1\n",
    "\n",
    "    clear = re.sub(r'[^a-zA-Z ]', ' ', limit(text)) #фильтруем латиницу, символы\n",
    "    clear1 = \" \".join(clear.split()) #применяем фильтр\n",
    "    return clear1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Лемматизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    #лемматизируем текст с помощью лемматизатора предложений из пакета pywsd\n",
    "    lemma = lemmatize_sentence(text) \n",
    "    return \" \".join(lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизатор, так же как и преобразование эмбеддингов, считается довольно долго, порядка 50 минут. Ниже лемматизирован кусочек из 100 строк оригинальной таблицы, чтобы показать работу лемматизатора.\n",
    "\n",
    "Полный датасет рассчитан заранее и загружается после проверки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 33284.16it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 69.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115799</th>\n",
       "      <td>Placenames with numbers \\n\\nPerhaps include Nu...</td>\n",
       "      <td>0</td>\n",
       "      <td>placenames with number perhaps include number ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33157</th>\n",
       "      <td>\"\\n\\n Gendergap v gender gap \\n\\nRe this edit ...</td>\n",
       "      <td>0</td>\n",
       "      <td>gendergap v gender gap re this edit i personal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7547</th>\n",
       "      <td>Please - DON'T ERASE CONTENT WITHOUT DISCUSSION.</td>\n",
       "      <td>0</td>\n",
       "      <td>please don t erase content without discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44180</th>\n",
       "      <td>Illegal usernames \\nPersonally I think this ap...</td>\n",
       "      <td>0</td>\n",
       "      <td>illegal usernames personally i think this appr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143265</th>\n",
       "      <td>One should add that a user who has been given ...</td>\n",
       "      <td>0</td>\n",
       "      <td>one should add that a user who have be give a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "115799  Placenames with numbers \\n\\nPerhaps include Nu...      0   \n",
       "33157   \"\\n\\n Gendergap v gender gap \\n\\nRe this edit ...      0   \n",
       "7547     Please - DON'T ERASE CONTENT WITHOUT DISCUSSION.      0   \n",
       "44180   Illegal usernames \\nPersonally I think this ap...      0   \n",
       "143265  One should add that a user who has been given ...      0   \n",
       "\n",
       "                                                    lemma  \n",
       "115799  placenames with number perhaps include number ...  \n",
       "33157   gendergap v gender gap re this edit i personal...  \n",
       "7547        please don t erase content without discussion  \n",
       "44180   illegal usernames personally i think this appr...  \n",
       "143265  one should add that a user who have be give a ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df_check['lemma'] = df_check['text'].progress_apply(clear_text) #повторяем очистку, т.к. датасет - другой\n",
    "df_check['lemma'] = df_check['lemma'].progress_apply(lemmatize_text) #лемматизируем текст\n",
    "df_check.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "\n",
    "- Лематизация удалась. Отличная библиотека pywsd, хотя впервые  вижу ее использование\n",
    "\n",
    "\n",
    "\n",
    "- Плюс за использование apply, неэффективные циклы нам ни к чему.\n",
    "\n",
    "\n",
    "- Да, всегда лучше проверить что получилось  в итоге, так всегда будет возможность поправить ошбку\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "- попробуй .progress_apply, делает что .apply, но еще и показывает на какой итерации находится процесс\n",
    "\n",
    "\n",
    "    \n",
    "- после очистки и лемитизации можно провести частотный анализ текста/[облако слов](https://habr.com/ru/post/517410/) - чтобы получить общее представление о тематике и о наиболее часто встерчаемых словах Кроме того графики, рисунки делают проект визуально интересней\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выгрузка датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же, как и с таблицей после преобразования эмбеддингов `df_ed`, этот датасет был выгружен один раз, после чего вывод таблицы - закомментирован. \n",
    "\n",
    "Лемматизировался полный датасет `df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dft.to_csv('df_lemma.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка лемматизированного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and for the second time of ask when your view ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>you should be ashamed of yourself that be a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>spitzer umm theres no actual article for prost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and it look like it be actually you who put on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>and i really don t think you understand i come...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...      0   \n",
       "1       D'aww! He matches this background colour I'm s...      0   \n",
       "2       Hey man, I'm really not trying to edit war. It...      0   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4       You, sir, are my hero. Any chance you remember...      0   \n",
       "...                                                   ...    ...   \n",
       "159287  \":::::And for the second time of asking, when ...      0   \n",
       "159288  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "159289  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
       "159290  And it looks like it was actually you who put ...      0   \n",
       "159291  \"\\nAnd ... I really don't think you understand...      0   \n",
       "\n",
       "                                                    lemma  \n",
       "0       explanation why the edits make under my userna...  \n",
       "1       d aww he match this background colour i m seem...  \n",
       "2       hey man i m really not try to edit war it s ju...  \n",
       "3       more i can t make any real suggestion on impro...  \n",
       "4       you sir be my hero any chance you remember wha...  \n",
       "...                                                   ...  \n",
       "159287  and for the second time of ask when your view ...  \n",
       "159288  you should be ashamed of yourself that be a ho...  \n",
       "159289  spitzer umm theres no actual article for prost...  \n",
       "159290  and it look like it be actually you who put on...  \n",
       "159291  and i really don t think you understand i come...  \n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# используем api \n",
    "base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?' \n",
    "public_key = 'https://disk.yandex.ru/d/zNN-U7f8m-UaaQ' \n",
    " \n",
    "# получаем url \n",
    "final_url = base_url + urlencode(dict(public_key=public_key)) \n",
    "response = requests.get(final_url) \n",
    "download_url = response.json()['href'] \n",
    " \n",
    "# загружаем файл в df \n",
    "download_response = requests.get(download_url)\n",
    "df_lem = pd.read_csv(download_url, sep=',')\n",
    "df_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      " 2   lemma   159281 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_lem.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, появились пустые значения в столбце `lemma`, это значит, что там были только такие символы, которые не пропустил фильтр. Их нужно убрать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lem.dropna(inplace=True)\n",
    "df_lem = df_lem.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Облако слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После очистки текста, можем просмотреть наиболее часто встречающиеся слова в датасете. Для этого сначала токенизируем текст - разобьем на составные части.\n",
    "\n",
    "Облако слов будем делать на отдельном датасете, чтобы не перегружать рабочий. Эти данные в обучении не пригодятся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemma</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159276</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and for the second time of ask when your view ...</td>\n",
       "      <td>and for the second time of ask when your view ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159277</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>you should be ashamed of yourself that be a ho...</td>\n",
       "      <td>you should be ashamed of yourself that be a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159278</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>spitzer umm theres no actual article for prost...</td>\n",
       "      <td>spitzer umm theres no actual article for prost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159279</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and it look like it be actually you who put on...</td>\n",
       "      <td>and it look like it be actually you who put on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159280</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>and i really don t think you understand i come...</td>\n",
       "      <td>and i really don t think you understand i come...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159281 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...      0   \n",
       "1       D'aww! He matches this background colour I'm s...      0   \n",
       "2       Hey man, I'm really not trying to edit war. It...      0   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4       You, sir, are my hero. Any chance you remember...      0   \n",
       "...                                                   ...    ...   \n",
       "159276  \":::::And for the second time of asking, when ...      0   \n",
       "159277  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "159278  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
       "159279  And it looks like it was actually you who put ...      0   \n",
       "159280  \"\\nAnd ... I really don't think you understand...      0   \n",
       "\n",
       "                                                    lemma  \\\n",
       "0       explanation why the edits make under my userna...   \n",
       "1       d aww he match this background colour i m seem...   \n",
       "2       hey man i m really not try to edit war it s ju...   \n",
       "3       more i can t make any real suggestion on impro...   \n",
       "4       you sir be my hero any chance you remember wha...   \n",
       "...                                                   ...   \n",
       "159276  and for the second time of ask when your view ...   \n",
       "159277  you should be ashamed of yourself that be a ho...   \n",
       "159278  spitzer umm theres no actual article for prost...   \n",
       "159279  and it look like it be actually you who put on...   \n",
       "159280  and i really don t think you understand i come...   \n",
       "\n",
       "                                                   tokens  \n",
       "0       explanation why the edits make under my userna...  \n",
       "1       d aww he match this background colour i m seem...  \n",
       "2       hey man i m really not try to edit war it s ju...  \n",
       "3       more i can t make any real suggestion on impro...  \n",
       "4       you sir be my hero any chance you remember wha...  \n",
       "...                                                   ...  \n",
       "159276  and for the second time of ask when your view ...  \n",
       "159277  you should be ashamed of yourself that be a ho...  \n",
       "159278  spitzer umm theres no actual article for prost...  \n",
       "159279  and it look like it be actually you who put on...  \n",
       "159280  and i really don t think you understand i come...  \n",
       "\n",
       "[159281 rows x 4 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cloud = df_lem.copy()\n",
    "df_cloud['tokens'] = df_cloud['lemma']\n",
    "df_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159281/159281 [00:33<00:00, 4709.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemma</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55335</th>\n",
       "      <td>\"45, 5 June 2006 (UTC) \\n\\nYou need to explain...</td>\n",
       "      <td>0</td>\n",
       "      <td>june utc you need to explain why we belong tog...</td>\n",
       "      <td>[june, utc, you, need, to, explain, why, we, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3407</th>\n",
       "      <td>Water controversy \\n\\nThis needs to be expande...</td>\n",
       "      <td>0</td>\n",
       "      <td>water controversy this need to be expand but i...</td>\n",
       "      <td>[water, controversy, this, need, to, be, expan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60264</th>\n",
       "      <td>Yep, I was thinking of it myself, and would ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>yep i be think of it myself and would have do ...</td>\n",
       "      <td>[yep, i, be, think, of, it, myself, and, would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94698</th>\n",
       "      <td>\"\\n\\n Is Brian really an atheist? \\n\\nIn the r...</td>\n",
       "      <td>0</td>\n",
       "      <td>be brian really an atheist in the recently air...</td>\n",
       "      <td>[be, brian, really, an, atheist, in, the, rece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149716</th>\n",
       "      <td>This is already in the article. - Ghost</td>\n",
       "      <td>0</td>\n",
       "      <td>this be already in the article ghost</td>\n",
       "      <td>[this, be, already, in, the, article, ghost]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "55335   \"45, 5 June 2006 (UTC) \\n\\nYou need to explain...      0   \n",
       "3407    Water controversy \\n\\nThis needs to be expande...      0   \n",
       "60264   Yep, I was thinking of it myself, and would ha...      0   \n",
       "94698   \"\\n\\n Is Brian really an atheist? \\n\\nIn the r...      0   \n",
       "149716            This is already in the article. - Ghost      0   \n",
       "\n",
       "                                                    lemma  \\\n",
       "55335   june utc you need to explain why we belong tog...   \n",
       "3407    water controversy this need to be expand but i...   \n",
       "60264   yep i be think of it myself and would have do ...   \n",
       "94698   be brian really an atheist in the recently air...   \n",
       "149716               this be already in the article ghost   \n",
       "\n",
       "                                                   tokens  \n",
       "55335   [june, utc, you, need, to, explain, why, we, b...  \n",
       "3407    [water, controversy, this, need, to, be, expan...  \n",
       "60264   [yep, i, be, think, of, it, myself, and, would...  \n",
       "94698   [be, brian, really, an, atheist, in, the, rece...  \n",
       "149716       [this, be, already, in, the, article, ghost]  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cloud['tokens'] = [','.join(map(str, l)) for l in df_cloud['tokens']]\n",
    "df_cloud['tokens'] = df_cloud['lemma'].progress_apply(word_tokenize) #лемматизируем текст\n",
    "df_cloud.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('explanation',\n",
       " 'd',\n",
       " 'hey',\n",
       " 'more',\n",
       " 'you',\n",
       " 'congratulation',\n",
       " 'cocksucker',\n",
       " 'your',\n",
       " 'sorry',\n",
       " 'alignment',\n",
       " 'fair',\n",
       " 'bbq',\n",
       " 'hey',\n",
       " 'before',\n",
       " 'oh',\n",
       " 'juelz',\n",
       " 'bye',\n",
       " 'redirect',\n",
       " 'the',\n",
       " 'don',\n",
       " 'regard',\n",
       " 'good',\n",
       " 'snowflake',\n",
       " 'the',\n",
       " 're',\n",
       " 'radial',\n",
       " 'there',\n",
       " 'yes',\n",
       " 'ok',\n",
       " 'a',\n",
       " 'how',\n",
       " 'not',\n",
       " 'praise',\n",
       " 'i',\n",
       " 'well',\n",
       " 'not',\n",
       " 'mainland',\n",
       " 'pretty',\n",
       " 'hi',\n",
       " 'notability',\n",
       " 'sure',\n",
       " 'tfd',\n",
       " 'you',\n",
       " 'fuck',\n",
       " 'i',\n",
       " 'i',\n",
       " 'you',\n",
       " 'in',\n",
       " 'a',\n",
       " 'jmabel',\n",
       " 'bi',\n",
       " 'get',\n",
       " 'are',\n",
       " 'thanks',\n",
       " 'awesome',\n",
       " 'stupid',\n",
       " 'tony',\n",
       " 'ga',\n",
       " 'my',\n",
       " 'why',\n",
       " 'lock',\n",
       " 'a',\n",
       " 'redirect',\n",
       " 'christian',\n",
       " 'dh',\n",
       " 'all',\n",
       " 'neiln',\n",
       " 'i',\n",
       " 'there',\n",
       " 'parzival',\n",
       " 'oppose',\n",
       " 'i',\n",
       " 'they',\n",
       " 'ambiguous',\n",
       " 'while',\n",
       " 'take',\n",
       " 'that',\n",
       " 'in',\n",
       " 'december',\n",
       " 'hi',\n",
       " 'minimization',\n",
       " 'be',\n",
       " 'screwjob',\n",
       " 'april',\n",
       " 'christ',\n",
       " 'can',\n",
       " 'would',\n",
       " 'oh',\n",
       " 'website',\n",
       " 'thanks',\n",
       " 'personal',\n",
       " 'transliteration',\n",
       " 'almost',\n",
       " 'how',\n",
       " 'lack',\n",
       " 'thanks',\n",
       " 'hi',\n",
       " 'collusion',\n",
       " 'thanks',\n",
       " 'you',\n",
       " 'however',\n",
       " 'check',\n",
       " 'i',\n",
       " 'well',\n",
       " 'what',\n",
       " 'a',\n",
       " 'i',\n",
       " 'what',\n",
       " 'i',\n",
       " 'welcome',\n",
       " 'include',\n",
       " 'comment',\n",
       " 'czech',\n",
       " 'thanks',\n",
       " 'paleontologist',\n",
       " 'also',\n",
       " 'bigfoot',\n",
       " 'also',\n",
       " 'chart',\n",
       " 'hahahaha',\n",
       " 'have',\n",
       " 'conformity',\n",
       " 'hi',\n",
       " 'should',\n",
       " 'sandbox',\n",
       " 'heh',\n",
       " 'ahh',\n",
       " 'ok',\n",
       " 'on',\n",
       " 'the',\n",
       " 'sorry',\n",
       " 'tcm',\n",
       " 'well',\n",
       " 'a',\n",
       " 'meivazhi',\n",
       " 'though',\n",
       " 'yeah',\n",
       " 'image',\n",
       " 'a',\n",
       " 'lmao',\n",
       " 'december',\n",
       " 'new',\n",
       " 'reply',\n",
       " 'p',\n",
       " 'the',\n",
       " 'opinion',\n",
       " 'azari',\n",
       " 'userbox',\n",
       " 'if',\n",
       " 'from',\n",
       " 'socialistm',\n",
       " 'sorry',\n",
       " 'the',\n",
       " 'pd',\n",
       " 'we',\n",
       " 'military',\n",
       " 'between',\n",
       " 'your',\n",
       " 'once',\n",
       " 'unblock',\n",
       " 'attribute',\n",
       " 'actually',\n",
       " 'katelyn',\n",
       " 'fradulent',\n",
       " 'that',\n",
       " 'july',\n",
       " 'and',\n",
       " 'hi',\n",
       " 'you',\n",
       " 'it',\n",
       " 'a',\n",
       " 'note',\n",
       " 'friesers',\n",
       " 'oh',\n",
       " 'lois',\n",
       " 'know',\n",
       " 'i',\n",
       " 'may',\n",
       " 'sorry',\n",
       " 'reply',\n",
       " 'august',\n",
       " 'you',\n",
       " 'eta',\n",
       " 'new',\n",
       " 'december',\n",
       " 'please',\n",
       " 'correct',\n",
       " 'i',\n",
       " 'george',\n",
       " 'sorry',\n",
       " 'absolutely',\n",
       " 'i',\n",
       " 'editor',\n",
       " 'about',\n",
       " 'sockpuppets',\n",
       " 'oh',\n",
       " 'review',\n",
       " 'i',\n",
       " 'homosexual',\n",
       " 'al',\n",
       " 'link',\n",
       " 'your',\n",
       " 'reliable',\n",
       " 'i',\n",
       " 'a',\n",
       " 'i',\n",
       " 'give',\n",
       " 'invite',\n",
       " 'i',\n",
       " 'say',\n",
       " 'i',\n",
       " 'fuck',\n",
       " 'attack',\n",
       " 'please',\n",
       " 'randroide',\n",
       " 'hence',\n",
       " 'pirate',\n",
       " 'and',\n",
       " 'kill',\n",
       " 'new',\n",
       " 'regard',\n",
       " 'december',\n",
       " 'you',\n",
       " 'i',\n",
       " 'please',\n",
       " 'an',\n",
       " 'i',\n",
       " 'very',\n",
       " 'http',\n",
       " 'the',\n",
       " 'i',\n",
       " 'burn',\n",
       " 'decesed',\n",
       " 'fatima',\n",
       " 'i',\n",
       " 'please',\n",
       " 'well',\n",
       " 'i',\n",
       " 'u',\n",
       " 'it',\n",
       " 'deletion',\n",
       " 'listas',\n",
       " 'bad',\n",
       " 'more',\n",
       " 'hi',\n",
       " 'it',\n",
       " 'thanks',\n",
       " 'and',\n",
       " 'and',\n",
       " 'it',\n",
       " 'some',\n",
       " 'yes',\n",
       " 'anyone',\n",
       " 'gore',\n",
       " 'pls',\n",
       " 'neither',\n",
       " 'a',\n",
       " 'for',\n",
       " 'same',\n",
       " 'y',\n",
       " 'thanks',\n",
       " 'if',\n",
       " 'i',\n",
       " 'citation',\n",
       " 'education',\n",
       " 'until',\n",
       " 'we',\n",
       " 'could',\n",
       " 'atheism',\n",
       " 'you',\n",
       " 'you',\n",
       " 'thanks',\n",
       " 'german',\n",
       " 'i',\n",
       " 'i',\n",
       " 'i',\n",
       " 'block',\n",
       " 'i',\n",
       " 'hey',\n",
       " 'i',\n",
       " 'change',\n",
       " 'utc',\n",
       " 'because',\n",
       " 'yes',\n",
       " 'get',\n",
       " 'keep',\n",
       " 'and',\n",
       " 'the',\n",
       " 'level',\n",
       " 'i',\n",
       " 'another',\n",
       " 'article',\n",
       " 'i',\n",
       " 'yes',\n",
       " 'i',\n",
       " 'this',\n",
       " 'it',\n",
       " 'image',\n",
       " 'fuck',\n",
       " 'how',\n",
       " 'well',\n",
       " 'orangemike',\n",
       " 'window',\n",
       " 'btw',\n",
       " 'i',\n",
       " 'shiny',\n",
       " 'will',\n",
       " 'thanks',\n",
       " 'appearance',\n",
       " 'cu',\n",
       " 'per',\n",
       " 'i',\n",
       " 'fuck',\n",
       " 'sorry',\n",
       " 'february',\n",
       " 'best',\n",
       " 'i',\n",
       " 'please',\n",
       " 'keep',\n",
       " 'the',\n",
       " 'over',\n",
       " 's',\n",
       " 'the',\n",
       " 'to',\n",
       " 'matt',\n",
       " 'lol',\n",
       " 'mfd',\n",
       " 'redirect',\n",
       " 'who',\n",
       " 'http',\n",
       " 'god',\n",
       " 'hello',\n",
       " 'i',\n",
       " 'unsure',\n",
       " 'marvin',\n",
       " 'have',\n",
       " 'rfa',\n",
       " 'when',\n",
       " 'this',\n",
       " 'rr',\n",
       " 'i',\n",
       " 'yes',\n",
       " 'thank',\n",
       " 'yes',\n",
       " 'fuck',\n",
       " 'yes',\n",
       " 'okay',\n",
       " 'north',\n",
       " 'the',\n",
       " 'jayjg',\n",
       " 'no',\n",
       " 'future',\n",
       " 'in',\n",
       " 'that',\n",
       " 'okay',\n",
       " 'there',\n",
       " 'after',\n",
       " 'i',\n",
       " 'i',\n",
       " 'ok',\n",
       " 'oppose',\n",
       " 'history',\n",
       " 'please',\n",
       " 'i',\n",
       " 'are',\n",
       " 'congratulation',\n",
       " 'paula',\n",
       " 'it',\n",
       " 'hate',\n",
       " 'page',\n",
       " 'your',\n",
       " 'npov',\n",
       " 'upgrade',\n",
       " 'a',\n",
       " 'ok',\n",
       " 'pov',\n",
       " 'redirect',\n",
       " 'wp',\n",
       " 'be',\n",
       " 'the',\n",
       " 'what',\n",
       " 'redirect',\n",
       " 'just',\n",
       " 'some',\n",
       " 'the',\n",
       " 'ho',\n",
       " 'i',\n",
       " 'hey',\n",
       " 'and',\n",
       " 'be',\n",
       " 'they',\n",
       " 'april',\n",
       " 'dear',\n",
       " 'you',\n",
       " 'peter',\n",
       " 'rfc',\n",
       " 'i',\n",
       " 'and',\n",
       " 'canon',\n",
       " 'capitalization',\n",
       " 'see',\n",
       " 'if',\n",
       " 'please',\n",
       " 'rant',\n",
       " 'hi',\n",
       " 'a',\n",
       " 'i',\n",
       " 'i',\n",
       " 'and',\n",
       " 'this',\n",
       " 'merge',\n",
       " 'everywhere',\n",
       " 'i',\n",
       " 'hi',\n",
       " 'support',\n",
       " 'thank',\n",
       " 'bulgars',\n",
       " 'you',\n",
       " 'mckinsey',\n",
       " 'message',\n",
       " 'thanks',\n",
       " 'well',\n",
       " 'salutation',\n",
       " 'be',\n",
       " 'leadbeater',\n",
       " 'quote',\n",
       " 'the',\n",
       " 'mark',\n",
       " 'i',\n",
       " 'gay',\n",
       " 'unfortunately',\n",
       " 'looks',\n",
       " 'perhaps',\n",
       " 'except',\n",
       " 'right',\n",
       " 'perhaps',\n",
       " 'it',\n",
       " 'i',\n",
       " 'ha',\n",
       " 'fuck',\n",
       " 'thanks',\n",
       " 'yes',\n",
       " 'hi',\n",
       " 'please',\n",
       " 'men',\n",
       " 'there',\n",
       " 'that',\n",
       " 'utc',\n",
       " 'and',\n",
       " 'yobot',\n",
       " 'bias',\n",
       " 'add',\n",
       " 'smer',\n",
       " 'utc',\n",
       " 'i',\n",
       " 'i',\n",
       " 'a',\n",
       " 'great',\n",
       " 'queen',\n",
       " 'january',\n",
       " 'unspecified',\n",
       " 'percent',\n",
       " 'support',\n",
       " 'apparently',\n",
       " 'newsletter',\n",
       " 'should',\n",
       " 'be',\n",
       " 'stay',\n",
       " 'anthony',\n",
       " 'thanks',\n",
       " 'more',\n",
       " 'stop',\n",
       " 'oppose',\n",
       " 'maybe',\n",
       " 'thanks',\n",
       " 'hello',\n",
       " 'f',\n",
       " 'a',\n",
       " 'oh',\n",
       " 'wrong',\n",
       " 'mark',\n",
       " 'can',\n",
       " 'in',\n",
       " 'well',\n",
       " 'tfd',\n",
       " 'artpop',\n",
       " 'crown',\n",
       " 'hamish',\n",
       " 'my',\n",
       " 'die',\n",
       " 'august',\n",
       " 'link',\n",
       " 'it',\n",
       " 'go',\n",
       " 'the',\n",
       " 'sarek',\n",
       " 'keep',\n",
       " 'nazi',\n",
       " 'interest',\n",
       " 'the',\n",
       " 'protect',\n",
       " 'hello',\n",
       " 'my',\n",
       " 'i',\n",
       " 'anytime',\n",
       " 'meet',\n",
       " 'globalization',\n",
       " 'he',\n",
       " 'and',\n",
       " 'to',\n",
       " 'belarus',\n",
       " 'censorship',\n",
       " 'if',\n",
       " 'thanks',\n",
       " 'it',\n",
       " 'i',\n",
       " 'agreed',\n",
       " 'vandalism',\n",
       " 'baer',\n",
       " 'i',\n",
       " 'hello',\n",
       " 'dictionary',\n",
       " 'apparently',\n",
       " 'while',\n",
       " 'december',\n",
       " 'i',\n",
       " 'excellent',\n",
       " 'how',\n",
       " 'afican',\n",
       " 'you',\n",
       " 'all',\n",
       " 'ok',\n",
       " 'sitush',\n",
       " 'december',\n",
       " 'november',\n",
       " 'ok',\n",
       " 'where',\n",
       " 'again',\n",
       " 'i',\n",
       " 'elvis',\n",
       " 'please',\n",
       " 'elizabeth',\n",
       " 'hi',\n",
       " 'welcome',\n",
       " 'i',\n",
       " 'be',\n",
       " 'that',\n",
       " 'the',\n",
       " 'comment',\n",
       " 'it',\n",
       " 'tim',\n",
       " 'no',\n",
       " 'sprecher',\n",
       " 'ipad',\n",
       " 'speedy',\n",
       " 'image',\n",
       " 'the',\n",
       " 'nope',\n",
       " 'the',\n",
       " 'boze',\n",
       " 'imdb',\n",
       " 'i',\n",
       " 'y',\n",
       " 'yes',\n",
       " 'i',\n",
       " 'vince',\n",
       " 'summary',\n",
       " 'it',\n",
       " 'whoever',\n",
       " 'a',\n",
       " 'can',\n",
       " 'sorry',\n",
       " 'we',\n",
       " 'large',\n",
       " 'at',\n",
       " 'you',\n",
       " 'meter',\n",
       " 'you',\n",
       " 'please',\n",
       " 'what',\n",
       " 'utc',\n",
       " 'remove',\n",
       " 'you',\n",
       " 'recaptcha',\n",
       " 'question',\n",
       " 'infobox',\n",
       " 'show',\n",
       " 'why',\n",
       " 'castro',\n",
       " 'antonov',\n",
       " 'another',\n",
       " 'i',\n",
       " 'redirect',\n",
       " 'i',\n",
       " 'for',\n",
       " 'this',\n",
       " 'macedonian',\n",
       " 'if',\n",
       " 'part',\n",
       " 'cfd',\n",
       " 'i',\n",
       " 'all',\n",
       " 'are',\n",
       " 'it',\n",
       " 'hello',\n",
       " 'i',\n",
       " 'when',\n",
       " 'that',\n",
       " 'your',\n",
       " 'two',\n",
       " 'dislike',\n",
       " 'the',\n",
       " 'user',\n",
       " 'i',\n",
       " 'i',\n",
       " 'direct',\n",
       " 'title',\n",
       " 'noel',\n",
       " 'warn',\n",
       " 'should',\n",
       " 'thank',\n",
       " 'please',\n",
       " 'i',\n",
       " 'use',\n",
       " 'however',\n",
       " 'first',\n",
       " 'pretty',\n",
       " 'seem',\n",
       " 'don',\n",
       " 'edit',\n",
       " 'welcome',\n",
       " 'gurch',\n",
       " 'it',\n",
       " 'you',\n",
       " 'season',\n",
       " 'philosopher',\n",
       " 'wp',\n",
       " 'january',\n",
       " 'you',\n",
       " 'see',\n",
       " 'i',\n",
       " 'curse',\n",
       " 'hahaha',\n",
       " 'block',\n",
       " 'and',\n",
       " 'deletion',\n",
       " 'thank',\n",
       " 'well',\n",
       " 'nigel',\n",
       " 'edit',\n",
       " 'nobody',\n",
       " 'i',\n",
       " 'i',\n",
       " 'you',\n",
       " 'holocaust',\n",
       " 'wikipedia',\n",
       " 'censorship',\n",
       " 'april',\n",
       " 'request',\n",
       " 'i',\n",
       " 'i',\n",
       " 'wikipedia',\n",
       " 'hebrew',\n",
       " 'which',\n",
       " 'did',\n",
       " 'you',\n",
       " 'class',\n",
       " 'i',\n",
       " 'welcome',\n",
       " 'stradbroke',\n",
       " 'agf',\n",
       " 'accent',\n",
       " 'delete',\n",
       " 'actually',\n",
       " 'i',\n",
       " 'please',\n",
       " 'precede',\n",
       " 'or',\n",
       " 'you',\n",
       " 'a',\n",
       " 'procedure',\n",
       " 'add',\n",
       " 'please',\n",
       " 'i',\n",
       " 'oh',\n",
       " 'june',\n",
       " 'terri',\n",
       " 'ok',\n",
       " 'past',\n",
       " 'simpson',\n",
       " 'help',\n",
       " 'looks',\n",
       " 'the',\n",
       " 'review',\n",
       " 'regard',\n",
       " 'come',\n",
       " 'i',\n",
       " 'why',\n",
       " 'i',\n",
       " 'regard',\n",
       " 'matt',\n",
       " 'okay',\n",
       " 'valerie',\n",
       " 'shamash',\n",
       " 'i',\n",
       " 'october',\n",
       " 'what',\n",
       " 'agreed',\n",
       " 'hello',\n",
       " 'american',\n",
       " 'regard',\n",
       " 'you',\n",
       " 'the',\n",
       " 'he',\n",
       " 'dar',\n",
       " 'i',\n",
       " 'dxraw',\n",
       " 'this',\n",
       " 'do',\n",
       " 'kudos',\n",
       " 'welcome',\n",
       " 'the',\n",
       " 'don',\n",
       " 'howd',\n",
       " 'i',\n",
       " 'by',\n",
       " 'you',\n",
       " 'fine',\n",
       " 'amber',\n",
       " 'kosovo',\n",
       " 'of',\n",
       " 'i',\n",
       " 'muslim',\n",
       " 'width',\n",
       " 'august',\n",
       " 'pkk',\n",
       " 'omd',\n",
       " 'try',\n",
       " 'ricky',\n",
       " 'triple',\n",
       " 'if',\n",
       " 'a',\n",
       " 'what',\n",
       " 'thanks',\n",
       " 'no',\n",
       " 'celebrity',\n",
       " 'you',\n",
       " 'tm',\n",
       " 'sofia',\n",
       " 'would',\n",
       " 'decline',\n",
       " 'weatherman',\n",
       " 'non',\n",
       " 'i',\n",
       " 'dispatch',\n",
       " 'i',\n",
       " 'here',\n",
       " 'your',\n",
       " 'listas',\n",
       " 'so',\n",
       " 'speedy',\n",
       " 'will',\n",
       " 'request',\n",
       " 'i',\n",
       " 'greek',\n",
       " 'where',\n",
       " 'oh',\n",
       " 'no',\n",
       " 'ga',\n",
       " 'for',\n",
       " 'afd',\n",
       " 'organization',\n",
       " 'action',\n",
       " 'dean',\n",
       " 'woopsies',\n",
       " 'for',\n",
       " 'why',\n",
       " 'gift',\n",
       " 'i',\n",
       " 'no',\n",
       " 'my',\n",
       " 'try',\n",
       " 'unsourced',\n",
       " 'your',\n",
       " 'when',\n",
       " 'we',\n",
       " 'i',\n",
       " 'hello',\n",
       " 'other',\n",
       " 'a',\n",
       " 'some',\n",
       " 'refer',\n",
       " 'mevins',\n",
       " 'they',\n",
       " 'i',\n",
       " 'although',\n",
       " 'do',\n",
       " 'the',\n",
       " 'excellent',\n",
       " 'content',\n",
       " 'ditto',\n",
       " 'be',\n",
       " 'fuck',\n",
       " 'i',\n",
       " 'please',\n",
       " 'dect',\n",
       " 'i',\n",
       " 'you',\n",
       " 'user',\n",
       " 'thanks',\n",
       " 'which',\n",
       " 'alex',\n",
       " 'in',\n",
       " 'the',\n",
       " 'amazing',\n",
       " 'groin',\n",
       " 'may',\n",
       " 'video',\n",
       " 'palmisano',\n",
       " 'history',\n",
       " 'massacre',\n",
       " 'july',\n",
       " 'notice',\n",
       " 'barn',\n",
       " 'may',\n",
       " 'two',\n",
       " 'hi',\n",
       " 'he',\n",
       " 'here',\n",
       " 'aug',\n",
       " 'just',\n",
       " 'oh',\n",
       " 'what',\n",
       " 'rajput',\n",
       " 'if',\n",
       " 'word',\n",
       " 'at',\n",
       " 'just',\n",
       " 'thank',\n",
       " 'the',\n",
       " 'gba',\n",
       " 'propose',\n",
       " 'no',\n",
       " 'the',\n",
       " 'redirect',\n",
       " 'no',\n",
       " 'why',\n",
       " 'therefore',\n",
       " 'user',\n",
       " 'not',\n",
       " 'im',\n",
       " 'chicadee',\n",
       " 'p',\n",
       " 'ohhh',\n",
       " 'new',\n",
       " 'bunchofgrapes',\n",
       " 'and',\n",
       " 'wow',\n",
       " 'glen',\n",
       " 'parody',\n",
       " 'pandur',\n",
       " 'i',\n",
       " 'no',\n",
       " 'i',\n",
       " 'replacement',\n",
       " 'ok',\n",
       " 'hello',\n",
       " 'i',\n",
       " 'he',\n",
       " 'so',\n",
       " 'so',\n",
       " 'beauty',\n",
       " 'on',\n",
       " 'no',\n",
       " 'please',\n",
       " 'alyssa',\n",
       " 'rom',\n",
       " 'fuck',\n",
       " 'in',\n",
       " 'after',\n",
       " 'wow',\n",
       " 'it',\n",
       " 'lamia',\n",
       " 'i',\n",
       " 'i',\n",
       " 'padua',\n",
       " 'ion',\n",
       " 'you',\n",
       " 'ok',\n",
       " 'that',\n",
       " 'the',\n",
       " 'could',\n",
       " 'mediation',\n",
       " 'well',\n",
       " 'the',\n",
       " 'wikipedia',\n",
       " 'flexpay',\n",
       " 'no',\n",
       " 'if',\n",
       " 'i',\n",
       " 'najib',\n",
       " 'lol',\n",
       " 'cfr',\n",
       " 'lead',\n",
       " 'unblock',\n",
       " 'if',\n",
       " 'the',\n",
       " 'try',\n",
       " 'actually',\n",
       " 'i',\n",
       " 'i',\n",
       " 'that',\n",
       " 'the',\n",
       " 'chill',\n",
       " 'a',\n",
       " 'added',\n",
       " 'no',\n",
       " 'batman',\n",
       " 'geometry',\n",
       " 'exactly',\n",
       " 'please',\n",
       " 'that',\n",
       " 'that',\n",
       " 'you',\n",
       " 'furthermore',\n",
       " 'wikipedia',\n",
       " 'they',\n",
       " 'in',\n",
       " 'that',\n",
       " 'that',\n",
       " 'french',\n",
       " 'why',\n",
       " 'davkal',\n",
       " 'thanks',\n",
       " 'transistor',\n",
       " 'i',\n",
       " 'the',\n",
       " 'hmmm',\n",
       " 'this',\n",
       " 'feather',\n",
       " 'bakan',\n",
       " 'message',\n",
       " 'trivia',\n",
       " 'might',\n",
       " 'speedy',\n",
       " 'your',\n",
       " 'speak',\n",
       " 'our',\n",
       " 'speedy',\n",
       " 'plus',\n",
       " 'unblock',\n",
       " 'i',\n",
       " 'you',\n",
       " 'thanks',\n",
       " 'for',\n",
       " 'you',\n",
       " 'the',\n",
       " 'fisherqueen',\n",
       " 'so',\n",
       " 'have',\n",
       " 'nevermind',\n",
       " 'i',\n",
       " 'a',\n",
       " 'please',\n",
       " 'delete',\n",
       " 'millinos',\n",
       " 'just',\n",
       " 'er',\n",
       " 'raffaele',\n",
       " 'yes',\n",
       " 'seriously',\n",
       " 'fu',\n",
       " 'some',\n",
       " 'you',\n",
       " 'sr',\n",
       " 'you',\n",
       " 'a',\n",
       " 'rather',\n",
       " 'the',\n",
       " 'no',\n",
       " 'okay',\n",
       " 'haha',\n",
       " 'leave',\n",
       " 'bloc',\n",
       " 'peta',\n",
       " 'please',\n",
       " 'august',\n",
       " 'email',\n",
       " 'it',\n",
       " 'perhaps',\n",
       " 'other',\n",
       " 'i',\n",
       " 'ooooh',\n",
       " 'omg',\n",
       " 'i',\n",
       " 'hi',\n",
       " 'it',\n",
       " 'april',\n",
       " 'i',\n",
       " 'this',\n",
       " ...)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = (df_cloud['tokens'].tolist())\n",
    "tokens = list(zip(*tokens))[0]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: explanation d hey more you congratulation cocksucker your...>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.Text(tokens)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'i': 15583, 'the': 4936, 'you': 4449, 'please': 3430, 'it': 2744, 'this': 2325, 'thanks': 2307, 'a': 2016, 'hi': 1765, 'no': 1709, ...})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = FreqDist(text)\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = [word for word in tokens if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: explanation hey congratulation cocksucker sorry alignment fair bbq...>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words = nltk.Text(filtered_words)\n",
    "filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'please': 3430, 'thanks': 2307, 'hi': 1765, 'thank': 1423, 'redirect': 1372, 'well': 1360, 'yes': 1130, 'hello': 1121, 'hey': 1086, 'ok': 947, ...})"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered = FreqDist(filtered_words)\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Samples', ylabel='Counts'>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered.plot(30,cumulative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение для TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разбиение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "\n",
    "Чтобы получить хорошую метрику в данном проекте важно использовать весь датсет (логистичечкая регрессия, SVM + полный датасет, даст лучше и быстрее результат, чем медленные \"деревянные\" модели с усеченным датасетом). Если не хватает мощности ядро обрушивается,  то тут часто проблема в использовании unicode, убираем и все бежит веселей, если и это не помогает ничего не поделать, тут студент сам смотрит что у него и как ) \n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарий студента:</b> Я ограничил, чтобы на ревью долго не считало. Так как вектора на полном считаются 30 минут, лес 25 и т.д. Т.к. я в целом показал работоспособность кода, я убираю ограничение датасета для TF-IDF (кроме BERTa, потому что BERT и по 8 часов считал, и не выдавал ответ. Но ядро не рушил)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_lem, features_test_lem, target_train_lem, target_test_lem = train_test_split( #создаем 4 датасета, два признаков (тест+валидация) и два целевых, \n",
    "    df_lem.drop(columns='toxic'), #для датасетов признаков удаляем целевой\n",
    "    df_lem['toxic'], #для целевого оставляем только целевой\n",
    "    test_size=0.2, #с соотношением \n",
    "    random_state=RANDOM_STATE, #с заданной опорой для рандома \n",
    "    stratify= df_lem['toxic']) #с заданной стратификацией по целевому признаку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "- random_state на месте\n",
    "\n",
    "\n",
    "- правильно разбил на 2 выборки (иногда студенты использующие GS разбивают на 3 датасета)\n",
    "\n",
    "    \n",
    "- здорово что используешь stratify    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вводим стоп слова"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоп-слова были введены ранее, в пункте \"Облако слов\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоп слова - слова, не несущие смысловой нагрузки. Они не должны влиять на обучение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "Не забыли о стопсловах, они ни к чему и код побежит быстрей\n",
    "\n",
    "    \n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет:     \n",
    "\n",
    "Вопросик:\n",
    "\n",
    "А стопслова важней убирать  когда мы используем TF-IDF, или когда используе обычный CountVectorizer? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарий студента:</b> Могу ошибаться, но, наверное при обычном CountVectorizer важнее. Т.к. метод TF-IDF использует частоту упоминаний в каждой строке и упоминания во всем корпусе, тогда слова I, a, различные предлоги и др. будут иметь меньший вес, и будут меньше влиять, чем уникальные слова. При CountVectorizer такой градации нет, поэтому оставленные в тексте стоп-слова будут влиять на обучение так же, как уникальные и редкие слова.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Мешки слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим счётчик, далее передаём счётчику корпус текстов. Для этого вызовем `fit_transform()`. \n",
    "\n",
    "Счётчик выделит из корпуса уникальные слова и посчитает количество их вхождений в каждом тексте корпуса. Отдельные буквы счётчик как слова не учитывает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 9522)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_train = features_train_lem['lemma'].values #создаем корпус текстов\n",
    "count_tf_idf_train = TfidfVectorizer(stop_words=stop_words) #создаем счетчик величин TF-IDF, с учетом стоп слов\n",
    "tf_idf_train = count_tf_idf_train.fit_transform(corpus_train) #передаем счётчику корпус текстов (fit запускается только на обучающей выборке)\n",
    "tf_idf_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Ошибка:\n",
    "\n",
    "\n",
    "\n",
    "Да, в тренажере был текст на кирилице, там перевод в unicode оправдан. В нашем случае (латиница) это лишь  увеличит количество потребляемой памяти и это в лучшем случаи, в худшем он обрушает ядро.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_tf_idf_train.get_feature_names() #посмотреть словарь уникальных слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичным образом работаем и с тестовой выборкой. Единственное отличие - `transform` для теста не обучается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 9522)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_test = features_test_lem['lemma'].values\n",
    "tf_idf_test = count_tf_idf_train.transform(corpus_test)\n",
    "tf_idf_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные предобработаны, можно переходить к обучению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Совет:\n",
    "\n",
    "\n",
    "- .fit_transform на train датасете, .transform на test/valid. Вроде все верно, но после ты подаешь tf_idf_train в GridSearchCV или cross_val_score и он внутри себя разбивая его на тренировочный и валидационный датасет, получается подглядывание в будущее (утечка данных). Решение в использовании pipeline, ниже распишу\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение метрики F1 для модели логистической регрессии с использованием кросс-валидации: 0.5550298252472166\n",
      "CPU times: user 522 ms, sys: 4.05 ms, total: 526 ms\n",
      "Wall time: 534 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "log_reg_lem = LogisticRegression(solver='lbfgs', random_state=RANDOM_STATE, max_iter=1000, class_weight= 'balanced') #максимальное количество итераций 1000, \n",
    "log_reg_scores_lem = cross_val_score(log_reg_lem, tf_idf_train, target_train_lem.values, scoring='f1', cv=10)\n",
    "log_reg_f1_lem = log_reg_scores_lem.mean()\n",
    "\n",
    "print(\"Среднее значение метрики F1 для модели логистической регрессии \"\\\n",
    "    \"с использованием кросс-валидации:\", log_reg_f1_lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Совет 🤔:\n",
    "\n",
    "\n",
    "Логистическая регрессия показывает одни из самых высоких результатов на этом датасете (а Деревянные модели медленные, и результаты плохие), поэтому стоит поперебирать по C\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель опорных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение метрики F1 для модели SVC с использованием кросс-валидации: 0.42659123055162657\n",
      "CPU times: user 446 ms, sys: 153 µs, total: 446 ms\n",
      "Wall time: 446 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "svclassifier_lem = SVC(kernel='linear', class_weight= 'balanced') \n",
    "svclassifier_scores_lem = cross_val_score(svclassifier_lem, tf_idf_train, target_train_lem.values, scoring='f1', cv=2)\n",
    "svclassifier_f1_lem = svclassifier_scores_lem.mean()\n",
    "\n",
    "print(\"Среднее значение метрики F1 для модели SVC \"\\\n",
    "    \"с использованием кросс-валидации:\", svclassifier_f1_lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для модели случайного леса с использованием кросс-валидации: {'n_estimators': 351, 'max_depth': 1}\n",
      "Наибольшее значение метрики F1 для модели случайного леса при лучших гиперпараметрах с использованием кросс-валидации: 0.3963191467112831\n",
      "CPU times: user 31.4 s, sys: 237 ms, total: 31.7 s\n",
      "Wall time: 31.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "forest_lem = RandomForestClassifier(random_state=RANDOM_STATE, class_weight= 'balanced') #модель случайного леса\n",
    "parameters = {'n_estimators': range (1, 500, 50), 'max_depth': range (1, 100, 10)} #перебор гиперпараметров\n",
    "#применение метода гридсёрч со встроенной кросс-валидацией к модели леса с перебором указанных параметров\n",
    "\n",
    "randomized_forest_lem = RandomizedSearchCV(forest_lem, n_iter=15, param_distributions= parameters, scoring='f1', n_jobs= -2, cv=2)\n",
    "#обучение модели\n",
    "randomized_forest_lem.fit(tf_idf_train, target_train_lem.values)\n",
    "\n",
    "#лучшее значение после перебора параметров \n",
    "best_forest_lem = randomized_forest_lem.best_score_\n",
    "\n",
    "print(\"Лучшие параметры для модели случайного леса с \"\\\n",
    "    \"использованием кросс-валидации:\", randomized_forest_lem.best_params_)\n",
    "print(\"Наибольшее значение метрики F1 для модели случайного леса \"\\\n",
    "    \"при лучших гиперпараметрах с использованием кросс-валидации:\", best_forest_lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для модели LGBMClassifier с использованием кросс-валидации: {'n_estimators': 191, 'max_depth': 61, 'learning_rate': 0.30000000000000004}\n",
      "Наибольшее значение метрики F1 для модели LGBMClassifier при лучших гиперпараметрах с использованием кросс-валидации: 0.30671891391315853\n",
      "CPU times: user 1min, sys: 963 ms, total: 1min 1s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgbm_lem = lgb.LGBMClassifier(class_weight= 'balanced') #\n",
    "parameters = {'n_estimators': range (1, 500, 10), 'max_depth': range (1, 100, 5), 'learning_rate': np.arange(0.1, 0.8, 0.1)}\n",
    "#применение метода гридсёрч со встроенной кросс-валидацией\n",
    "\n",
    "rand_lgbm_lem = RandomizedSearchCV(lgbm_lem, n_iter=20, param_distributions= parameters, scoring='f1', n_jobs= -2, cv=3)\n",
    "#обучение модели\n",
    "rand_lgbm_lem.fit(tf_idf_train, target_train_lem.values)\n",
    "\n",
    "#лучшее значение после перебора параметров \n",
    "best_lgbm_lem = rand_lgbm_lem.best_score_\n",
    "\n",
    "print(\"Лучшие параметры для модели LGBMClassifier с \"\\\n",
    "    \"использованием кросс-валидации:\", rand_lgbm_lem.best_params_)\n",
    "print(\"Наибольшее значение метрики F1 для модели LGBMClassifier \"\\\n",
    "    \"при лучших гиперпараметрах с использованием кросс-валидации:\", best_lgbm_lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "    \n",
    "    \n",
    "    \n",
    "Совет: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Молодец что используешь GrisSearch, но в случаи TFIDF еще лучше использовать связку GridSearchCV + pipeline. \n",
    "\n",
    "\n",
    "О pipeline:\n",
    "\n",
    "[Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html), это тема которая сразу затрагивает кроссвалидацию, тюнинг \"векторайз\", подбор гиперпараметров модели и о том что код стоит делать компактным.\n",
    "    \n",
    "    \n",
    "- в TfidfVectorizer(stop_words=stopwords) у тебя по умолчанию ngram_range=(1, 1), тут можно подбирать разное число n- грамм (и другие параметры), максимизируя метрику, но как объединить перебор по ngram_range с обучением моделей, чтобы не делать это по отдельности или с использованием цикла?! pipeline! Готовый [пример для работы с текстами](https://medium.com/@yoni.levine/how-to-grid-search-with-a-pipeline-93147835d916). Всё что нужно там есть, хотя очень лаконично. Можешь погуглить по:\n",
    "\n",
    "\n",
    "    \n",
    "    pipeline nlp gridsearchcv\n",
    "\n",
    "\n",
    "\n",
    "- как избежать ошибки подглядывания в будущее, когда мы предварительно работаем с данными (шкалирование, нормализация, TfidfVectorizer итп итд)? pipeline! особенно это важно, когда мы используем кроссвалидацию. Для TfidfVectorizer делаем .fit (обучаемся) на train, а transform на test, но точно также нужно сделать для валидационной выборки. Но GS делает валидационные внутри себя, спрашивается как добраться до нее и избежать подглядывания в будущее? Казалось бы никак, но нет! Pipeline! ) \n",
    "    \n",
    "    \n",
    "- pipeline позволяет делать наш код компактней и читабельней, это большой плюс, когда код будет раздуваться     \n",
    "    \n",
    "    \n",
    "\n",
    "         \n",
    "Если раньше не использовал pipeline то могу посоветовать видео в котором [индус](https://www.youtube.com/watch?v=mOYJCR0IDk8&ab_channel=HimanshuChandra) на английском с сильным акцентом, но на пальцах обьясняет  самое непонятное (по моему опыту): сопряженность методов fit и transform. Там же есть и код и ссылка на текст. Мне помогло )\n",
    "\n",
    "\n",
    "\n",
    "В общем если сделать GS+pipeline будет вообще хорошо )  \n",
    "    \n",
    "<div>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по методу TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>Значение метрики F1</th>\n",
       "      <th>Время расчета (весь датасет)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Логистическая регрессия</td>\n",
       "      <td>0.555030</td>\n",
       "      <td>~15 секунд</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Модель опорных векторов</td>\n",
       "      <td>0.426591</td>\n",
       "      <td>~8 минут</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Случайный лес</td>\n",
       "      <td>0.396319</td>\n",
       "      <td>~6 минут</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.306719</td>\n",
       "      <td>~6 минут</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Модель  Значение метрики F1 Время расчета (весь датасет)\n",
       "0  Логистическая регрессия             0.555030                   ~15 секунд\n",
       "1  Модель опорных векторов             0.426591                     ~8 минут\n",
       "2            Случайный лес             0.396319                     ~6 минут\n",
       "3           LGBMClassifier             0.306719                     ~6 минут"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = ['Логистическая регрессия', 'Модель опорных векторов', 'Случайный лес', 'LGBMClassifier']\n",
    "F1 = [log_reg_f1_lem, svclassifier_f1_lem, best_forest_lem, best_lgbm_lem]\n",
    "total_time = ['~15 секунд', '~8 минут', '~6 минут', '~6 минут']\n",
    "\n",
    "tf_result_table = pd.DataFrame({ #созаем датафрейм\n",
    "    'Модель': models, #\n",
    "    'Значение метрики F1': F1,\n",
    "    'Время расчета (весь датасет)': total_time\n",
    "}) #\n",
    "tf_result_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили два близких значения метрики F1 к требуемому: на логистической регрессии и на модели опорных векторов. Несмотря на то, что значение метрики для регрессии ниже требуемого, она все же может пригодиться, если нужно сделать довольно точные предсказания на скорость. Модель векторов, напротив, самая медленная из всех. Модель леса оказалась самой неточной. \n",
    "\n",
    "Единственная модель, удовлетворяющая условию - `LGBMClassifier`, дает необходимое значение метрики, к тому же предсказывает результат не дольше других моделей (а на полном наборе - быстрее других)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверяем лучшую модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестируем модель `LGBMClassifier`, которая при предобработке методом `TF-IDF`, показала себя как точную и достаточно быструю (даже с учетом перебора гиперпараметров) модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наименьшее значение метрики F1 на тестовых данных 0.4473684210526316\n",
      "CPU times: user 1.26 s, sys: 16 ms, total: 1.28 s\n",
      "Wall time: 1.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgbm_lem_1 = rand_lgbm_lem.best_estimator_\n",
    "lgbm_lem_1.fit(tf_idf_train, target_train_lem.values)\n",
    "\n",
    "predictions_lgbm_lem_1 = lgbm_lem_1.predict(tf_idf_test)\n",
    "\n",
    "lgbm_lem_f1 = f1_score(target_test_lem, predictions_lgbm_lem_1)\n",
    "print(\"Наименьшее значение метрики F1 на тестовых данных\", lgbm_lem_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV</b></font>\n",
    "    \n",
    "    \n",
    "Совет:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Не надо воспринимать  GS как способ получить .best_params_, чтобы подставить их в модель и обучить на них. GS это сделал уже и модельку положил тут: .best_estimator_\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарий студента:</b> Я в восторге от этого, спасибо!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили значение метрики F1 в пределах 0,77."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех: \n",
    "\n",
    "- Все верно, логика моделирования не нарушена, тут тестируем только лучшую модель отобранную на валидации, или парочку лучших, если на валидации результаты близки\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Если студент получил на тесте f1 выше 0,75, это считается приемлемым результатом.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "Что может помочь добиться лучшего результата для (от простого)? \n",
    "\n",
    "\n",
    "- Использовать вес датасет (для TFIDF это точно возможно) \n",
    "    \n",
    "    \n",
    "- использовать stratify Done!\n",
    "    \n",
    "\n",
    "\n",
    "- можно поиграться порогом\n",
    "   \n",
    "\n",
    "- учесть дисбаланс класов в таргете. (но не oversampling, это скользкая дорожка, через class_weight) Done!\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "- подобрать лучшие гиперпараметры с использованием кроссвалидации (тут пригодится GridSearchCV) Done!\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    " - полезно настраивать векторайзеры и избегать утечки данных при использовании GS и предобработки данных  (тут пригодится pipeline)\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "- сгенерировать новые фичи, например  например посчитать число слов в тексте, длину слов итп итд. Или с помощью [тематического моделирования](https://pythobyte.com/python-for-nlp-topic-modeling-8fb3d689/) \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "- использование предбученной модели Берта, выбрав соответствующую модель и используя полученные эмбединги, даже на небольшом тренировочном датасете можно обучить модель, которая на test покажет хорошую метрику Done!\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В проекте было рассмотрено два метода обработки натурального языка, а именно:\n",
    "\n",
    "- `BERT`,\n",
    "- `TF-IDF`.\n",
    "\n",
    "Преобразовав текст для `BERT`, мы получили значение метрики, не удовлетворяющее условию, а именно, метрику F1 < 0.75. Это связано с тем, что модели обучались не на всем наборе данных, а лишь на 10%. Здесь упираемся в аппаратные ограничения и скорость обучения и перебора параметров. \n",
    "\n",
    "В методе `TF-IDF` мы добились необходимого значения метрики `F1`, для модели `LGBMClassifier`. Она же показала результат на тестовых данных равный 0.78. Здесь омодели обучались уже на всем наборе данных, что значительно увеличило значение метрики `F1`. То есть, даже если этот метод менее точен, чем `BERT` (при условии использования 100% данных), он намного менее требователен к аппаратным ресурсам и намного быстрее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Максим, у тебя старательно выполненная работа, все четко, осмысленно. Некоторые пункты выполнены в большем чем требуется обьеме. Логика моделирования не нарушена, GS использован корректно. Если хочешь прокачать свой скилл попробуй использовать pipeline.\n",
    "Я оставил небольшие советы и вопросики (если есть время и желание можешь воспользоваться/ответить).\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "Обязательное к исправлению:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- .astype('U') лишнее, стоит экономить ресурсы, иначе может даже ядро обрушиться\n",
    "\n",
    "\n",
    "\n",
    "- не забываем о random_state\n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "Жду исправлений, для принятия проекта. Если какие то вопросы, то сразу спрашивай ) \n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 4,
    "start_time": "2023-02-14T07:01:16.148Z"
   },
   {
    "duration": 2893,
    "start_time": "2023-02-14T07:01:18.097Z"
   },
   {
    "duration": 91,
    "start_time": "2023-02-14T07:01:50.689Z"
   },
   {
    "duration": 100,
    "start_time": "2023-02-14T07:02:01.288Z"
   },
   {
    "duration": 27934,
    "start_time": "2023-02-14T07:02:06.490Z"
   },
   {
    "duration": 9041,
    "start_time": "2023-02-14T07:02:46.187Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T07:04:36.316Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T07:08:16.853Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T07:08:18.115Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T07:08:19.940Z"
   },
   {
    "duration": 6646,
    "start_time": "2023-02-14T07:08:46.347Z"
   },
   {
    "duration": 2601,
    "start_time": "2023-02-14T07:09:00.819Z"
   },
   {
    "duration": 8057,
    "start_time": "2023-02-14T07:09:04.251Z"
   },
   {
    "duration": 6608,
    "start_time": "2023-02-14T07:10:20.651Z"
   },
   {
    "duration": 2771,
    "start_time": "2023-02-14T07:10:30.732Z"
   },
   {
    "duration": 738,
    "start_time": "2023-02-14T07:10:34.285Z"
   },
   {
    "duration": 8835,
    "start_time": "2023-02-14T07:10:37.396Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-14T07:12:35.677Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T07:12:36.197Z"
   },
   {
    "duration": 6395,
    "start_time": "2023-02-14T07:12:50.925Z"
   },
   {
    "duration": 2492,
    "start_time": "2023-02-14T07:12:58.339Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T07:13:01.364Z"
   },
   {
    "duration": 8869,
    "start_time": "2023-02-14T07:13:01.628Z"
   },
   {
    "duration": 6404,
    "start_time": "2023-02-14T07:18:19.239Z"
   },
   {
    "duration": 2579,
    "start_time": "2023-02-14T07:18:25.725Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T07:18:29.357Z"
   },
   {
    "duration": 8896,
    "start_time": "2023-02-14T07:18:30.253Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T07:19:44.093Z"
   },
   {
    "duration": 2528,
    "start_time": "2023-02-14T07:19:45.053Z"
   },
   {
    "duration": 9433,
    "start_time": "2023-02-14T07:19:47.974Z"
   },
   {
    "duration": 2386,
    "start_time": "2023-02-14T07:20:45.053Z"
   },
   {
    "duration": 2,
    "start_time": "2023-02-14T07:20:49.399Z"
   },
   {
    "duration": 32,
    "start_time": "2023-02-14T07:20:52.719Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-14T07:20:55.759Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-14T07:23:15.008Z"
   },
   {
    "duration": 12,
    "start_time": "2023-02-14T07:23:18.982Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-14T07:23:24.560Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-14T07:23:26.887Z"
   },
   {
    "duration": 12,
    "start_time": "2023-02-14T07:23:28.998Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-14T07:23:32.070Z"
   },
   {
    "duration": 472,
    "start_time": "2023-02-14T07:25:07.912Z"
   },
   {
    "duration": 126,
    "start_time": "2023-02-14T07:25:21.943Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T07:26:09.807Z"
   },
   {
    "duration": 301,
    "start_time": "2023-02-14T07:29:01.632Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-14T07:30:30.489Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-14T07:33:02.283Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-14T07:33:27.841Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-14T07:33:40.073Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T07:34:20.753Z"
   },
   {
    "duration": 2727,
    "start_time": "2023-02-14T07:34:20.758Z"
   },
   {
    "duration": 10419,
    "start_time": "2023-02-14T07:34:23.487Z"
   },
   {
    "duration": 2,
    "start_time": "2023-02-14T07:34:33.908Z"
   },
   {
    "duration": 2227,
    "start_time": "2023-02-14T07:34:33.913Z"
   },
   {
    "duration": 30,
    "start_time": "2023-02-14T07:34:36.142Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-14T07:34:36.174Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T07:34:36.186Z"
   },
   {
    "duration": 94996,
    "start_time": "2023-02-14T07:34:36.191Z"
   },
   {
    "duration": 16,
    "start_time": "2023-02-14T07:37:02.972Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-14T07:37:32.675Z"
   },
   {
    "duration": 12,
    "start_time": "2023-02-14T07:37:40.330Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T07:37:43.618Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-14T07:37:48.546Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-14T07:39:16.481Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-14T07:39:39.219Z"
   },
   {
    "duration": 4206,
    "start_time": "2023-02-14T07:40:17.595Z"
   },
   {
    "duration": 145,
    "start_time": "2023-02-14T07:40:43.290Z"
   },
   {
    "duration": 162,
    "start_time": "2023-02-14T07:40:50.956Z"
   },
   {
    "duration": 152,
    "start_time": "2023-02-14T07:41:01.210Z"
   },
   {
    "duration": 164,
    "start_time": "2023-02-14T07:41:07.579Z"
   },
   {
    "duration": 215,
    "start_time": "2023-02-14T07:41:27.219Z"
   },
   {
    "duration": 125,
    "start_time": "2023-02-14T07:41:37.836Z"
   },
   {
    "duration": 138,
    "start_time": "2023-02-14T07:42:01.027Z"
   },
   {
    "duration": 137,
    "start_time": "2023-02-14T07:42:12.236Z"
   },
   {
    "duration": 130,
    "start_time": "2023-02-14T07:42:17.827Z"
   },
   {
    "duration": 127,
    "start_time": "2023-02-14T07:42:21.396Z"
   },
   {
    "duration": 133,
    "start_time": "2023-02-14T07:42:51.580Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T07:44:11.667Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T07:44:17.428Z"
   },
   {
    "duration": 12,
    "start_time": "2023-02-14T07:44:43.804Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-14T07:44:54.549Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T07:45:08.261Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-14T07:45:18.667Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T08:26:54.148Z"
   },
   {
    "duration": 2097,
    "start_time": "2023-02-14T08:26:57.693Z"
   },
   {
    "duration": 13730,
    "start_time": "2023-02-14T08:27:18.853Z"
   },
   {
    "duration": 733,
    "start_time": "2023-02-14T09:19:25.746Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T10:18:55.728Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T10:18:55.952Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T10:19:00.984Z"
   },
   {
    "duration": 955,
    "start_time": "2023-02-14T10:19:04.503Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-14T10:19:39.697Z"
   },
   {
    "duration": 416,
    "start_time": "2023-02-14T10:19:40.985Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T10:19:42.674Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T10:19:44.928Z"
   },
   {
    "duration": 5194,
    "start_time": "2023-02-14T10:19:45.952Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T10:19:52.624Z"
   },
   {
    "duration": 806,
    "start_time": "2023-02-14T10:20:00.024Z"
   },
   {
    "duration": 22,
    "start_time": "2023-02-14T10:21:39.031Z"
   },
   {
    "duration": 29,
    "start_time": "2023-02-14T10:21:42.673Z"
   },
   {
    "duration": 18,
    "start_time": "2023-02-14T10:21:43.032Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T10:21:43.536Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T10:21:44.327Z"
   },
   {
    "duration": 5693,
    "start_time": "2023-02-14T10:21:44.768Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T10:21:50.463Z"
   },
   {
    "duration": 20,
    "start_time": "2023-02-14T10:21:55.281Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T10:23:22.584Z"
   },
   {
    "duration": 901,
    "start_time": "2023-02-14T10:23:23.952Z"
   },
   {
    "duration": 2,
    "start_time": "2023-02-14T10:23:37.977Z"
   },
   {
    "duration": 1025,
    "start_time": "2023-02-14T10:23:38.537Z"
   },
   {
    "duration": 3621,
    "start_time": "2023-02-14T10:24:08.911Z"
   },
   {
    "duration": 12213,
    "start_time": "2023-02-14T10:24:12.535Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T10:24:28.049Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T10:24:34.026Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T10:24:35.420Z"
   },
   {
    "duration": 2,
    "start_time": "2023-02-14T10:24:37.922Z"
   },
   {
    "duration": 935,
    "start_time": "2023-02-14T10:24:40.401Z"
   },
   {
    "duration": 38,
    "start_time": "2023-02-14T10:24:43.466Z"
   },
   {
    "duration": 16,
    "start_time": "2023-02-14T10:24:44.072Z"
   },
   {
    "duration": 152,
    "start_time": "2023-02-14T10:24:48.273Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T10:24:48.466Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T10:25:13.761Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-14T10:25:35.058Z"
   },
   {
    "duration": 265,
    "start_time": "2023-02-14T10:25:36.345Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T10:25:37.969Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T10:25:41.865Z"
   },
   {
    "duration": 5750,
    "start_time": "2023-02-14T10:25:43.127Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T10:25:48.879Z"
   },
   {
    "duration": 209,
    "start_time": "2023-02-14T10:25:56.177Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-14T10:26:14.831Z"
   },
   {
    "duration": 1331,
    "start_time": "2023-02-14T10:26:25.521Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T10:37:55.445Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-14T10:37:56.821Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T10:37:58.503Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-14T10:38:01.340Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T10:38:07.228Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-14T10:38:07.789Z"
   },
   {
    "duration": 149,
    "start_time": "2023-02-14T10:38:10.189Z"
   },
   {
    "duration": 18,
    "start_time": "2023-02-14T10:38:19.275Z"
   },
   {
    "duration": 38,
    "start_time": "2023-02-14T10:38:38.397Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-14T10:38:39.309Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T10:38:39.533Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T10:38:39.852Z"
   },
   {
    "duration": 4714,
    "start_time": "2023-02-14T10:38:40.028Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T10:38:44.744Z"
   },
   {
    "duration": 18168,
    "start_time": "2023-02-14T10:38:44.749Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T10:39:09.147Z"
   },
   {
    "duration": 7528,
    "start_time": "2023-02-14T10:39:09.700Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T10:39:17.230Z"
   },
   {
    "duration": 43,
    "start_time": "2023-02-14T10:39:17.235Z"
   },
   {
    "duration": 39,
    "start_time": "2023-02-14T10:39:17.281Z"
   },
   {
    "duration": 151,
    "start_time": "2023-02-14T10:39:17.322Z"
   },
   {
    "duration": 2,
    "start_time": "2023-02-14T10:39:19.040Z"
   },
   {
    "duration": 31,
    "start_time": "2023-02-14T10:39:19.557Z"
   },
   {
    "duration": 408,
    "start_time": "2023-02-14T10:39:21.516Z"
   },
   {
    "duration": 394,
    "start_time": "2023-02-14T10:39:24.647Z"
   },
   {
    "duration": 22621,
    "start_time": "2023-02-14T10:39:27.221Z"
   },
   {
    "duration": 110249,
    "start_time": "2023-02-14T10:40:03.070Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-14T10:42:10.918Z"
   },
   {
    "duration": 18,
    "start_time": "2023-02-14T10:42:49.693Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-14T10:43:05.870Z"
   },
   {
    "duration": 350,
    "start_time": "2023-02-14T10:43:22.578Z"
   },
   {
    "duration": 115,
    "start_time": "2023-02-14T10:45:13.575Z"
   },
   {
    "duration": 604,
    "start_time": "2023-02-14T10:45:31.927Z"
   },
   {
    "duration": 61927,
    "start_time": "2023-02-14T10:47:41.079Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-14T10:49:05.173Z"
   },
   {
    "duration": 1270,
    "start_time": "2023-02-14T10:49:11.535Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-14T13:12:17.507Z"
   },
   {
    "duration": 39,
    "start_time": "2023-02-14T13:13:23.918Z"
   },
   {
    "duration": 33,
    "start_time": "2023-02-14T13:13:25.768Z"
   },
   {
    "duration": 49,
    "start_time": "2023-02-14T13:14:37.093Z"
   },
   {
    "duration": 34,
    "start_time": "2023-02-14T13:14:43.979Z"
   },
   {
    "duration": 172,
    "start_time": "2023-02-14T13:14:50.464Z"
   },
   {
    "duration": 105,
    "start_time": "2023-02-14T13:14:55.752Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T13:14:56.888Z"
   },
   {
    "duration": 23,
    "start_time": "2023-02-14T13:14:57.632Z"
   },
   {
    "duration": 474,
    "start_time": "2023-02-14T13:15:08.258Z"
   },
   {
    "duration": 520,
    "start_time": "2023-02-14T13:15:17.690Z"
   },
   {
    "duration": 24732,
    "start_time": "2023-02-14T13:15:25.331Z"
   },
   {
    "duration": 155,
    "start_time": "2023-02-14T13:16:16.241Z"
   },
   {
    "duration": 54,
    "start_time": "2023-02-14T13:16:20.252Z"
   },
   {
    "duration": 539,
    "start_time": "2023-02-14T13:16:25.035Z"
   },
   {
    "duration": 454,
    "start_time": "2023-02-14T13:16:29.318Z"
   },
   {
    "duration": 31750,
    "start_time": "2023-02-14T13:16:32.629Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-14T13:51:22.930Z"
   },
   {
    "duration": 1694,
    "start_time": "2023-02-14T13:52:03.883Z"
   },
   {
    "duration": 55,
    "start_time": "2023-02-14T13:52:12.400Z"
   },
   {
    "duration": 647,
    "start_time": "2023-02-14T13:53:27.641Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-14T13:53:45.979Z"
   },
   {
    "duration": 663,
    "start_time": "2023-02-14T13:59:05.123Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-14T14:00:37.643Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T14:01:06.427Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T14:01:11.477Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T14:01:27.574Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T14:01:58.851Z"
   },
   {
    "duration": 23,
    "start_time": "2023-02-14T14:02:33.982Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T14:03:04.424Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-14T14:03:11.601Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-14T14:03:19.250Z"
   },
   {
    "duration": 2108,
    "start_time": "2023-02-14T14:05:05.331Z"
   },
   {
    "duration": 1489,
    "start_time": "2023-02-14T14:05:21.388Z"
   },
   {
    "duration": 18,
    "start_time": "2023-02-14T14:05:31.884Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-14T14:05:42.333Z"
   },
   {
    "duration": 18,
    "start_time": "2023-02-14T14:07:32.133Z"
   },
   {
    "duration": 19,
    "start_time": "2023-02-14T14:07:55.159Z"
   },
   {
    "duration": 89,
    "start_time": "2023-02-14T14:08:12.076Z"
   },
   {
    "duration": 850,
    "start_time": "2023-02-14T14:08:37.557Z"
   },
   {
    "duration": 39,
    "start_time": "2023-02-14T14:08:44.453Z"
   },
   {
    "duration": 99,
    "start_time": "2023-02-14T14:09:06.757Z"
   },
   {
    "duration": 994,
    "start_time": "2023-02-14T14:09:13.547Z"
   },
   {
    "duration": 36,
    "start_time": "2023-02-14T14:09:17.131Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-14T14:09:18.148Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-14T14:09:53.140Z"
   },
   {
    "duration": 77,
    "start_time": "2023-02-14T14:10:20.948Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-14T14:10:22.162Z"
   },
   {
    "duration": 164,
    "start_time": "2023-02-14T14:10:27.263Z"
   },
   {
    "duration": 253,
    "start_time": "2023-02-14T14:10:29.788Z"
   },
   {
    "duration": 8073,
    "start_time": "2023-02-14T14:10:34.132Z"
   },
   {
    "duration": 1112,
    "start_time": "2023-02-14T14:10:58.797Z"
   },
   {
    "duration": 23,
    "start_time": "2023-02-14T14:11:00.733Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-14T14:11:02.093Z"
   },
   {
    "duration": 126,
    "start_time": "2023-02-14T14:11:51.484Z"
   },
   {
    "duration": 184,
    "start_time": "2023-02-14T14:12:10.084Z"
   },
   {
    "duration": 382,
    "start_time": "2023-02-14T14:12:20.189Z"
   },
   {
    "duration": 567,
    "start_time": "2023-02-14T14:12:35.072Z"
   },
   {
    "duration": 1570,
    "start_time": "2023-02-14T14:12:40.869Z"
   },
   {
    "duration": 23,
    "start_time": "2023-02-14T14:12:42.441Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T14:13:21.029Z"
   },
   {
    "duration": 865,
    "start_time": "2023-02-14T14:13:24.572Z"
   },
   {
    "duration": 20,
    "start_time": "2023-02-14T14:13:25.439Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T14:13:27.158Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T14:13:29.597Z"
   },
   {
    "duration": 746,
    "start_time": "2023-02-14T14:14:48.226Z"
   },
   {
    "duration": 82,
    "start_time": "2023-02-14T14:14:59.038Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T14:15:08.578Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T14:15:09.633Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-14T14:15:12.866Z"
   },
   {
    "duration": 25,
    "start_time": "2023-02-14T14:16:12.948Z"
   },
   {
    "duration": 2,
    "start_time": "2023-02-14T14:16:32.639Z"
   },
   {
    "duration": 637,
    "start_time": "2023-02-14T14:16:35.165Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T14:16:36.366Z"
   },
   {
    "duration": 30,
    "start_time": "2023-02-14T14:16:37.435Z"
   },
   {
    "duration": 672,
    "start_time": "2023-02-14T14:17:42.575Z"
   },
   {
    "duration": 33,
    "start_time": "2023-02-14T14:17:44.339Z"
   },
   {
    "duration": 2,
    "start_time": "2023-02-14T14:17:47.345Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T14:17:48.165Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-14T14:17:52.727Z"
   },
   {
    "duration": 31,
    "start_time": "2023-02-14T14:18:35.742Z"
   },
   {
    "duration": 28,
    "start_time": "2023-02-14T14:18:45.331Z"
   },
   {
    "duration": 35,
    "start_time": "2023-02-14T14:18:59.733Z"
   },
   {
    "duration": 688,
    "start_time": "2023-02-14T14:19:08.183Z"
   },
   {
    "duration": 62,
    "start_time": "2023-02-14T14:19:10.758Z"
   },
   {
    "duration": 712,
    "start_time": "2023-02-14T14:19:28.029Z"
   },
   {
    "duration": 51,
    "start_time": "2023-02-14T14:19:30.581Z"
   },
   {
    "duration": 132,
    "start_time": "2023-02-14T14:20:10.831Z"
   },
   {
    "duration": 631,
    "start_time": "2023-02-14T14:20:15.958Z"
   },
   {
    "duration": 117,
    "start_time": "2023-02-14T14:20:17.938Z"
   },
   {
    "duration": 683,
    "start_time": "2023-02-14T14:20:27.798Z"
   },
   {
    "duration": 123,
    "start_time": "2023-02-14T14:20:29.542Z"
   },
   {
    "duration": 847,
    "start_time": "2023-02-14T14:20:40.415Z"
   },
   {
    "duration": 51,
    "start_time": "2023-02-14T14:20:41.264Z"
   },
   {
    "duration": 758,
    "start_time": "2023-02-14T14:22:13.271Z"
   },
   {
    "duration": 44,
    "start_time": "2023-02-14T14:22:14.886Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T14:22:16.286Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T14:22:18.074Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T14:22:32.947Z"
   },
   {
    "duration": 688,
    "start_time": "2023-02-14T14:22:57.064Z"
   },
   {
    "duration": 56,
    "start_time": "2023-02-14T14:22:58.535Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-14T14:22:59.790Z"
   },
   {
    "duration": 731,
    "start_time": "2023-02-14T14:24:19.539Z"
   },
   {
    "duration": 38,
    "start_time": "2023-02-14T14:24:21.974Z"
   },
   {
    "duration": 12,
    "start_time": "2023-02-14T14:24:25.855Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-14T14:24:45.240Z"
   },
   {
    "duration": 30,
    "start_time": "2023-02-14T14:25:10.441Z"
   },
   {
    "duration": 69,
    "start_time": "2023-02-14T14:25:17.968Z"
   },
   {
    "duration": 100,
    "start_time": "2023-02-14T14:25:28.999Z"
   },
   {
    "duration": 34,
    "start_time": "2023-02-14T14:25:30.296Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-14T14:25:44.383Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T14:25:45.665Z"
   },
   {
    "duration": 472,
    "start_time": "2023-02-14T14:25:53.790Z"
   },
   {
    "duration": 644,
    "start_time": "2023-02-14T14:26:29.018Z"
   },
   {
    "duration": 40,
    "start_time": "2023-02-14T14:26:30.128Z"
   },
   {
    "duration": 26,
    "start_time": "2023-02-14T14:26:33.447Z"
   },
   {
    "duration": 12,
    "start_time": "2023-02-14T14:26:35.422Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-14T14:26:36.722Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T14:26:38.032Z"
   },
   {
    "duration": 428,
    "start_time": "2023-02-14T14:26:38.935Z"
   },
   {
    "duration": 698,
    "start_time": "2023-02-14T14:27:02.271Z"
   },
   {
    "duration": 37,
    "start_time": "2023-02-14T14:27:06.248Z"
   },
   {
    "duration": 18,
    "start_time": "2023-02-14T14:27:49.695Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-14T14:27:51.703Z"
   },
   {
    "duration": 697,
    "start_time": "2023-02-14T14:28:48.461Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T14:28:49.731Z"
   },
   {
    "duration": 702,
    "start_time": "2023-02-14T14:29:10.999Z"
   },
   {
    "duration": 36,
    "start_time": "2023-02-14T14:29:12.260Z"
   },
   {
    "duration": 673,
    "start_time": "2023-02-14T14:29:43.992Z"
   },
   {
    "duration": 30,
    "start_time": "2023-02-14T14:29:45.271Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-14T14:29:54.448Z"
   },
   {
    "duration": 778,
    "start_time": "2023-02-14T14:30:05.177Z"
   },
   {
    "duration": 18,
    "start_time": "2023-02-14T14:30:05.957Z"
   },
   {
    "duration": 23,
    "start_time": "2023-02-14T14:30:06.752Z"
   },
   {
    "duration": 701,
    "start_time": "2023-02-14T14:31:18.479Z"
   },
   {
    "duration": 1648,
    "start_time": "2023-02-14T14:31:19.944Z"
   },
   {
    "duration": 750,
    "start_time": "2023-02-14T14:31:41.804Z"
   },
   {
    "duration": 769,
    "start_time": "2023-02-14T14:31:43.073Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T14:33:23.983Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-14T14:33:30.426Z"
   },
   {
    "duration": 718,
    "start_time": "2023-02-14T14:34:02.257Z"
   },
   {
    "duration": 16,
    "start_time": "2023-02-14T14:34:04.099Z"
   },
   {
    "duration": 654,
    "start_time": "2023-02-14T14:34:41.873Z"
   },
   {
    "duration": 84,
    "start_time": "2023-02-14T14:34:43.600Z"
   },
   {
    "duration": 90,
    "start_time": "2023-02-14T14:35:08.678Z"
   },
   {
    "duration": 678,
    "start_time": "2023-02-14T14:35:11.792Z"
   },
   {
    "duration": 71,
    "start_time": "2023-02-14T14:35:13.545Z"
   },
   {
    "duration": 16,
    "start_time": "2023-02-14T14:35:24.918Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T14:35:54.393Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T14:35:54.855Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-14T14:35:59.129Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-14T14:38:04.991Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T14:38:06.561Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-14T14:38:29.242Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-14T14:39:20.282Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-14T14:39:53.744Z"
   },
   {
    "duration": 632,
    "start_time": "2023-02-14T14:39:59.633Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-14T14:40:00.268Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T14:40:00.971Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T14:40:01.620Z"
   },
   {
    "duration": 12,
    "start_time": "2023-02-14T14:40:02.858Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-14T14:40:28.739Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-14T14:40:34.910Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-14T14:44:12.843Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T14:44:29.757Z"
   },
   {
    "duration": 635,
    "start_time": "2023-02-14T14:44:49.499Z"
   },
   {
    "duration": 20,
    "start_time": "2023-02-14T14:44:50.906Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T14:45:05.123Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T14:45:06.009Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-14T14:45:06.787Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-14T14:45:43.916Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T14:45:53.299Z"
   },
   {
    "duration": 2,
    "start_time": "2023-02-14T14:46:00.843Z"
   },
   {
    "duration": 627,
    "start_time": "2023-02-14T14:46:05.540Z"
   },
   {
    "duration": 639,
    "start_time": "2023-02-14T14:46:21.474Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T14:46:22.587Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-14T14:46:25.318Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T14:46:45.028Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-14T14:47:15.644Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T14:47:18.978Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T14:47:24.171Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-14T14:47:25.563Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T14:47:27.655Z"
   },
   {
    "duration": 82,
    "start_time": "2023-02-14T14:49:30.427Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-14T14:49:37.062Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T14:50:00.332Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T14:50:19.939Z"
   },
   {
    "duration": 734,
    "start_time": "2023-02-14T14:50:24.948Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T14:50:25.684Z"
   },
   {
    "duration": 27,
    "start_time": "2023-02-14T14:50:25.689Z"
   },
   {
    "duration": 21,
    "start_time": "2023-02-14T14:50:25.718Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T14:50:25.875Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-14T14:50:26.737Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T14:50:27.179Z"
   },
   {
    "duration": 98,
    "start_time": "2023-02-14T14:50:27.539Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-14T14:50:28.668Z"
   },
   {
    "duration": 82,
    "start_time": "2023-02-14T14:50:47.948Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-14T14:50:48.694Z"
   },
   {
    "duration": 94,
    "start_time": "2023-02-14T14:50:56.931Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-14T14:50:58.039Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-14T14:51:28.069Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T14:51:50.974Z"
   },
   {
    "duration": 28,
    "start_time": "2023-02-14T14:52:51.131Z"
   },
   {
    "duration": 26,
    "start_time": "2023-02-14T14:52:56.631Z"
   },
   {
    "duration": 103,
    "start_time": "2023-02-14T14:53:12.580Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T14:53:13.045Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-14T14:53:13.524Z"
   },
   {
    "duration": 203,
    "start_time": "2023-02-14T14:53:23.141Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-14T14:53:23.620Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T14:53:25.061Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "af7472ffbb6f11e94eca2dc243fc9b09d1dc0fb11170c3918ea151f7aad82d25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
