{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Установка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nltk # доустанавливаем необходимые библиотеки\n",
    "# pip install pywsd\n",
    "# pip install transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import transformers \n",
    "import transformers as ppb # pytorch transformers\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from tqdm import notebook\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from urllib.parse import urlencode # для задания адреса таблицы в я.диске\n",
    "import requests #получить финальный url я.диска\n",
    "\n",
    "import nltk\n",
    "import re \n",
    "from pywsd.utils import lemmatize_sentence #лемматизатор\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка констант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 100\n",
    "max_len = 512"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Знакомство с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159292, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('toxic_comments.csv')\n",
    "except:\n",
    "    df = pd.read_csv(r'C:\\Users\\maxpe\\Downloads\\Practicum\\Projects\\datasets\\toxic_comments.csv')\n",
    "display(df.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет не содержит пустых строк, состоит из 3 столбцов, один из которых будет преобразован в признаки (`text`), а `toxic` - целевой признак. Столбец `Unnamed` можем удалить. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных для BERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка предобученных модели и токенизатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим любой рандомный текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 2017,\n",
       " 1010,\n",
       " 2909,\n",
       " 1010,\n",
       " 2024,\n",
       " 2026,\n",
       " 5394,\n",
       " 1012,\n",
       " 2151,\n",
       " 3382,\n",
       " 2017,\n",
       " 3342,\n",
       " 1012,\n",
       " 1012,\n",
       " 102]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('You, sir, are my hero. Any chance you remember..', add_special_tokens=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизатор отрабатывает корректно. Применим его предварительно к датасету."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразуем текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "pre_tokenized = df['text'].apply(\n",
    "  lambda x: tokenizer.encode(x, add_special_tokens=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [101, 7526, 2339, 1996, 10086, 2015, 2081, 210...\n",
       "1         [101, 1040, 1005, 22091, 2860, 999, 2002, 3503...\n",
       "2         [101, 4931, 2158, 1010, 1045, 1005, 1049, 2428...\n",
       "3         [101, 1000, 2062, 1045, 2064, 1005, 1056, 2191...\n",
       "4         [101, 2017, 1010, 2909, 1010, 2024, 2026, 5394...\n",
       "                                ...                        \n",
       "159287    [101, 1000, 1024, 1024, 1024, 1024, 1024, 1998...\n",
       "159288    [101, 2017, 2323, 2022, 14984, 1997, 4426, 200...\n",
       "159289    [101, 13183, 6290, 26114, 1010, 2045, 2015, 20...\n",
       "159290    [101, 1998, 2009, 3504, 2066, 2009, 2001, 2941...\n",
       "159291    [101, 1000, 1998, 1012, 1012, 1012, 1045, 2428...\n",
       "Name: text, Length: 159292, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_tokenized"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим из сообщения к `pre_tokenized`, имеем ограничение в 512 токенов в строке. Создадим такое ограничение."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Фильтруем данные"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем датасет из токенизированных данных - столбец `text`, целевого признака и длин списков токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 7526, 2339, 1996, 10086, 2015, 2081, 210...</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 1040, 1005, 22091, 2860, 999, 2002, 3503...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 4931, 2158, 1010, 1045, 1005, 1049, 2428...</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[101, 1000, 2062, 1045, 2064, 1005, 1056, 2191...</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[101, 2017, 1010, 2909, 1010, 2024, 2026, 5394...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>[101, 1000, 1024, 1024, 1024, 1024, 1024, 1998...</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>[101, 2017, 2323, 2022, 14984, 1997, 4426, 200...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>[101, 13183, 6290, 26114, 1010, 2045, 2015, 20...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>[101, 1998, 2009, 3504, 2066, 2009, 2001, 2941...</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>[101, 1000, 1998, 1012, 1012, 1012, 1045, 2428...</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  len\n",
       "0       [101, 7526, 2339, 1996, 10086, 2015, 2081, 210...      0   68\n",
       "1       [101, 1040, 1005, 22091, 2860, 999, 2002, 3503...      0   35\n",
       "2       [101, 4931, 2158, 1010, 1045, 1005, 1049, 2428...      0   54\n",
       "3       [101, 1000, 2062, 1045, 2064, 1005, 1056, 2191...      0  144\n",
       "4       [101, 2017, 1010, 2909, 1010, 2024, 2026, 5394...      0   21\n",
       "...                                                   ...    ...  ...\n",
       "159287  [101, 1000, 1024, 1024, 1024, 1024, 1024, 1998...      0   68\n",
       "159288  [101, 2017, 2323, 2022, 14984, 1997, 4426, 200...      0   27\n",
       "159289  [101, 13183, 6290, 26114, 1010, 2045, 2015, 20...      0   19\n",
       "159290  [101, 1998, 2009, 3504, 2066, 2009, 2001, 2941...      0   28\n",
       "159291  [101, 1000, 1998, 1012, 1012, 1012, 1045, 2428...      0   51\n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = pd.DataFrame(pre_tokenized)\n",
    "df_temp['toxic'] = df['toxic']\n",
    "len_list = []\n",
    "for i in df_temp['text']:\n",
    "    len_list.append(len(i))\n",
    "df_temp['len'] = len_list\n",
    "df_temp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляем строки с превышающими лимит токенами. таких строк порядка 1.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_temp.loc[df_temp['len'] < 513].drop(['len'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем данные по индексу: слева - тексты из исходного датасета, справа - целевой признак из нового, отфильтрованного датасета. Так как `join` имеет значение `inner`, то остаются только те строки, в которых совпадает индекс, то есть прошедшие фильтрацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155789 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159287  \":::::And for the second time of asking, when ...      0\n",
       "159288  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159289  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159290  And it looks like it was actually you who put ...      0\n",
       "159291  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[155789 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_left = df['text']\n",
    "df_right = df_temp['toxic']\n",
    "result = pd.concat([df_left, df_right], axis=1, join=\"inner\")\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае преобразования в эмбенддинги внутри ноутбука, код ниже - указывает количество семплов для будущего датасета, где `q_sample = len(result)` - это полный датасет.\n",
    "\n",
    "Ниже приведен пример расчета для очень маленькой выборки - взяли 100 строк, чтобы показать работоспособность кода. \n",
    "\n",
    "Полный преобразованный датасет будет использоваться уже на этапе разделения признаков и целевого признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_sample = 100 # нужное число для датасета, вплоть до q_sample = len(result)\n",
    "result = result.sample(q_sample).reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразуем текст предобработанных данных"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизируем отфильтрованную выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = result['text'].apply(\n",
    "  lambda x: tokenizer.encode(x, add_special_tokens=True)) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предупреждения больше нет. Максимальная длина токена `max_len` равна ограничению - 512. Вынесли это значения в константы.\n",
    "\n",
    "При исполнении преобразования внутри ноутбука, `max_len` расчитывается ниже. Так как мы случайным образом отберем какое-то количество строк, может случиться, что строки будут короче константной `max_len = 512`, это нужно учитывать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "427"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "max_len"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразование векторов"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Паддингом добавляем к каждому вектору нули в конец, так, чтобы длина каждого вектора была равна длине `max_len`.\n",
    "\n",
    "Маска тоже применяется к каждому вектору - значению, отличному от нуля, присваивается 1, нули остаются нулями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заранее рассчитанные данные:\n",
    "- В Яндекс.Диске лежит датасет, содержащий 78% данных (ограничение по размеру файла), при батче равном 200. Он будет прочитан позже.\n",
    "\n",
    "Преобразование эмбеддингов было произведено в Google Colab, с использованием GPU."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразование в эмбеддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02424907684326172,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec02e1479efc4faf94c002c471169561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.180258</td>\n",
       "      <td>-0.069345</td>\n",
       "      <td>0.067308</td>\n",
       "      <td>0.129491</td>\n",
       "      <td>0.527740</td>\n",
       "      <td>-0.173354</td>\n",
       "      <td>-0.136002</td>\n",
       "      <td>0.456516</td>\n",
       "      <td>-0.261843</td>\n",
       "      <td>0.051326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232042</td>\n",
       "      <td>0.065451</td>\n",
       "      <td>-0.136329</td>\n",
       "      <td>-0.036738</td>\n",
       "      <td>0.351970</td>\n",
       "      <td>-0.020417</td>\n",
       "      <td>-0.090589</td>\n",
       "      <td>0.355534</td>\n",
       "      <td>0.694603</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.257796</td>\n",
       "      <td>0.173529</td>\n",
       "      <td>-0.096371</td>\n",
       "      <td>0.362834</td>\n",
       "      <td>0.370819</td>\n",
       "      <td>-0.450347</td>\n",
       "      <td>0.213386</td>\n",
       "      <td>0.352308</td>\n",
       "      <td>-0.219311</td>\n",
       "      <td>-0.073698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227018</td>\n",
       "      <td>0.164091</td>\n",
       "      <td>-0.001414</td>\n",
       "      <td>-0.043954</td>\n",
       "      <td>0.117454</td>\n",
       "      <td>-0.126218</td>\n",
       "      <td>0.072296</td>\n",
       "      <td>0.454344</td>\n",
       "      <td>0.253548</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.265842</td>\n",
       "      <td>0.079536</td>\n",
       "      <td>-0.008228</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0.048826</td>\n",
       "      <td>-0.294324</td>\n",
       "      <td>0.248901</td>\n",
       "      <td>0.595242</td>\n",
       "      <td>-0.146441</td>\n",
       "      <td>-0.640853</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.497844</td>\n",
       "      <td>0.252351</td>\n",
       "      <td>-0.408397</td>\n",
       "      <td>0.076342</td>\n",
       "      <td>0.369730</td>\n",
       "      <td>-0.198952</td>\n",
       "      <td>0.018505</td>\n",
       "      <td>0.258208</td>\n",
       "      <td>0.606681</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.392533</td>\n",
       "      <td>-0.003290</td>\n",
       "      <td>-0.242121</td>\n",
       "      <td>-0.003258</td>\n",
       "      <td>0.386686</td>\n",
       "      <td>-0.093546</td>\n",
       "      <td>-0.177152</td>\n",
       "      <td>0.280647</td>\n",
       "      <td>-0.556676</td>\n",
       "      <td>0.267730</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.329821</td>\n",
       "      <td>0.188621</td>\n",
       "      <td>0.107821</td>\n",
       "      <td>0.146280</td>\n",
       "      <td>0.266547</td>\n",
       "      <td>-0.132216</td>\n",
       "      <td>0.083194</td>\n",
       "      <td>0.331464</td>\n",
       "      <td>0.399364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041432</td>\n",
       "      <td>0.458728</td>\n",
       "      <td>0.125541</td>\n",
       "      <td>-0.458067</td>\n",
       "      <td>-0.359498</td>\n",
       "      <td>-0.516204</td>\n",
       "      <td>0.612352</td>\n",
       "      <td>0.468278</td>\n",
       "      <td>0.044442</td>\n",
       "      <td>-0.177572</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072933</td>\n",
       "      <td>-0.018716</td>\n",
       "      <td>-0.308049</td>\n",
       "      <td>0.574486</td>\n",
       "      <td>0.226451</td>\n",
       "      <td>-0.231072</td>\n",
       "      <td>-0.202866</td>\n",
       "      <td>0.580723</td>\n",
       "      <td>0.638694</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.259413</td>\n",
       "      <td>-0.284309</td>\n",
       "      <td>-0.201027</td>\n",
       "      <td>-0.017551</td>\n",
       "      <td>-0.449832</td>\n",
       "      <td>-0.614521</td>\n",
       "      <td>-0.027409</td>\n",
       "      <td>0.587838</td>\n",
       "      <td>-0.205535</td>\n",
       "      <td>0.024848</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.291052</td>\n",
       "      <td>0.299488</td>\n",
       "      <td>-0.591564</td>\n",
       "      <td>0.097257</td>\n",
       "      <td>1.108976</td>\n",
       "      <td>-0.219779</td>\n",
       "      <td>-0.332158</td>\n",
       "      <td>0.165074</td>\n",
       "      <td>0.691611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.333628</td>\n",
       "      <td>0.137654</td>\n",
       "      <td>-0.122666</td>\n",
       "      <td>0.026730</td>\n",
       "      <td>-0.218588</td>\n",
       "      <td>-0.236194</td>\n",
       "      <td>-0.025301</td>\n",
       "      <td>0.512384</td>\n",
       "      <td>-0.221927</td>\n",
       "      <td>0.041977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123007</td>\n",
       "      <td>0.256707</td>\n",
       "      <td>-0.086893</td>\n",
       "      <td>0.220921</td>\n",
       "      <td>0.204233</td>\n",
       "      <td>-0.049905</td>\n",
       "      <td>-0.264247</td>\n",
       "      <td>0.445555</td>\n",
       "      <td>0.525016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.048696</td>\n",
       "      <td>0.212514</td>\n",
       "      <td>-0.015065</td>\n",
       "      <td>-0.160278</td>\n",
       "      <td>-0.397783</td>\n",
       "      <td>-0.397764</td>\n",
       "      <td>0.431256</td>\n",
       "      <td>0.466553</td>\n",
       "      <td>0.138425</td>\n",
       "      <td>-0.281985</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.322410</td>\n",
       "      <td>0.049418</td>\n",
       "      <td>-0.418673</td>\n",
       "      <td>-0.008705</td>\n",
       "      <td>-0.012006</td>\n",
       "      <td>-0.205094</td>\n",
       "      <td>-0.179316</td>\n",
       "      <td>0.340955</td>\n",
       "      <td>0.728311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.494844</td>\n",
       "      <td>-0.336033</td>\n",
       "      <td>0.245763</td>\n",
       "      <td>-0.179141</td>\n",
       "      <td>-0.247788</td>\n",
       "      <td>-0.195357</td>\n",
       "      <td>0.084165</td>\n",
       "      <td>0.652698</td>\n",
       "      <td>-0.487815</td>\n",
       "      <td>-0.468103</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099521</td>\n",
       "      <td>-0.098415</td>\n",
       "      <td>-0.173609</td>\n",
       "      <td>0.118502</td>\n",
       "      <td>0.019956</td>\n",
       "      <td>-0.025561</td>\n",
       "      <td>-0.542009</td>\n",
       "      <td>0.321918</td>\n",
       "      <td>0.656737</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.057036</td>\n",
       "      <td>-0.181161</td>\n",
       "      <td>-0.069798</td>\n",
       "      <td>0.103241</td>\n",
       "      <td>0.200080</td>\n",
       "      <td>-0.491464</td>\n",
       "      <td>0.043683</td>\n",
       "      <td>0.074803</td>\n",
       "      <td>0.118653</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081268</td>\n",
       "      <td>0.067643</td>\n",
       "      <td>-0.316171</td>\n",
       "      <td>0.112910</td>\n",
       "      <td>0.390269</td>\n",
       "      <td>-0.009387</td>\n",
       "      <td>-0.285203</td>\n",
       "      <td>0.327809</td>\n",
       "      <td>0.650036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0   0.180258 -0.069345  0.067308  0.129491  0.527740 -0.173354 -0.136002   \n",
       "1   0.257796  0.173529 -0.096371  0.362834  0.370819 -0.450347  0.213386   \n",
       "2  -0.265842  0.079536 -0.008228  0.050172  0.048826 -0.294324  0.248901   \n",
       "3   0.392533 -0.003290 -0.242121 -0.003258  0.386686 -0.093546 -0.177152   \n",
       "4   0.041432  0.458728  0.125541 -0.458067 -0.359498 -0.516204  0.612352   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95 -0.259413 -0.284309 -0.201027 -0.017551 -0.449832 -0.614521 -0.027409   \n",
       "96  0.333628  0.137654 -0.122666  0.026730 -0.218588 -0.236194 -0.025301   \n",
       "97 -0.048696  0.212514 -0.015065 -0.160278 -0.397783 -0.397764  0.431256   \n",
       "98 -0.494844 -0.336033  0.245763 -0.179141 -0.247788 -0.195357  0.084165   \n",
       "99 -0.057036 -0.181161 -0.069798  0.103241  0.200080 -0.491464  0.043683   \n",
       "\n",
       "           7         8         9  ...       759       760       761       762  \\\n",
       "0   0.456516 -0.261843  0.051326  ...  0.232042  0.065451 -0.136329 -0.036738   \n",
       "1   0.352308 -0.219311 -0.073698  ...  0.227018  0.164091 -0.001414 -0.043954   \n",
       "2   0.595242 -0.146441 -0.640853  ... -0.497844  0.252351 -0.408397  0.076342   \n",
       "3   0.280647 -0.556676  0.267730  ... -0.329821  0.188621  0.107821  0.146280   \n",
       "4   0.468278  0.044442 -0.177572  ... -0.072933 -0.018716 -0.308049  0.574486   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "95  0.587838 -0.205535  0.024848  ... -0.291052  0.299488 -0.591564  0.097257   \n",
       "96  0.512384 -0.221927  0.041977  ...  0.123007  0.256707 -0.086893  0.220921   \n",
       "97  0.466553  0.138425 -0.281985  ... -0.322410  0.049418 -0.418673 -0.008705   \n",
       "98  0.652698 -0.487815 -0.468103  ... -0.099521 -0.098415 -0.173609  0.118502   \n",
       "99  0.074803  0.118653  0.000054  ...  0.081268  0.067643 -0.316171  0.112910   \n",
       "\n",
       "         763       764       765       766       767  toxic  \n",
       "0   0.351970 -0.020417 -0.090589  0.355534  0.694603      0  \n",
       "1   0.117454 -0.126218  0.072296  0.454344  0.253548      0  \n",
       "2   0.369730 -0.198952  0.018505  0.258208  0.606681      0  \n",
       "3   0.266547 -0.132216  0.083194  0.331464  0.399364      0  \n",
       "4   0.226451 -0.231072 -0.202866  0.580723  0.638694      0  \n",
       "..       ...       ...       ...       ...       ...    ...  \n",
       "95  1.108976 -0.219779 -0.332158  0.165074  0.691611      0  \n",
       "96  0.204233 -0.049905 -0.264247  0.445555  0.525016      0  \n",
       "97 -0.012006 -0.205094 -0.179316  0.340955  0.728311      0  \n",
       "98  0.019956 -0.025561 -0.542009  0.321918  0.656737      0  \n",
       "99  0.390269 -0.009387 -0.285203  0.327809  0.650036      0  \n",
       "\n",
       "[100 rows x 769 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50 # задаем размер батча (кратен q_sample, если уменьшаем q_sample - уменьшаем и батч)\n",
    "embeddings = [] # список эмбеддингов\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)): # цикл по батчам, отображать прогресс будет функция notebook()\n",
    "        batch = torch.IntTensor(padded[batch_size*i:batch_size*(i+1)]) # преобразуем данные в формат тензоров\n",
    "        attention_mask_batch = torch.IntTensor(attention_mask[batch_size*i:batch_size*(i+1)]) # преобразуем маску\n",
    "        \n",
    "        with torch.no_grad(): # для ускорения вычисления функцией no_grad() в библиотеке torch укажем, что градиенты не нужны\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch) # чтобы получить эмбеддинги для батча, передадим модели данные и маску\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy()) # преобразуем элементы методом numpy() к типу numpy.array\n",
    "\n",
    "df_ed = pd.DataFrame(np.concatenate(embeddings)) # соберём все эмбеддинги в матрицу признаков вызовом функции concatenate()\n",
    "df_ed['toxic'] = result['toxic'] # добавляем целевой признак\n",
    "df_ed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код выше, показывает механизм преобразования эмбеддингов на маленькой выборке. То же самое было расчитано на всем датасете. Прочитаем его."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выгрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ed.to_csv('df_ed_20k.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выгружаем датасет после этапа преобразования в эмбеддинги, для того, чтобы не пересчитывать их в следующий сеанс или на другом устройстве. Выгрузка датасета закомментирована, она не должна больше исполняться."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка датасета"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитанные эмбендинги в Colab я сохранил в Яндекс.Диске. Здесь сохранен неполный датасет, порядка 78% от исходного. Прочитаем `csv-файл`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.214180</td>\n",
       "      <td>0.147004</td>\n",
       "      <td>-0.198792</td>\n",
       "      <td>0.039257</td>\n",
       "      <td>-0.117727</td>\n",
       "      <td>-0.340003</td>\n",
       "      <td>-0.144716</td>\n",
       "      <td>0.312527</td>\n",
       "      <td>-0.208113</td>\n",
       "      <td>-0.603441</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.209616</td>\n",
       "      <td>0.381346</td>\n",
       "      <td>0.129333</td>\n",
       "      <td>0.156410</td>\n",
       "      <td>-0.196734</td>\n",
       "      <td>-0.076245</td>\n",
       "      <td>-0.302536</td>\n",
       "      <td>0.222647</td>\n",
       "      <td>0.358534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.352702</td>\n",
       "      <td>0.166299</td>\n",
       "      <td>0.279629</td>\n",
       "      <td>-0.027249</td>\n",
       "      <td>0.170146</td>\n",
       "      <td>-0.320978</td>\n",
       "      <td>0.132645</td>\n",
       "      <td>0.255978</td>\n",
       "      <td>-0.076715</td>\n",
       "      <td>-0.255779</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071787</td>\n",
       "      <td>-0.004774</td>\n",
       "      <td>-0.050075</td>\n",
       "      <td>0.283952</td>\n",
       "      <td>0.130654</td>\n",
       "      <td>-0.132127</td>\n",
       "      <td>-0.168120</td>\n",
       "      <td>0.573513</td>\n",
       "      <td>0.351487</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.390808</td>\n",
       "      <td>0.389703</td>\n",
       "      <td>0.201352</td>\n",
       "      <td>-0.158126</td>\n",
       "      <td>-0.351628</td>\n",
       "      <td>-0.587400</td>\n",
       "      <td>0.745436</td>\n",
       "      <td>0.543038</td>\n",
       "      <td>0.301617</td>\n",
       "      <td>-0.075048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.401640</td>\n",
       "      <td>0.525003</td>\n",
       "      <td>-0.361147</td>\n",
       "      <td>0.151722</td>\n",
       "      <td>0.284467</td>\n",
       "      <td>-0.114487</td>\n",
       "      <td>-0.712322</td>\n",
       "      <td>0.500326</td>\n",
       "      <td>0.233124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.172516</td>\n",
       "      <td>-0.347529</td>\n",
       "      <td>0.091326</td>\n",
       "      <td>0.274101</td>\n",
       "      <td>-0.638771</td>\n",
       "      <td>-0.430128</td>\n",
       "      <td>0.085095</td>\n",
       "      <td>0.347237</td>\n",
       "      <td>-0.185096</td>\n",
       "      <td>-0.064509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003850</td>\n",
       "      <td>0.156936</td>\n",
       "      <td>-0.172188</td>\n",
       "      <td>-0.043264</td>\n",
       "      <td>0.498429</td>\n",
       "      <td>-0.266780</td>\n",
       "      <td>-0.493660</td>\n",
       "      <td>0.516713</td>\n",
       "      <td>0.692796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.525008</td>\n",
       "      <td>-0.264399</td>\n",
       "      <td>-0.078045</td>\n",
       "      <td>-0.365558</td>\n",
       "      <td>-0.029540</td>\n",
       "      <td>-0.140087</td>\n",
       "      <td>0.207137</td>\n",
       "      <td>0.112012</td>\n",
       "      <td>-0.148200</td>\n",
       "      <td>-0.204890</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169026</td>\n",
       "      <td>-0.345219</td>\n",
       "      <td>-0.417685</td>\n",
       "      <td>-0.296221</td>\n",
       "      <td>-0.003516</td>\n",
       "      <td>-0.313758</td>\n",
       "      <td>-0.492042</td>\n",
       "      <td>0.370257</td>\n",
       "      <td>0.604431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121363</th>\n",
       "      <td>-0.212598</td>\n",
       "      <td>0.256898</td>\n",
       "      <td>-0.447700</td>\n",
       "      <td>0.227991</td>\n",
       "      <td>0.286868</td>\n",
       "      <td>-0.134953</td>\n",
       "      <td>0.286301</td>\n",
       "      <td>0.290358</td>\n",
       "      <td>-0.119520</td>\n",
       "      <td>-0.162863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228032</td>\n",
       "      <td>0.299517</td>\n",
       "      <td>-0.117757</td>\n",
       "      <td>0.055547</td>\n",
       "      <td>0.581419</td>\n",
       "      <td>-0.358383</td>\n",
       "      <td>-0.404726</td>\n",
       "      <td>0.595774</td>\n",
       "      <td>0.296562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121364</th>\n",
       "      <td>0.159202</td>\n",
       "      <td>0.578980</td>\n",
       "      <td>0.106536</td>\n",
       "      <td>-0.247540</td>\n",
       "      <td>-0.566379</td>\n",
       "      <td>-0.770876</td>\n",
       "      <td>0.918120</td>\n",
       "      <td>0.894100</td>\n",
       "      <td>0.635024</td>\n",
       "      <td>-0.554825</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121072</td>\n",
       "      <td>0.448461</td>\n",
       "      <td>-0.421211</td>\n",
       "      <td>-0.195475</td>\n",
       "      <td>0.213188</td>\n",
       "      <td>-0.265779</td>\n",
       "      <td>-0.492184</td>\n",
       "      <td>0.749388</td>\n",
       "      <td>0.467811</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121365</th>\n",
       "      <td>-0.183408</td>\n",
       "      <td>-0.071542</td>\n",
       "      <td>-0.303102</td>\n",
       "      <td>-0.209128</td>\n",
       "      <td>-0.538787</td>\n",
       "      <td>-0.419055</td>\n",
       "      <td>0.380409</td>\n",
       "      <td>0.182944</td>\n",
       "      <td>0.382511</td>\n",
       "      <td>-0.468929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184913</td>\n",
       "      <td>-0.053646</td>\n",
       "      <td>-0.508643</td>\n",
       "      <td>-0.307283</td>\n",
       "      <td>0.272276</td>\n",
       "      <td>-0.089274</td>\n",
       "      <td>0.003302</td>\n",
       "      <td>0.500062</td>\n",
       "      <td>0.727596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121366</th>\n",
       "      <td>-0.865203</td>\n",
       "      <td>-0.198704</td>\n",
       "      <td>-0.309393</td>\n",
       "      <td>-0.249649</td>\n",
       "      <td>-0.151374</td>\n",
       "      <td>0.112604</td>\n",
       "      <td>0.326239</td>\n",
       "      <td>0.257939</td>\n",
       "      <td>-0.153978</td>\n",
       "      <td>-0.107524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156371</td>\n",
       "      <td>-0.256471</td>\n",
       "      <td>-0.130817</td>\n",
       "      <td>0.261458</td>\n",
       "      <td>-0.010640</td>\n",
       "      <td>-0.337773</td>\n",
       "      <td>-0.589161</td>\n",
       "      <td>0.084944</td>\n",
       "      <td>0.195185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121367</th>\n",
       "      <td>-0.350851</td>\n",
       "      <td>0.153475</td>\n",
       "      <td>-0.000659</td>\n",
       "      <td>-0.175750</td>\n",
       "      <td>0.097799</td>\n",
       "      <td>-0.125996</td>\n",
       "      <td>0.166500</td>\n",
       "      <td>0.109540</td>\n",
       "      <td>-0.282164</td>\n",
       "      <td>-0.295945</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013262</td>\n",
       "      <td>-0.041247</td>\n",
       "      <td>0.148737</td>\n",
       "      <td>0.262797</td>\n",
       "      <td>0.274336</td>\n",
       "      <td>-0.072843</td>\n",
       "      <td>-0.352375</td>\n",
       "      <td>0.213584</td>\n",
       "      <td>0.661390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121368 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0      -0.214180  0.147004 -0.198792  0.039257 -0.117727 -0.340003 -0.144716   \n",
       "1       0.352702  0.166299  0.279629 -0.027249  0.170146 -0.320978  0.132645   \n",
       "2      -0.390808  0.389703  0.201352 -0.158126 -0.351628 -0.587400  0.745436   \n",
       "3      -0.172516 -0.347529  0.091326  0.274101 -0.638771 -0.430128  0.085095   \n",
       "4      -0.525008 -0.264399 -0.078045 -0.365558 -0.029540 -0.140087  0.207137   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "121363 -0.212598  0.256898 -0.447700  0.227991  0.286868 -0.134953  0.286301   \n",
       "121364  0.159202  0.578980  0.106536 -0.247540 -0.566379 -0.770876  0.918120   \n",
       "121365 -0.183408 -0.071542 -0.303102 -0.209128 -0.538787 -0.419055  0.380409   \n",
       "121366 -0.865203 -0.198704 -0.309393 -0.249649 -0.151374  0.112604  0.326239   \n",
       "121367 -0.350851  0.153475 -0.000659 -0.175750  0.097799 -0.125996  0.166500   \n",
       "\n",
       "               7         8         9  ...       759       760       761  \\\n",
       "0       0.312527 -0.208113 -0.603441  ... -0.209616  0.381346  0.129333   \n",
       "1       0.255978 -0.076715 -0.255779  ... -0.071787 -0.004774 -0.050075   \n",
       "2       0.543038  0.301617 -0.075048  ... -0.401640  0.525003 -0.361147   \n",
       "3       0.347237 -0.185096 -0.064509  ...  0.003850  0.156936 -0.172188   \n",
       "4       0.112012 -0.148200 -0.204890  ... -0.169026 -0.345219 -0.417685   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "121363  0.290358 -0.119520 -0.162863  ...  0.228032  0.299517 -0.117757   \n",
       "121364  0.894100  0.635024 -0.554825  ... -0.121072  0.448461 -0.421211   \n",
       "121365  0.182944  0.382511 -0.468929  ... -0.184913 -0.053646 -0.508643   \n",
       "121366  0.257939 -0.153978 -0.107524  ...  0.156371 -0.256471 -0.130817   \n",
       "121367  0.109540 -0.282164 -0.295945  ... -0.013262 -0.041247  0.148737   \n",
       "\n",
       "             762       763       764       765       766       767  toxic  \n",
       "0       0.156410 -0.196734 -0.076245 -0.302536  0.222647  0.358534      0  \n",
       "1       0.283952  0.130654 -0.132127 -0.168120  0.573513  0.351487      1  \n",
       "2       0.151722  0.284467 -0.114487 -0.712322  0.500326  0.233124      1  \n",
       "3      -0.043264  0.498429 -0.266780 -0.493660  0.516713  0.692796      0  \n",
       "4      -0.296221 -0.003516 -0.313758 -0.492042  0.370257  0.604431      0  \n",
       "...          ...       ...       ...       ...       ...       ...    ...  \n",
       "121363  0.055547  0.581419 -0.358383 -0.404726  0.595774  0.296562      0  \n",
       "121364 -0.195475  0.213188 -0.265779 -0.492184  0.749388  0.467811      1  \n",
       "121365 -0.307283  0.272276 -0.089274  0.003302  0.500062  0.727596      0  \n",
       "121366  0.261458 -0.010640 -0.337773 -0.589161  0.084944  0.195185      0  \n",
       "121367  0.262797  0.274336 -0.072843 -0.352375  0.213584  0.661390      0  \n",
       "\n",
       "[121368 rows x 769 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# используем api \n",
    "base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?' \n",
    "public_key = 'https://disk.yandex.ru/d/KLot7E--emZcKg' \n",
    " \n",
    "# получаем url \n",
    "final_url = base_url + urlencode(dict(public_key=public_key)) \n",
    "response = requests.get(final_url) \n",
    "download_url = response.json()['href'] \n",
    " \n",
    "# загружаем файл в df \n",
    "download_response = requests.get(download_url)\n",
    "df_ed_78 = pd.read_csv(download_url, sep=',')\n",
    "df_ed_78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ed_78 = df_ed_78.astype('float32') #меняем тип - чтобы при работе с данными требовалось меньше памяти\n",
    "df_ed_78['toxic'] = df_ed_78['toxic'].astype('int')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение для BERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ограничение датасета"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как датасет получается тяжелым, чтобы была возможность на его данных провести обучение, их нужно немного разделить. Сделаем это с помощью `train_test_split`, чтобы сохранить соотношение в целевом признаке.\n",
    "\n",
    "Таблица `out` - это таблица неиспользуемых данных. Их слишком много, чтобы оборудование было способно их обработать.\n",
    "\n",
    "Соотношение 0.1 - это 10% на второй сет в сплите, то есть порядка 12 тысяч строк будет при таком соотношении во втором датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, df_ed = train_test_split(df_ed_78, test_size=0.1, random_state=RANDOM_STATE, stratify= df_ed_78['toxic']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12137 entries, 39465 to 20976\n",
      "Columns: 769 entries, 0 to toxic\n",
      "dtypes: float32(768), int32(1)\n",
      "memory usage: 35.7 MB\n"
     ]
    }
   ],
   "source": [
    "df_ed.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разбиение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split( #создаем 4 датасета, два признаков (тест+валидация) и два целевых, \n",
    "    df_ed.drop(columns='toxic'), #для датасетов признаков удаляем целевой\n",
    "    df_ed['toxic'], #для целевого оставляем только целевой\n",
    "    test_size=0.2, #с соотношением \n",
    "    random_state=RANDOM_STATE, #с заданной опорой для рандома \n",
    "    stratify= df_ed['toxic']) #с заданной стратификацией по целевому признаку"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение метрики F1 для модели логистической регрессии с использованием кросс-валидации: 0.6284264732021358\n",
      "CPU times: total: 56.1 s\n",
      "Wall time: 26.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "log_reg = LogisticRegression(solver='lbfgs', max_iter=1000, class_weight= 'balanced') #максимальное количество итераций 1000, \n",
    "log_reg_scores = cross_val_score(log_reg, features_train, target_train.values, scoring='f1', cv=10)\n",
    "log_reg_f1 = log_reg_scores.mean()\n",
    "\n",
    "print(\"Среднее значение метрики F1 для модели логистической регрессии \"\\\n",
    "    \"с использованием кросс-валидации:\", log_reg_f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель опорных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение метрики F1 для модели SVC с использованием кросс-валидации: 0.6631569448391847\n",
      "CPU times: total: 45.5 s\n",
      "Wall time: 49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "svclassifier = SVC(kernel='linear') \n",
    "svclassifier_scores = cross_val_score(svclassifier, features_train, target_train.values, scoring='f1', cv=10)\n",
    "svclassifier_f1 = svclassifier_scores.mean()\n",
    "\n",
    "print(\"Среднее значение метрики F1 для модели SVC \"\\\n",
    "    \"с использованием кросс-валидации:\", svclassifier_f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для модели случайного леса с использованием кросс-валидации: {'n_estimators': 106, 'max_depth': 9}\n",
      "Наибольшее значение метрики F1 для модели случайного леса при лучших гиперпараметрах с использованием кросс-валидации: 0.6142330101451825\n",
      "CPU times: total: 11 s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "forest = RandomForestClassifier(random_state=RANDOM_STATE, class_weight= 'balanced') #модель случайного леса\n",
    "parameters = {'n_estimators': range (1, 300), 'max_depth': range (1, 50)} #перебор гиперпараметров\n",
    "#применение метода гридсёрч со встроенной кросс-валидацией к модели леса с перебором указанных параметров\n",
    "\n",
    "randomized_forest = RandomizedSearchCV(forest, n_iter=20, param_distributions= parameters, scoring='f1', n_jobs= -3, cv=5)\n",
    "#обучение модели\n",
    "randomized_forest.fit(features_train, target_train.values)\n",
    "\n",
    "#лучшее значение после перебора параметров \n",
    "best_forest = abs(randomized_forest.best_score_)\n",
    "\n",
    "print(\"Лучшие параметры для модели случайного леса с \"\\\n",
    "    \"использованием кросс-валидации:\", randomized_forest.best_params_)\n",
    "print(\"Наибольшее значение метрики F1 для модели случайного леса \"\\\n",
    "    \"при лучших гиперпараметрах с использованием кросс-валидации:\", best_forest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для модели случайного леса с использованием кросс-валидации: {'n_estimators': 617, 'max_depth': 97, 'learning_rate': 0.3}\n",
      "Наибольшее значение метрики F1 для модели LGBMClassifier при лучших гиперпараметрах с использованием кросс-валидации: 0.6463309945210048\n",
      "CPU times: total: 1min 20s\n",
      "Wall time: 7min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgbm = lgb.LGBMClassifier() #\n",
    "parameters = {'n_estimators': range (1, 1000), 'max_depth': range (1, 100), 'learning_rate': np.arange(0.05, 0.5, 0.05)}\n",
    "#применение метода гридсёрч со встроенной кросс-валидацией\n",
    "\n",
    "rand_lgbm = RandomizedSearchCV(lgbm, n_iter=20, param_distributions= parameters, scoring='f1', n_jobs= -3, cv=5)\n",
    "#обучение модели\n",
    "rand_lgbm.fit(features_train, target_train.values)\n",
    "\n",
    "#лучшее значение после перебора параметров \n",
    "best_lgbm = rand_lgbm.best_score_\n",
    "\n",
    "print(\"Лучшие параметры для модели LGBMClassifier с \"\\\n",
    "    \"использованием кросс-валидации:\", rand_lgbm.best_params_)\n",
    "print(\"Наибольшее значение метрики F1 для модели LGBMClassifier \"\\\n",
    "    \"при лучших гиперпараметрах с использованием кросс-валидации:\", best_lgbm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по методу BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>Значение метрики F1</th>\n",
       "      <th>Время расчета (~12 000 строк)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Логистическая регрессия</td>\n",
       "      <td>0.628426</td>\n",
       "      <td>~30 секунд</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Модель опорных векторов</td>\n",
       "      <td>0.663157</td>\n",
       "      <td>~1 минута</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Случайный лес</td>\n",
       "      <td>0.614233</td>\n",
       "      <td>~3 минуты</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.646331</td>\n",
       "      <td>~10 минут</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Модель  Значение метрики F1 Время расчета (~12 000 строк)\n",
       "0  Логистическая регрессия             0.628426                    ~30 секунд\n",
       "1  Модель опорных векторов             0.663157                     ~1 минута\n",
       "2            Случайный лес             0.614233                     ~3 минуты\n",
       "3           LGBMClassifier             0.646331                     ~10 минут"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = ['Логистическая регрессия', 'Модель опорных векторов', 'Случайный лес', 'LGBMClassifier']\n",
    "F1 = [log_reg_f1, svclassifier_f1, best_forest, best_lgbm]\n",
    "total_time = ['~30 секунд', '~1 минута', '~3 минуты', '~10 минут']\n",
    "\n",
    "bert_result_table = pd.DataFrame({ #созаем датафрейм\n",
    "    'Модель': models, #\n",
    "    'Значение метрики F1': F1,\n",
    "    'Время расчета (~12 000 строк)': total_time\n",
    "}) #\n",
    "bert_result_table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили довольно неплохие показатели метрики F1. На всех моделях удалось получить сравнительно одинаковое значение метрики. На модели опорных векторов получили максимальное значение 0.66. Чего, в свою очередь недостаточно, для выполнения этой задачи.\n",
    "\n",
    "Модель `LGBMClassifier` дает результат значительнее дольше остальных моделей."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка важности слова определяется величиной `TF-IDF`. `TF` отвечает за количество упоминаний слова в отдельном тексте, а `IDF` отражает частоту его употребления во всём корпусе."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подгрузка необходимых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df.copy() #исходный датасет, до преобразований BERTa\n",
    "df_check = df.head(100) #таблица для проверки работоспособности лемматизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\maxpe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\maxpe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\maxpe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maxpe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#загружаем необходимые дополнения для библиотеки\n",
    "nltk.download('wordnet') \n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None #убираем предупреждения"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция очистки текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "\n",
    "    def limit(text):\n",
    "        #убираем из комментариев слова длиной от 50 до 10000 символов\n",
    "        #это ограничение необходимо, т.к. есть \"слово\", ломающее лемматизатор\n",
    "        lim = re.sub(r'\\b\\w{50,10000}\\b', ' ', text) \n",
    "        lim1 = \" \".join(lim.split()) #применяем фильтр\n",
    "        \n",
    "        return lim1\n",
    "\n",
    "    clear = re.sub(r'[^a-zA-Z ]', ' ', limit(text)) #фильтруем латиницу, символы\n",
    "    clear1 = \" \".join(clear.split()) #применяем фильтр\n",
    "    \n",
    "    return clear1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft['lemma'] = dft['text'].apply(clear_text) #применяем очистку текста"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Лемматизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    #лемматизируем текст с помощью лемматизатора предложений из пакета pywsd\n",
    "    lemma = lemmatize_sentence(text) \n",
    "    return \" \".join(lemma)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизатор, так же как и преобразование эмбеддингов, считается довольно долго, порядка 50 минут. Ниже лемматизирован кусочек из 100 строк оригинальной таблицы, чтобы показать работу лемматизатора.\n",
    "\n",
    "Полный датасет рассчитан заранее и загружается после проверки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                               lemma  \n",
       "0  explanation why the edits make under my userna...  \n",
       "1  d aww he match this background colour i m seem...  \n",
       "2  hey man i m really not try to edit war it s ju...  \n",
       "3  more i can t make any real suggestion on impro...  \n",
       "4  you sir be my hero any chance you remember wha...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check['lemma'] = df_check['text'].apply(clear_text) #повторяем очистку, т.к. датасет - другой\n",
    "df_check['lemma'] = df_check['lemma'].apply(lemmatize_text) #лемматизируем текст\n",
    "df_check.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выгрузка датасета"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же, как и с таблицей после преобразования эмбеддингов `df_ed`, этот датасет был выгружен один раз, после чего вывод таблицы - закомментирован. \n",
    "\n",
    "Лемматизировался полный датасет `df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dft.to_csv('df_lemma.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка лемматизированного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and for the second time of ask when your view ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>you should be ashamed of yourself that be a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>spitzer umm theres no actual article for prost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and it look like it be actually you who put on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>and i really don t think you understand i come...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...      0   \n",
       "1       D'aww! He matches this background colour I'm s...      0   \n",
       "2       Hey man, I'm really not trying to edit war. It...      0   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4       You, sir, are my hero. Any chance you remember...      0   \n",
       "...                                                   ...    ...   \n",
       "159287  \":::::And for the second time of asking, when ...      0   \n",
       "159288  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "159289  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
       "159290  And it looks like it was actually you who put ...      0   \n",
       "159291  \"\\nAnd ... I really don't think you understand...      0   \n",
       "\n",
       "                                                    lemma  \n",
       "0       explanation why the edits make under my userna...  \n",
       "1       d aww he match this background colour i m seem...  \n",
       "2       hey man i m really not try to edit war it s ju...  \n",
       "3       more i can t make any real suggestion on impro...  \n",
       "4       you sir be my hero any chance you remember wha...  \n",
       "...                                                   ...  \n",
       "159287  and for the second time of ask when your view ...  \n",
       "159288  you should be ashamed of yourself that be a ho...  \n",
       "159289  spitzer umm theres no actual article for prost...  \n",
       "159290  and it look like it be actually you who put on...  \n",
       "159291  and i really don t think you understand i come...  \n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# используем api \n",
    "base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?' \n",
    "public_key = 'https://disk.yandex.ru/d/zNN-U7f8m-UaaQ' \n",
    " \n",
    "# получаем url \n",
    "final_url = base_url + urlencode(dict(public_key=public_key)) \n",
    "response = requests.get(final_url) \n",
    "download_url = response.json()['href'] \n",
    " \n",
    "# загружаем файл в df \n",
    "download_response = requests.get(download_url)\n",
    "df_lem_f = pd.read_csv(download_url, sep=',')\n",
    "df_lem_f"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение для TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разбиение данных"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заранее посчитав все метрики на полном датасете, я пришел к выводу, что датасет придется также ограничить, взяв на разбиение признаков 60% от исходного. Время обучения некоторых моделей даже при грубом переборе гиперпараметров (а в случае модели опорных векторов, то даже на голой модели без перебора) слишком велико, притом, для получения необходимого порога метрики хватает с запасом 60% данных. \n",
    "\n",
    "Обязательно стратифицируем по целевому признаку, чтобы сохранить баланс классов целевого признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1, df_lem = train_test_split(df_lem_f, test_size=0.6, random_state=RANDOM_STATE, stratify= df_lem_f['toxic']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_lem, features_test_lem, target_train_lem, target_test_lem = train_test_split( #создаем 4 датасета, два признаков (тест+валидация) и два целевых, \n",
    "    df_lem.drop(columns='toxic'), #для датасетов признаков удаляем целевой\n",
    "    df_lem['toxic'], #для целевого оставляем только целевой\n",
    "    test_size=0.2, #с соотношением \n",
    "    random_state=RANDOM_STATE, #с заданной опорой для рандома \n",
    "    stratify= df_lem['toxic']) #с заданной стратификацией по целевому признаку"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вводим стоп слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоп слова - слова, не несущие смысловой нагрузки. Они не должны влиять на обучение."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Мешки слов"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим счётчик, далее передаём счётчику корпус текстов. Для этого вызовем `fit_transform()`. \n",
    "\n",
    "Счётчик выделит из корпуса уникальные слова и посчитает количество их вхождений в каждом тексте корпуса. Отдельные буквы счётчик как слова не учитывает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76460, 99373)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_train = features_train_lem['lemma'].values.astype('U') #создаем корпус текстов\n",
    "count_tf_idf_train = TfidfVectorizer(stop_words=stop_words) #создаем счетчик величин TF-IDF, с учетом стоп слов\n",
    "tf_idf_train = count_tf_idf_train.fit_transform(corpus_train) #передаем счётчику корпус текстов (fit запускается только на обучающей выборке)\n",
    "tf_idf_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_tf_idf_train.get_feature_names() #посмотреть словарь уникальных слов"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичным образом работаем и с тестовой выборкой. Единственное отличие - `transform` для теста не обучается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19116, 99373)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_test = features_test_lem['lemma'].values.astype('U')\n",
    "tf_idf_test = count_tf_idf_train.transform(corpus_test)\n",
    "tf_idf_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные предобработаны, можно переходить к обучению."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение метрики F1 для модели логистической регрессии с использованием кросс-валидации: 0.7400516020260364\n",
      "CPU times: total: 4.52 s\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "log_reg_lem = LogisticRegression(solver='lbfgs', max_iter=1000, class_weight= 'balanced') #максимальное количество итераций 1000, \n",
    "log_reg_scores_lem = cross_val_score(log_reg_lem, tf_idf_train, target_train_lem.values, scoring='f1', cv=10)\n",
    "log_reg_f1_lem = log_reg_scores_lem.mean()\n",
    "\n",
    "print(\"Среднее значение метрики F1 для модели логистической регрессии \"\\\n",
    "    \"с использованием кросс-валидации:\", log_reg_f1_lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель опорных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение метрики F1 для модели SVC с использованием кросс-валидации: 0.7394661035823685\n",
      "CPU times: total: 8min 3s\n",
      "Wall time: 8min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "svclassifier_lem = SVC(kernel='linear', class_weight= 'balanced') \n",
    "svclassifier_scores_lem = cross_val_score(svclassifier_lem, tf_idf_train, target_train_lem.values, scoring='f1', cv=2)\n",
    "svclassifier_f1_lem = svclassifier_scores_lem.mean()\n",
    "\n",
    "print(\"Среднее значение метрики F1 для модели SVC \"\\\n",
    "    \"с использованием кросс-валидации:\", svclassifier_f1_lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для модели случайного леса с использованием кросс-валидации: {'n_estimators': 151, 'max_depth': 91}\n",
      "Наибольшее значение метрики F1 для модели случайного леса при лучших гиперпараметрах с использованием кросс-валидации: 0.5342654316870761\n",
      "CPU times: total: 1min 12s\n",
      "Wall time: 5min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "forest_lem = RandomForestClassifier(random_state=RANDOM_STATE, class_weight= 'balanced') #модель случайного леса\n",
    "parameters = {'n_estimators': range (1, 500, 50), 'max_depth': range (1, 100, 10)} #перебор гиперпараметров\n",
    "#применение метода гридсёрч со встроенной кросс-валидацией к модели леса с перебором указанных параметров\n",
    "\n",
    "randomized_forest_lem = RandomizedSearchCV(forest_lem, n_iter=15, param_distributions= parameters, scoring='f1', n_jobs= -2, cv=2)\n",
    "#обучение модели\n",
    "randomized_forest_lem.fit(tf_idf_train, target_train_lem.values)\n",
    "\n",
    "#лучшее значение после перебора параметров \n",
    "best_forest_lem = abs(randomized_forest_lem.best_score_)\n",
    "\n",
    "print(\"Лучшие параметры для модели случайного леса с \"\\\n",
    "    \"использованием кросс-валидации:\", randomized_forest_lem.best_params_)\n",
    "print(\"Наибольшее значение метрики F1 для модели случайного леса \"\\\n",
    "    \"при лучших гиперпараметрах с использованием кросс-валидации:\", best_forest_lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для модели случайного леса с использованием кросс-валидации: {'n_estimators': 131, 'max_depth': 96, 'learning_rate': 0.30000000000000004}\n",
      "Наибольшее значение метрики F1 для модели LGBMClassifier при лучших гиперпараметрах с использованием кросс-валидации: 0.758343798605508\n",
      "CPU times: total: 1min 30s\n",
      "Wall time: 5min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgbm_lem = lgb.LGBMClassifier() #\n",
    "parameters = {'n_estimators': range (1, 500, 10), 'max_depth': range (1, 100, 5), 'learning_rate': np.arange(0.1, 0.8, 0.1)}\n",
    "#применение метода гридсёрч со встроенной кросс-валидацией\n",
    "\n",
    "rand_lgbm_lem = RandomizedSearchCV(lgbm_lem, n_iter=20, param_distributions= parameters, scoring='f1', n_jobs= -2, cv=3)\n",
    "#обучение модели\n",
    "rand_lgbm_lem.fit(tf_idf_train, target_train_lem.values)\n",
    "\n",
    "#лучшее значение после перебора параметров \n",
    "best_lgbm_lem = rand_lgbm_lem.best_score_\n",
    "\n",
    "print(\"Лучшие параметры для модели LGBMClassifier с \"\\\n",
    "    \"использованием кросс-валидации:\", rand_lgbm_lem.best_params_)\n",
    "print(\"Наибольшее значение метрики F1 для модели LGBMClassifier \"\\\n",
    "    \"при лучших гиперпараметрах с использованием кросс-валидации:\", best_lgbm_lem)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по методу TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>Значение метрики F1</th>\n",
       "      <th>Время расчета (~12 000 строк)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Логистическая регрессия</td>\n",
       "      <td>0.740052</td>\n",
       "      <td>~15 секунд</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Модель опорных векторов</td>\n",
       "      <td>0.739466</td>\n",
       "      <td>~8 минут</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Случайный лес</td>\n",
       "      <td>0.534265</td>\n",
       "      <td>~6 минут</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.758344</td>\n",
       "      <td>~6 минут</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Модель  Значение метрики F1 Время расчета (~12 000 строк)\n",
       "0  Логистическая регрессия             0.740052                    ~15 секунд\n",
       "1  Модель опорных векторов             0.739466                      ~8 минут\n",
       "2            Случайный лес             0.534265                      ~6 минут\n",
       "3           LGBMClassifier             0.758344                      ~6 минут"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = ['Логистическая регрессия', 'Модель опорных векторов', 'Случайный лес', 'LGBMClassifier']\n",
    "F1 = [log_reg_f1_lem, svclassifier_f1_lem, best_forest_lem, best_lgbm_lem]\n",
    "total_time = ['~15 секунд', '~8 минут', '~6 минут', '~6 минут']\n",
    "\n",
    "tf_result_table = pd.DataFrame({ #созаем датафрейм\n",
    "    'Модель': models, #\n",
    "    'Значение метрики F1': F1,\n",
    "    'Время расчета (~12 000 строк)': total_time\n",
    "}) #\n",
    "tf_result_table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили два близких значения метрики F1 к требуемому: на логистической регрессии и на модели опорных векторов. Несмотря на то, что значение метрики для регрессии ниже требуемого, она все же может пригодиться, если нужно сделать довольно точные предсказания на скорость. Модель векторов, напротив, самая медленная из всех. Модель леса оказалась самой неточной. \n",
    "\n",
    "Единственная модель, удовлетворяющая условию - `LGBMClassifier`, дает необходимое значение метрики, к тому же предсказывает результат не дольше других моделей (а на полном наборе - быстрее других)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверяем лучшую модель"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестируем модель `LGBMClassifier`, которая при предобработке методом `TF-IDF`, показала себя как точную и достаточно быструю (даже с учетом перебора гиперпараметров) модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наименьшее значение метрики F1 на тестовых данных 0.7659820653746022\n",
      "CPU times: total: 1min 32s\n",
      "Wall time: 6.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgbm_lem_1 = lgb.LGBMClassifier(\n",
    "    n_estimators=rand_lgbm_lem.best_params_['n_estimators'], \n",
    "    max_depth=rand_lgbm_lem.best_params_['max_depth'], \n",
    "    learning_rate=rand_lgbm_lem.best_params_['learning_rate'])\n",
    "lgbm_lem_1.fit(tf_idf_train, target_train_lem.values)\n",
    "\n",
    "predictions_lgbm_lem_1 = lgbm_lem_1.predict(tf_idf_test)\n",
    "\n",
    "lgbm_lem_f1 = f1_score(target_test_lem, predictions_lgbm_lem_1)\n",
    "print(\"Наименьшее значение метрики F1 на тестовых данных\", lgbm_lem_f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили значение метрики F1 в пределах 0,77."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В проекте было рассмотрено два метода обработки натурального языка, а именно:\n",
    "\n",
    "- `BERT`,\n",
    "- `TF-IDF`.\n",
    "\n",
    "Преобразовав текст для `BERT`, мы получили значение метрики, не удовлетворяющее условию, а именно, метрику F1 < 0.75. Это связано с тем, что модели обучались не на всем наборе данных, а лишь на 10%. Здесь упираемся в аппаратные ограничения и скорость обучения и перебора параметров. \n",
    "\n",
    "В методе `TF-IDF` мы добились необходимого значения метрики `F1`, для модели `LGBMClassifier`. Она же показала результат на тестовых данных равный 0.77. Здесь омодели обучались уже на 60% данных, что значительно увеличило значение метрики `F1`. То есть, даже если этот метод менее точен, чем `BERT` (при условии использования 100% данных), он намного менее требователен к аппаратным ресурсам и намного быстрее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_practicum_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "af7472ffbb6f11e94eca2dc243fc9b09d1dc0fb11170c3918ea151f7aad82d25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
